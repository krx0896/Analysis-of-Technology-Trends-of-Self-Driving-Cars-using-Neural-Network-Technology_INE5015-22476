순서,출원번호,출원일자,공개번호,공개일자,공고번호,공고일자,등록번호,등록일자,발명의명칭,IPC분류,출원인,요약
1,16985460,2020.08.05,20220044033,2022.02.10,20220044033,2022.02.10,,,MULTIPLE RESOLUTION DEEP NEURAL NETWORKS FOR VEHICLE AUTONOMOUS DRIVING SYSTEMS,"G06K9/00,G06K9/62,G06N3/08,G06N3/04,G06N20/20,G06T7/00,G06T7/20,G01S17/89","Dalong Li,Stephen Horton,Neil R Garbacik","Techniques for training multiple resolution deep neural networks (DNNs) for vehicle autonomous driving comprise obtaining a training dataset for training a plurality of DNNs for an autonomous driving feature of the vehicle, sub-sampling the training dataset to obtain a plurality of training datasets comprising the training dataset and one or more sub-sampled datasets each having a different resolution than a remainder of the plurality of training datasets, training the plurality of DNNs using the plurality of training datasets, respectively, determining a plurality of outputs for the autonomous driving feature using the plurality of trained DNNs and the input data, receiving input data for the autonomous driving feature captured by a sensor device, and determining a best output for the autonomous driving feature using the plurality of outputs."
2,17229264,2021.04.13,,,11254331,2022.02.22,11254331,2022.02.22,"Learning method and learning device for updating object detector, based on deep learning, of autonomous vehicle to adapt the object detector to driving circumstance, and updating method and updating device using the same","B60W60/00,G06K9/62,G06K9/32,G06N3/08","Stradvision, Inc.","A method for updating an object detector of an autonomous vehicle to adapt the object detector to a driving circumstance is provided. The method includes steps of: a learning device (a) (i) inputting a training image, corresponding to a driving circumstance, into a circumstance-specific object detector to apply (i-1) convolution to the training image to generate a circumstance-specific feature map, (i-2) ROI pooling to the circumstance-specific feature map to generate a circumstance-specific pooled feature map, and (i-3) fully-connected operation to the circumstance-specific pooled feature map to generate circumstance-specific object detection information and (ii) inputting the circumstance-specific feature map into a circumstance-specific ranking network to (ii-1) apply deconvolution to the circumstance-specific feature map and generate a circumstance-specific segmentation map and (ii-2) generate a circumstance-specific rank score via a circumstance-specific discriminator; and (b) training the circumstance-specific object detector, the circumstance-specific deconvolutional layer, the circumstance-specific convolutional layer, and the circumstance-specific discriminator."
3,17229264,2021.04.13,20210354721,2021.11.18,20210354721,2021.11.18,,,"Learning Method and Learning Device for Updating Object Detector, Based on Deep Learning, of Autonomous Vehicle to Adapt the Object Detector to Driving Circumstance, and Updating Method and Updating Device Using the Same","B60W60/00,G06K9/62,G06N3/08,G06K9/32","Stradvision, Inc.","A method for updating an object detector of an autonomous vehicle to adapt the object defector to a driving circumstance is provided. The method includes steps of; a learning device (a) (i) inputting a training image, corresponding to a driving circumstance, into a circumstance-specific object detector to apply (i-1) convolution to the training image to generate a circumstance-specific feature map, (i-2) ROI pooling to the circumstance-specific feature map to generate a circumstance-specific pooled feature map, and (i-3) fully-connected operation to the circumstance-specific pooled feature map to generate circumstance-specific object detection information and (ii) inputting the circumstance-specific feature map into a circumstance-specific ranking network to (ii-1) apply deconvolution to the circumstance-specific feature map and generate a circumstance-specific segmentation map and (ii-2) generate a circumstance-specific rank score via a circumstance-specific discriminator; and (b) training the circumstance-specific object detector, the circumstance-specific deconvolutional layer, the circumstance-specific convolutional layer, and the circumstance-specific discriminator."
4,17073860,2020.10.19,20220119002,2022.04.21,20220119002,2022.04.21,,,System and Method for Neural Network-Based Autonomous Driving,"B60W60/00,B60W40/11,B60W40/112,B60W40/114,B60W50/04,G06N3/04,G06N3/08","Marvell Asia Pte, Ltd.","A system and corresponding method for autonomous driving of a vehicle are provided. The system comprises at least one neural network (NN) that generates at least one output for controlling the autonomous driving. The system further comprises a main data path that routes bulk sensor data to the at least one NN and a low-latency data path with reduced latency relative to the main data path. The low-latency data path routes limited sensor data to the at least one NN which, in turn, employs the limited sensor data to improve performance of the at least one NN's processing of the bulk sensor data for generating the at least one output. Improving performance of the at least one NN's processing of the bulk sensor data enables the system to, for example, identify a safety hazard sooner, enabling the autonomous driving to divert the vehicle and avoid contact with the safety hazard."
5,16519814,2019.07.23,,,11199839,2021.12.14,11199839,2021.12.14,Method of real time vehicle recognition with neuromorphic computing network for autonomous driving,"G05D1/00,G05B13/00,G08G1/16,G06K5/00,G06K7/00,G06N20/00,G05D1/02,G05B13/02","HRL Laboratories, LLC","Described is a system for online vehicle recognition in an autonomous driving environment. Using a learning network comprising an unsupervised learning component and a supervised learning component, images of moving vehicles extracted from videos captured in the autonomous driving environment are learned and classified. Vehicle feature data is extracted from input moving vehicle images. The extracted vehicle feature data is clustered into different vehicle classes using the unsupervised learning component. Vehicle class labels for the different vehicle classes are generated using the supervised learning component. Based on a vehicle class label for a moving vehicle in the autonomous driving environment, the system selects an action to be performed by the autonomous vehicle, and causes the selected action to be performed by the autonomous vehicle in the autonomous driving environment."
6,17024137,2020.09.17,20210001880,2021.01.07,20210001880,2021.01.07,,,"VEHICLE-MOUNTED CONTROL UNIT, AND METHOD AND APPARATUS FOR FPGA BASED AUTOMATIC DRIVING OF VEHICLE","B60W60/00,H04N7/18,G06K9/00,G06N3/08,G05D1/02,G05D1/00,G01S13/86","BAIDU ONLINE NETWORK TECHNOLOGY (BEIJING) CO., LTD.,BAIDU ONLINE NETWORK TECHNOLOGY (BEIJING) CO., LTD.","Embodiments of the present disclosure provide a vehicle-mounted control unit, and a method and an apparatus for FPGA based automatic driving of a vehicle, which includes a MCU and a first SoC implemented by being integrated with an ARM through the FPGA, where the vehicle-mounted control unit is set on an automatic driving vehicle, the FPGA of the first SoC receives video data sent by a vehicle-mounted camera, performs visual perception on the video data by using a first neural network algorithm to obtain first perception information; and sends the first perception information to the ARM of the first SoC. The ARM of the first SoC processes the first perception information to obtain first decision information, and sends the first decision information to the MCU. Finally, the MCU generates a control command according to the first decision information and sends it to the corresponding execution mechanism."
7,16519814,2019.07.23,20200026287,2020.01.23,20200026287,2020.01.23,,,METHOD OF REAL TIME VEHICLE RECOGNITION WITH NEUROMORPHIC COMPUTING NETWORK FOR AUTONOMOUS DRIVING,"G05D1/00,G05B13/02,G05D1/02","HRL Laboratories, LLC","Described is a system for online vehicle recognition in an autonomous driving environment. Using a learning network comprising an unsupervised learning component and a supervised learning component, images of moving vehicles extracted from videos captured in the autonomous driving environment are learned and classified. Vehicle feature data is extracted from input moving vehicle images. The extracted vehicle feature data is clustered into different vehicle classes using the unsupervised learning component. Vehicle class labels for the different vehicle classes are generated using the supervised learning component. Based on a vehicle class label for a moving vehicle in the autonomous driving environment, the system selects an action to be performed by the autonomous vehicle, and causes the selected action to be performed by the autonomous vehicle in the autonomous driving environment."
8,16709790,2019.12.10,20200180647,2020.06.11,20200180647,2020.06.11,,,NEURAL NETWORK BASED MODELING AND SIMULATION OF NON-STATIONARY TRAFFIC OBJECTS FOR TESTING AND DEVELOPMENT OF AUTONOMOUS VEHICLE SYSTEMS,"B60W50/00,G05D1/00,B60W40/04","Perceptive Automata, Inc.","A system performs modeling and simulation of non-stationary traffic entities for testing and development of modules used in an autonomous vehicle system. The system uses a machine learning based model that predicts hidden context attributes for traffic entities that may be encountered by a vehicle in traffic. The system generates simulation data for testing and development of modules that help navigate autonomous vehicles. The generated simulation data may be image or video data including representations of traffic entities, for example, pedestrians, bicyclists, and other vehicles. The system may generate simulation data using generative adversarial neural networks."
9,17396269,2021.08.06,20220041180,2022.02.10,20220041180,2022.02.10,,,SYSTEM AND METHOD FOR GENERATING AND CONTROLLING DRIVING PATHS IN AUTONOMOUS VEHICLE,"B60W60/00,B60W40/105,B60W10/20,G06N3/04,G06N3/08","Electronics and Telecommunications Research Institute,Electronics and Telecommunications Research Institute","Provided is a method of generating and controlling a driving path for an autonomous vehicle, the method including generating a driving path that matches a driving intention on the basis of sensing data acquired from a sensing module of the autonomous vehicle, determining steering angle information corresponding to the generated driving path, and controlling a steering angle of the autonomous vehicle."
10,16724833,2019.12.23,20200239029,2020.07.30,10919543,2021.02.16,10919543,2021.02.16,Learning method and learning device for determining whether to switch mode of vehicle from manual driving mode to autonomous driving mode by performing trajectory-based behavior analysis on recent driving route,"B60W60/00,H04W4/40,B60W30/095,G06K9/00,G06K9/62,G06N3/04,G06N3/08","StradVision, Inc.","A learning method for calculating collision probability, to be used for determining whether it is appropriate or not to switch driving modes of a vehicle capable of an autonomous driving, by analyzing a recent driving route of a driver is provided. And the method includes steps of: (a) a learning device, on condition that a status vector and a trajectory vector are acquired, performing processes of (i) instructing a status network to generate a status feature map and (ii) instructing a trajectory network to generate a trajectory feature map; (b) the learning device instructing a safety network to calculate a predicted collision probability representing a predicted probability of an accident occurrence; and (c) the learning device instructing a loss layer to generate a loss by referring to the predicted collision probability and a GT collision probability, which have been acquired beforehand, to learn at least part of parameters."
11,16725064,2019.12.23,20200242411,2020.07.30,20200242411,2020.07.30,,,"LEARNING METHOD AND LEARNING DEVICE FOR SWITCHING MODES OF AUTONOMOUS VEHICLE BASED ON ON-DEVICE STANDALONE PREDICTION TO THEREBY ACHIEVE SAFETY OF AUTONOMOUS DRIVING, AND TESTING METHOD AND TESTING DEVICE USING THE SAME","G06K9/62,G06K9/00,G06N3/04,G06N3/08,G05D1/00","StradVision, Inc.","A learning method for generating parameters capable of representing a degree of credibility of an object detection during a process of the object detection is provided. And the method includes steps of: (a) a learning device instructing a convolutional layer to generate a convolutional feature map by applying a convolutional operation to a training image; (b) the learning device instructing an anchor layer to generate an RPN confidence map including RPN confidence scores; (c) the learning device instructing an FC layer to generate CNN confidence scores, to thereby generate a CNN confidence map; and (d) the learning device instructing a loss layer to learn parameters in the CNN and the RPN by performing backpropagation using an RPN loss and a CNN loss, generated by referring to the RPN confidence map, the CNN confidence map, an estimated object detection result and a GT object detection result."
12,16725064,2019.12.23,,,10726303,2020.07.28,10726303,2020.07.28,"Learning method and learning device for switching modes of autonomous vehicle based on on-device standalone prediction to thereby achieve safety of autonomous driving, and testing method and testing device using the same","G06K9/62,G06K9/00,G06N3/08,G05D1/00,G06N3/04","StradVision, Inc.","A learning method for generating parameters capable of representing a degree of credibility of an object detection during a process of the object detection is provided. And the method includes steps of: (a) a learning device instructing a convolutional layer to generate a convolutional feature map by applying a convolutional operation to a training image; (b) the learning device instructing an anchor layer to generate an RPN confidence map including RPN confidence scores; (c) the learning device instructing an FC layer to generate CNN confidence scores, to thereby generate a CNN confidence map; and (d) the learning device instructing a loss layer to learn parameters in the CNN and the RPN by performing backpropagation using an RPN loss and a CNN loss, generated by referring to the RPN confidence map, the CNN confidence map, an estimated object detection result and a GT object detection result."
13,16936897,2020.07.23,20200357285,2020.11.12,20200357285,2020.11.12,,,APPARATUS AND METHOD FOR PREVENTING INCORRECT BOARDING OF AUTONOMOUS DRIVING VEHICLE,"G08G1/00,H04W4/46,G08B25/01",LG ELECTRONICS INC.,"A method and an apparatus for preventing an incorrect boarding of an autonomous driving vehicle are disclosed. The method includes calling a first vehicle, acquiring positional information of the first vehicle and positional information of a passenger terminal, determining that a passenger boards a second vehicle when a position of the passenger terminal is continuously changed and a position of the first vehicle and the position of the passenger terminal are farther than a preset distance after a time point when the first vehicle is called, displaying a message inquiring whether to transfer to the first vehicle on a display of the passenger terminal, and transmitting a response to the message to a server."
14,16494724,2019.04.26,,,11367169,2022.06.21,11367169,2022.06.21,Method for processing picture of automatic driving vehicle,"G06T5/50,G06T7/70,B60W60/00,B60W50/00,B60W50/02,G06T7/20,G06N3/04",LG ELECTRONICS INC.,"Disclosed herein is a method for processing a picture of an automatic driving vehicle. The method for processing a picture of an automatic driving vehicle according to an embodiment of the present disclosure includes obtaining a first image from a camera while a vehicle on which the camera is driving, generating a prediction signal for predicting a sign of occurrence of White-Out from the first image, when a quantity of light which is a threshold brightness or higher from the first image, storing the first image during a first period when the prediction signal is generated, and predicting and correcting a second image based on the first image stored during the first period and a correction model, when the second image in which the White-Out occurs in the first image is detected on a specific time during the first period, and the correction model is a result of learning the second image by processing high dynamic range (HDR) image. At least one of the automatic driving vehicle according to the present disclosure, a user terminal and a server may be linked with artificial intelligence, robot, Augmented Reality (AR), virtual reality (VR), and the like."
15,16494724,2019.04.26,20210366088,2021.11.25,20210366088,2021.11.25,,,METHOD FOR PROCESSING PICTURE OF AUTOMATIC DRIVING VEHICLE,"G06T5/50,G06T7/20,G06T7/70,B60W60/00,B60W50/00,B60W50/02","LG ELECTRONICS INC.,LG ELECTRONICS INC.","Disclosed herein is a method for processing a picture of an automatic driving vehicle. The method for processing a picture of an automatic driving vehicle according to an embodiment of the present disclosure includes obtaining a first image from a camera while a vehicle on which the camera is driving, generating a prediction signal for predicting a sign of occurrence of White-Out from the first image, when a quantity of light which is a threshold brightness or higher from the first image, storing the first image during a first period when the prediction signal is generated, and predicting and correcting a second image based on the first image stored during the first period and a correction model, when the second image in which the White-Out occurs in the first image is detected on a specific time during the first period, and the correction model is a result of learning the second image by processing high dynamic range (HDR) image. At least one of the automatic driving vehicle according to the present disclosure, a user terminal and a server may be linked with artificial intelligence, robot, Augmented Reality (AR), virtual reality (VR), and the like."
16,16548747,2019.08.22,20190377360,2019.12.12,20190377360,2019.12.12,,,METHOD FOR ITEM DELIVERY USING AUTONOMOUS DRIVING VEHICLE,"G05D1/02,G08G1/127,H04W4/44,G06Q10/08","LG ELECTRONICS INC.,LG ELECTRONICS INC.","There is provided a method of delivering an item using an autonomous driving vehicle, including: receiving, from a server, a driving request signal for an item delivery service and controlling a vehicle to reach a location of a first terminal; providing a user of the first terminal with an item storage space, in a case where an authentication completion signal for the user of the first terminal is received from the server after the vehicle reaches the location of the first terminal; controlling the vehicle to reach the location of the second terminal, in a case where storage of the item is completed; and providing a user of the second terminal with the item, in a case where an authentication completion signal for the user of the second terminal is received from the server after the vehicle reaches the location of the second terminal."
17,17516129,2021.11.01,20220341739,2022.10.27,20220341739,2022.10.27,,,APPARATUS FOR GENERATING ROUTE OF AUTONOMOUS DRIVING VEHICLE AND METHOD FOR OFFERING SERVICE BY AUTONOMOUS DRIVING VEHICLE,"G01C21/34,G06Q10/04,G05D1/02,G06Q50/30,G06N3/02","HYUNDAI MOTOR COMPANY,Kia Corporation,HYUNDAI MOTOR COMPANY,Kia Corporation","An apparatus of generating a route of an autonomous driving vehicle may include an information obtaining device to obtain information on a road and information on a demand amount of the autonomous driving vehicle, and a controller to generate a map based on the information obtained from the information obtaining device and to generate a docking point based on the map."
18,17201412,2021.03.15,20210284193,2021.09.16,20210284193,2021.09.16,,,METHOD AND SYSTEM FOR AUTONOMOUS DRIVING OF A VEHICLE,"B60W60/00,G06K9/00,G06N3/08,G06K9/62",KOPERNIKUS AUTOMOTIVE GMBH,"The disclosure relates to a method for remote-controlled autonomous driving of a vehicle (  201  ) having the following method steps:  capturing the vehicle (  201  ) with the aid of at least one sensor, in particular camera, arranged in the surroundings of the vehicle (  201  ), determining a movement path for the vehicle (  201  ) by means of a processing device (  501  ) located outside the vehicle,  transmitting the movement path and/or control commands regarding the movement path to the vehicle (  201  ), and  implementing the movement path and/or the control commands in the vehicle (  201  ), in order to move the vehicle (  201  ) in accordance with the movement path."
19,16800125,2020.02.25,20210263157,2021.08.26,20210263157,2021.08.26,,,AUTOMATED LABELING SYSTEM FOR AUTONOMOUS DRIVING VEHICLE LIDAR DATA,"G01S17/89,G01S17/931,G01S17/86,G01S13/86,G06K9/00",Baidu USA LLC,A system and method for using high-end perception sensors such as high-end LIDARs to automatically label sensor data of low-end LIDARs of autonomous driving vehicles is disclosed. A perception system operating with a high-end LIDAR may process sensed data from the high-end LIDAR to detect objects and generate metadata of objects surrounding the vehicle. The confidence level of correctly identifying the objects using the high-end LIDAR may be further enhanced by fusing the data from the high-end LIDAR with data from other sensors such as cameras and radars. The method may use the detected objects and metadata of the detected objects processed from the data captured by the high-end LIDAR and other sensors as ground truth to label data of a same scene captured by a low-end LIDAR mounted on the vehicle. A neural network may use the labeled sensor data from the low-end LIDAR during offline supervised training.
20,16248214,2019.01.15,20200225676,2020.07.16,10915109,2021.02.09,10915109,2021.02.09,Control of autonomous vehicle based on pre-learned passenger and environment aware driving style profile,"G05D1/02,B60W40/09,G06N20/00,B60W50/00,G05D1/00",GM Global Technology Operations LLC,"A method for controlling a vehicle includes collecting data about human driving styles; machine learning how the human driver reacts to different traffic scenarios based on the collected data to create a plurality of human driving styles profiles; selecting an optimal driving profile of the plurality of human driving styles profiles, wherein the optimal driving profile is selected based feedback provided by a passenger of the vehicle, the feedback is indicative of a pleasantness of each of the plurality of human driving styles profiles; creating a driving plan based on the optimal driving profile; commanding the vehicle to execute the driving plan in a controlled environment to test the pleasantness of the optimal driving profile; and receiving a pleasantness rating from the passenger of the vehicle while the vehicle executes the driving plan."
21,17065910,2020.10.08,20210024346,2021.01.28,20210024346,2021.01.28,,,"METHOD, DEVICE AND SYSTEM FOR AUTOMATIC OILING OF LONG-DISTANCE TRANSPORT VEHICLE","B67D7/30,G01C21/34,G07C5/00,G05D1/00,G08G1/0968,B67D7/04,G08G1/0967,G08G1/00","Beijing Tusen Weilai Technology Co., Ltd.","The present application discloses a method, device and system for automatic oiling of a long-distance transport vehicle. The method provided by the present application includes: obtaining, by a transport planning system at a network side, vehicle status information, transport mission information and highway port information of the vehicle before the long-distance transport vehicle starts from a highway port of departure; generating a transport plan according to the vehicle status information, the transport mission information and the highway port information, wherein the transport plan comprises at least one highway port to be stopped at, cargo quantity to be loaded at each highway port to be stopped at and oil mass to be filled at each highway port to be stopped at; and sending the transport plan to the vehicle"
22,16783845,2020.02.06,,,11467579,2022.10.11,11467579,2022.10.11,Probabilistic neural network for predicting hidden context of traffic entities for autonomous vehicles,"G05D1/00,G06N7/00,G06N3/08,G05D1/02,B60W60/00","Perceptive Automata, Inc.",An autonomous vehicle uses probabilistic neural networks to predict hidden context attributes associated with traffic entities. The hidden context represents behavior of the traffic entities in the traffic. The probabilistic neural network is configured to receive an image of traffic as input and generate output representing hidden context for a traffic entity displayed in the image. The system executes the probabilistic neural network to generate output representing hidden context for traffic entities encountered while navigating through traffic. The system determines a measure of uncertainty for the output values. The autonomous vehicle uses the measure of uncertainty generated by the probabilistic neural network during navigation.
23,17187170,2021.02.26,20220274625,2022.09.01,20220274625,2022.09.01,,,GRAPH NEURAL NETWORKS WITH VECTORIZED OBJECT REPRESENTATIONS IN AUTONOMOUS VEHICLE SYSTEMS,"B60W60/00,G06N3/08,G06N3/04,B60W30/095,B60W50/00,B60W30/09","Zoox, Inc.,Zoox, Inc.","Techniques are discussed herein for generating and using graph neural networks (GNNs) including vectorized representations of map elements and entities within the environment of an autonomous vehicle. Various techniques may include vectorizing map data into representations of map elements, and object data representing entities in the environment of the autonomous vehicle. In some examples, the autonomous vehicle may generate and/or use a GNN representing the environment, including nodes stored as vectorized representations of map elements and entities, and edge features including the relative position and relative yaw between the objects. Machine-learning inference operations may be executed on the GNN, and the node and edge data may be extracted and decoded to predict future states of the entities in the environment."
24,16932680,2020.07.17,20210024090,2021.01.28,20210024090,2021.01.28,,,NEURAL NETWORK BASED PREDICTION OF HIDDEN CONTEXT OF TRAFFIC ENTITIES FOR AUTONOMOUS VEHICLES,"B60W60/00,G05D1/02,G06K9/46,G06K9/00,G06N3/08,G06N3/04","Perceptive Automata, Inc.",An autonomous vehicle uses machine learning based models such as neural networks to predict hidden context attributes associated with traffic entities. The hidden context represents behavior of the traffic entities in the traffic. The machine learning based model is configured to receive a video frame as input and output likelihoods of receiving user responses having particular ordinal values. The system uses a loss function based on cumulative histogram of user responses corresponding to various ordinal values. The system identifies user responses that are unlikely to be valid user responses to generate training data for training the machine learning mode. The system identifies invalid user responses based on response time of the user responses.
25,16783845,2020.02.06,20200249677,2020.08.06,20200249677,2020.08.06,,,PROBABILISTIC NEURAL NETWORK FOR PREDICTING HIDDEN CONTEXT OF TRAFFIC ENTITIES FOR AUTONOMOUS VEHICLES,"G05D1/00,G06N7/00,G06N3/08,G05D1/02,B60W60/00","Perceptive Automata, Inc.",An autonomous vehicle uses probabilistic neural networks to predict hidden context attributes associated with traffic entities. The hidden context represents behavior of the traffic entities in the traffic. The probabilistic neural network is configured to receive an image of traffic as input and generate output representing hidden context for a traffic entity displayed in the image. The system executes the probabilistic neural network to generate output representing hidden context for traffic entities encountered while navigating through traffic. The system determines a measure of uncertainty for the output values. The autonomous vehicle uses the measure of uncertainty generated by the probabilistic neural network during navigation.
26,16580201,2019.09.24,,,11427212,2022.08.30,11427212,2022.08.30,Autonomous driving control system for vehicle,"B60W50/038,B60R16/023,B60W50/02,G05D1/00,G07C5/08,B60W50/00",DENSO CORPORATION,"An autonomous driving control system is configured to perform autonomous driving of a vehicle. The autonomous driving control system includes: an electric power supply circuit including a plurality of electric power supplies, electric power supply lines respectively belonging to a plurality of systems and a relay device; a fault detector configured to detect a fault state of the relay device; an electric power supply controller configured to control the electric power supply circuit; and an autonomous driving control unit provided to control the autonomous driving of the vehicle. The autonomous driving control unit is configured to perform, upon detection by the fault detector of occurrence of a fault corresponding to a specific fault pattern in the relay device, a restricted autonomous driving control in which part of a control function of the autonomous driving is restricted compared to when no fault corresponding to the specific fault pattern is detected."
27,17248196,2021.01.13,,,11430466,2022.08.30,11430466,2022.08.30,Sound source detection and localization for autonomous driving vehicle,"H04B1/00,G10L25/51,H04R1/08,H04R1/40,G06N20/00,G06N5/04,G05D1/02,H04R3/00",Baidu USA LLC,"Systems and methods for sound source detection and localization utilizing an autonomous driving vehicle (ADV) are disclosed. The method includes receiving audio data from a number of audio sensors mounted on the ADV. The audio data comprises sounds captured by the audio sensors and emitted by one or more sound sources. Based on the received audio data, the method further includes determining a number of sound source information. Each sound source information comprises a confidence score associated with an existence of a specific sound. The method further includes generating a data representation to report whether there exists the specific sound within the driving environment of the ADV. The data representation comprises the determined sound source information. The received audio data and the generated data representation are utilized to subsequently train a machine learning algorithm to recognize the specific sound source during autonomous driving of the ADV in real-time."
28,17642367,2020.11.03,20220324440,2022.10.13,20220324440,2022.10.13,,,METHOD FOR OPERATING AN AUTONOMOUS DRIVING FUNCTION OF A VEHICLE,"B60W30/095,B60W60/00,B60W50/06",Robert Bosch GmbH,"A method for operating an autonomous driving function of a vehicle. The vehicle includes a computer unit and sensors for detecting surroundings data. The computer unit is configured to determine a setpoint trajectory for the vehicle, based on the detected surroundings data. In step a), an actual trajectory, and distances from objects in the surroundings, are detected. In step b), an ascertainment of the quality of the autonomous driving function takes place by comparing the actual trajectory to the setpoint trajectory and monitoring the detected distances from objects in the surroundings. In step c), a control of the quality to a predefined target value takes place by selecting sensors to be used for the autonomous driving function from the plurality of sensors and/or by changing a measuring rate, at which measurements are carried out, of at least one sensor from the plurality of sensors."
29,17678036,2022.02.23,20220266872,2022.08.25,20220266872,2022.08.25,,,MASS TRANSPORTATION VEHICLE AND DISPATCH MANAGEMENT DEVICE OF AUTONOMOUS VEHICLE,"B60W60/00,G01C21/36,G01C21/34,G06Q10/06",TOYOTA JIDOSHA KABUSHIKI KAISHA,A mass transportation vehicle includes a stop selector and a dispatcher. The stop selector is configured to enable a passenger on the mass transportation vehicle to select a destination stop at which the passenger plans to get off. The dispatcher is configured to book dispatch of an autonomous vehicle to which the passenger transfers after getting off the mass transportation vehicle at the destination stop. The dispatcher sends information about the destination stop to a dispatch management device of the autonomous vehicle as information about a waiting point of the autonomous vehicle.
30,17673788,2022.02.17,20220261707,2022.08.18,20220261707,2022.08.18,,,MANAGEMENT DEVICE OF AUTONOMOUS DRIVING VEHICLE,"G06Q10/02,G06Q30/02,G08G1/00,G08G1/01",TOYOTA JIDOSHA KABUSHIKI KAISHA,"The management device of an autonomous driving vehicle includes a congestion rate calculation unit and a waiting place setting unit. The congestion rate calculation unit is able to calculate the congestion rate of a parking lot adjoining each of a plurality of commercial facilities. In a case where the congestion rate of a neighbor parking lot, or a parking lot in the neighborhood of a boarding place contained in reservation information for an autonomous driving vehicle reserved for dispatch, during a waiting time period before the scheduled boarding time, is less than a congestion threshold, the waiting place setting unit sets the neighbor parking lot as a waiting place for the autonomous driving vehicle to wait during the waiting time period."
31,17534811,2021.11.24,20220204037,2022.06.30,20220204037,2022.06.30,,,METHOD AND APPARATUS FOR CREATING DRIVING ROUTE OF AUTONOMOUS VEHICLE AND COMPUTER PROGRAM THEREFOR,B60W60/00,"RideFlux Inc.,RideFlux Inc.","Provided are a method and apparatus for creating a driving route of an autonomous vehicle and a computer program therefor. A method of creating a driving route of an autonomous vehicle, the method being performed by a computing device, includes obtaining information about a start point and an end point, setting an intermediate point between the start point and the end point, and creating a driving route by connecting the start point, the set intermediate point, and the end point, wherein the driving route includes a set of a curve connecting the start point and the set intermediate point and a curve connecting the set intermediate point and the end point, is expressed by a polynomial function for an angle of movement of the autonomous vehicle, and satisfies one or more continuity conditions related to a curvature."
32,17248196,2021.01.13,20220223170,2022.07.14,20220223170,2022.07.14,,,SOUND SOURCE DETECTION AND LOCALIZATION FOR AUTONOMOUS DRIVING VEHICLE,"G10L25/51,H04R1/08,H04R1/40,H04R3/00,G06N20/00,G06N5/04,G05D1/02",Baidu USA LLC,"Systems and methods for sound source detection and localization utilizing an autonomous driving vehicle (ADV) are disclosed. The method includes receiving audio data from a number of audio sensors mounted on the ADV. The audio data comprises sounds captured by the audio sensors and emitted by one or more sound sources. Based on the received audio data, the method further includes determining a number of sound source information. Each sound source information comprises a confidence score associated with an existence of a specific sound. The method further includes generating a data representation to report whether there exists the specific sound within the driving environment of the ADV. The data representation comprises the determined sound source information. The received audio data and the generated data representation are utilized to subsequently train a machine learning algorithm to recognize the specific sound source during autonomous driving of the ADV in real-time."
33,17658072,2022.04.05,20220227392,2022.07.21,20220227392,2022.07.21,,,"VEHICLE CONTROL DEVICE, VEHICLE CONTROL METHOD, AND AUTOMATIC DRIVING METHOD","B60W60/00,B60W30/095,B60W40/04,B60W30/09,B60W30/14,B60W10/20,G06N3/08",DENSO CORPORATION,"In a vehicle control device, environmental information is acquired which is information about an environment in which a vehicle is placed. The environmental information precludes an obstacle around the vehicle. A possibility is estimated for potential proximity of the vehicle to the obstacle. A behavior of a predicted target moving object including the vehicle and at least one moving object around the vehicle is predicted based on the estimated possibility. A responsibility is determined for a potential accident that is assumed in response to the vehicle traveling on a candidate route that the vehicle travels."
34,16448497,2019.06.21,,,11327497,2022.05.10,11327497,2022.05.10,Autonomous transportation vehicle image augmentation,"G01C22/00,G05D1/00,G05D1/02,G01C21/36,G06N3/08,G06T19/00,B60W60/00","VOLKSWAGEN AG,AUDI AG,PORSCHE AG","Devices, systems, and methods related to autonomous transportation vehicle operation may include image augmentation arrangements for training and/or evaluating autonomous operations. Such augmentations may include artificial impressions of driving conditions which can prompt recovery operations."
35,17669325,2022.02.10,20220165100,2022.05.26,20220165100,2022.05.26,,,INTERVENTION IN OPERATION OF A VEHICLE HAVING AUTONOMOUS DRIVING CAPABILITIES,"G07C5/00,G05D1/00,G06N20/00,G06N5/00",Motional AD LLC,"Among other things, a determination is made that intervention in an operation of one or more autonomous driving capabilities of a vehicle is appropriate. Based on the determination, a person is enabled to provide information for an intervention. The intervention is caused in the operation of the one or more autonomous driving capabilities of the vehicle."
36,17599595,2019.12.06,20220161818,2022.05.26,20220161818,2022.05.26,,,METHOD AND SYSTEM FOR SUPPORTING AUTONOMOUS DRIVING OF AN AUTONOMOUS VEHICLE,"B60W60/00,B60W40/04,G16Y40/50,G08G1/16,G08G1/0967,G06N3/02,G06V20/58,H04W4/40",NEC Laboratories Europe GmbH,"A method for supporting autonomous driving of an autonomous vehicle includes detecting, by an in-vehicle internet-of-things (IoT) platform of the autonomous vehicle, a vulnerable road user (VRU) having a mobile device in a vicinity of the autonomous vehicle. A mobility application runs on the mobile device of the VRU and sends VRU-specific data to the in-vehicle IoT platform of the autonomous vehicle. The VRU is detected based on the VRU-specific data and/or in-vehicle sensor data of the autonomous vehicle. The method further includes determining, by the in-vehicle IoT platform, a movement intention prediction based on the VRU-specific data. The movement intention prediction is computed by use of a machine learning model. The VRU-specific data of the mobile device are provided as input data for the machine learning model. In addition, the method includes performing an autonomous driving decision for the autonomous vehicle based on the movement intention prediction."
37,17645350,2021.12.21,20220113722,2022.04.14,20220113722,2022.04.14,,,"METHOD FOR REMOTE CONTROL OF AUTONOMOUS DRIVING VEHICLE, AUTONOMOUS DRIVING VEHICLE AND CLOUD DEVICE","G05D1/00,G05D1/02,G06F3/0488","BEIJING BAIDU NETCOM SCIENCE TECHNOLOGY CO., LTD.,BEIJING BAIDU NETCOM SCIENCE TECHNOLOGY CO., LTD.",A method for remote control of an autonomous driving vehicle (ADV) includes: sending an assistance request to a cloud server in response to detecting that a current road section in front of the ADV is unable to be passed; obtaining a reference detour route returned from the cloud server; generating control instructions based on the reference detour route and a current driving environment of the ADV; and controlling the ADV based on the control instructions.
38,17099109,2020.11.16,20220153300,2022.05.19,20220153300,2022.05.19,,,ADJUSTING DRIVING PATTERN OF AUTONOMOUS VEHICLE,"B60W60/00,G06N20/00,B60W40/09,G01C21/34",International Business Machines Corporation,"An approach for adjusting driving parameters of an AV (autonomous vehicle) based on the driving style of the passenger is disclosed. The approach utilizes existing driving patterns of the passenger and perform a dynamic comparison and correlation with safe driving patterns of the passengers themselves. Based on that evaluation, the approach would suggest the parameters for adjusting the AV driving style in order to ensure AV riding experience meets the expected level of safe and stress-less riding. Furthermore, the approach can dynamically adjust the driving style during the trip based on the reaction and feedback from the passenger."
39,17475778,2021.09.15,20220089152,2022.03.24,20220089152,2022.03.24,,,APPARATUS AND METHOD FOR CONTROLLING AUTONOMOUS DRIVING OF VEHICLE,"B60W30/095,B60W40/04,B60W40/076,B60W60/00","HYUNDAI MOTOR COMPANY,KIA CORPORATION,HYUNDAI MOTOR COMPANY,KIA CORPORATION","An apparatus and method are provided for controlling autonomous driving of a vehicle which may derive predicted paths of a pedestrian and a two-wheel vehicle during autonomous driving of the vehicle so as to minimize accidents. The method includes calculating first height information allocating a first gradient that descends in a proceeding direction of objects, including a vehicle and a pedestrian, from respective positions of the objects based on dynamic information of the objects, calculating second height information allocating a second gradient based on a probability that the pedestrian will occupy infrastructure, calculating final height information by fusing the first height information and the second height information, generating a predicted path of the pedestrian, determining a driving strategy of a host vehicle based on a predicted path of the host vehicle and the predicted path of the pedestrian."
40,17399738,2021.08.11,20220048533,2022.02.17,20220048533,2022.02.17,,,Method and system for validating autonomous control software for a self-driving vehicle,"B60W60/00,G08G1/01",Volvo Car Corporation,"Method and system for validating an automated control software, ACS, for a vehicle, wherein the ACS is adapted for operating a vehicle in autonomous driving mode. The method comprises simulating use of the ACS in agent movement scenarios, wherein said simulating includes providing input sensor data to each vehicle agent to which an ACS has been assigned, and wherein movement of each of the other agents in the simulation is controlled to move either according to a replay of a corresponding real-world agent, or by an agent movement model."
41,16241083,2019.01.07,,,11262757,2022.03.01,11262757,2022.03.01,Autonomous driving apparatus and method for autonomous driving of a vehicle,"G05D1/00,G05D1/02,B60W30/00","SAMSUNG ELECTRONICS CO., LTD.","Disclosed are an autonomous driving apparatus for performing autonomous driving of a vehicle and a controlling method thereof. An autonomous driving apparatus according to an example aspect of the present disclosure includes a sensor configured to acquire sensing information to determine a driving state of the vehicle; a storage configured to store a plurality of autonomous driving models; and at least one processor configured to perform autonomous driving of the vehicle using one of the plurality of autonomous driving models stored in the storage based on sensing information sensed by the sensor. Accordingly, the autonomous driving apparatus is capable of performing autonomous driving of a vehicle by rapidly changing a driving mode to an autonomous driving mode suitable for an event occurring during autonomous driving of the vehicle."
42,16989576,2020.08.10,,,11263830,2022.03.01,11263830,2022.03.01,Intervention in operation of a vehicle having autonomous driving capabilities,"G07C5/00,G05D1/00,G06N99/00,G06N20/00,G06N5/00",Motional AD LLC,"Among other things, a determination is made that intervention in an operation of one or more autonomous driving capabilities of a vehicle is appropriate. Based on the determination, a person is enabled to provide information for an intervention. The intervention is caused in the operation of the one or more autonomous driving capabilities of the vehicle."
43,16923746,2020.07.08,20220012688,2022.01.13,20220012688,2022.01.13,,,DELIVERY PRODUCT ASSEMBLY IN COLLABORATION WITH INTELLIGENT AUTONOMOUS VEHICLE TRANSPORTATION SYSTEM,"G06Q10/08,G05D1/02,G05D1/00,G06Q10/04",International Business Machines Corporation,"Aspects of the present invention disclose a method for coordinating assembly of a final product in transit via an autonomous vehicle. The method includes one or more processors identifying a delivery request from a user for a product. The method further includes identifying suppliers of component parts of the product. The method further includes determining common delivery routes of the component parts of the product, wherein the common delivery routes includes respective routes from locations of the one or more suppliers to a delivery destination of the delivery request. The method further includes determining a delivery path to the delivery destination of the product based at least in part on the common delivery routes. The method further includes generating a final delivery plan corresponding to the product for one or more autonomous vehicles based at least in part on the delivery path and the suppliers of the component parts."
44,17098911,2020.11.16,20220001859,2022.01.06,20220001859,2022.01.06,,,AUTONOMOUS DRIVING SYSTEM FOR PREVENTING COLLISION OF CUT-IN VEHICLE AND AUTONOMOUS DRIVING METHOD THEREOF,"B60W30/09,B60W30/095,B60W60/00","HYUNDAI MOBIS CO., LTD.","An autonomous driving system for preventing collision with a cut-in vehicle may include a counterpart vehicle detector detecting driving information of a surrounding vehicle to deliver the driving information of the surrounding vehicle to a vehicle controller, a host vehicle detector detecting driving information of a host vehicle to deliver the driving information of the host vehicle to the vehicle controller, and the vehicle controller generating avoidance routes for avoiding collision with the surrounding vehicle entering a front of the host vehicle, designating a reach location according to a speed at a specific interval on the avoidance routes, and selecting an avoidance route for avoiding the collision among the plurality of avoidance routes, and then controlling a speed of the host vehicle to reach the reach location for avoiding the collision with the surrounding vehicle on the selected avoidance route, when there is possibility of collision."
45,17471982,2021.09.10,20210405635,2021.12.30,20210405635,2021.12.30,,,CONTROLLING DRIVING CONDITION COMPONENTS OF AN AUTONOMOUS VEHICLE BASED ON A CURRENT DRIVING MODE AND CURRENT CONDITIONS,"G05D1/00,B60W10/30,B60W50/00","TOYOTA RESEARCH INSTITUTE, INC.","A method for controlling a driving condition component of a vehicle includes disabling automatic operation of the driving condition component based on enabling an autonomous operating mode of the vehicle. The method also includes determining, while the vehicle is operating in the autonomous mode, a current condition satisfies an unsafe driving condition for a manual operating mode of the vehicle. The method further includes enabling the driving condition component to mitigate based on predicting a human occupant will enable the manual operating mode during a time period associated with the current condition, the driving condition component being enabled prior to the human occupant switching from the autonomous operating mode to the manual operating mode."
46,16907295,2020.06.21,20210394800,2021.12.23,20210394800,2021.12.23,,,Autonomous Driving Co-Driver Switch Mode Certification System and Method of Its Operation in a Commercial Vehicle ELD,"B60W60/00,G07C5/08,B60W40/09","TrueLite Trace, Inc.,TrueLite Trace, Inc.","A novel autonomous driving co-driver switch mode certification system securely determines and certifies an autonomous machine driving mode, which is activated in a permitted route under conditions approved by a regulatory agency. The autonomous driving co-driver switch mode, when enabled, allows a commercial vehicle driver to utilize the vehicle's autonomous driving capability as long as the commercial vehicle driver and the vehicle are also meeting the regulatory agency-defined safety and regulatory requirements before and during the autonomous machine driving mode. The autonomous driving co-driver switch mode is deemed trustworthy and certified by the regulatory agency, if the vehicle's ECU, ELD, and sensory readouts confirm a tamperproof validation of the agency-approvable state of the commercial vehicle driver and the vehicle. The novel autonomous driving co-driver switch mode certification system improves the public trustworthiness of autonomous driving modes intended to increase fleet productivity, fuel efficiency, and safety in commercial vehicles."
47,16960843,2020.06.12,20210387631,2021.12.16,20210387631,2021.12.16,,,FAIL-SAFE HANDLING SYSTEM FOR AUTONOMOUS DRIVING VEHICLE,"B60W50/023,B60W60/00,B60W50/02,B60W10/18,B60W30/06","Baidu USA LLC,Baidu.com Times Technology (Beijing) Co., Ltd.","According to various embodiment, described herein are methods and systems for reliably detecting malfunctions in a variety of software or hardware components in an autonomous driving vehicle (ADV). In one embodiment, a redundant system can be provided on an independent computing device in an ADV to check for malfunctions in a number of software or hardware components. When no malfunction occurs in the ADV, an autonomous driving system (ADS) in the ADV operates to drive the ADV, while the redundant system can monitor the ADS in a standby mode. In the event of a malfunction, the redundant system can take over the control of the ADV, and take appropriate actions based on a severity level of the malfunction."
48,17376118,2021.07.14,20210341915,2021.11.04,20210341915,2021.11.04,,,INTERVENTION IN OPERATION OF A VEHICLE HAVING AUTONOMOUS DRIVING CAPABILITIES,"G05D1/00,G07C5/08,G07C5/00",Motional AD LLC,"Among other things, a determination is made that intervention in an operation of one or more autonomous driving capabilities of a vehicle is appropriate. Based on the determination, a person is enabled to provide information for an intervention. The intervention is caused in the operation of the one or more autonomous driving capabilities of the vehicle."
49,16375610,2019.04.04,,,11144053,2021.10.12,11144053,2021.10.12,Controlling driving condition components of an autonomous vehicle based on a current driving mode and current conditions,"G05D1/00,B60W10/30,B60W50/00","TOYOTA RESEARCH INSTITUTE, INC.",A method for controlling a driving condition component of an autonomous vehicle is presented. The method includes determining whether current conditions would limit a driver's visibility. The method also includes predicting whether the driver will enable a manual mode during the current conditions. The method further includes controlling the driving condition component to mitigate the current conditions prior to the driver enabling the manual mode.
50,16485423,2019.07.22,,,11136048,2021.10.05,11136048,2021.10.05,System for sensor synchronization data analysis in an autonomous driving vehicle,"B60W60/00,G06K9/00","Baidu USA LLC,Baidu.com Times Technology (Beijing) Co., Ltd.","The disclosure describes various embodiments for online system-level validation of sensor synchronization. According to an embodiment, an exemplary method of analyzing sensor synchronization in an autonomous driving vehicle (ADV) include the operations of acquiring raw sensor data from a first sensor and a second sensor mounted on the ADV, the raw sensor data describing a target object in a surrounding environment of the ADV; and generating an accuracy map based on the raw sensor data in view of timestamps extracted from the raw sensor data. The method further includes the operations of generating a first bounding box and a second bounding box around the target object using the raw sensor data; and performing an analysis of the first and second bounding boxes and the accuracy map using a predetermined algorithm in view of one or more pre-configured sensor settings to determine whether the first sensor and the second sensor are synchronized with each other."
51,16929482,2020.07.15,20210291869,2021.09.23,20210291869,2021.09.23,,,MONITORING HEAD MOVEMENTS OF DRIVERS TASKED WITH MONITORING A VEHICLE OPERATING IN AN AUTONOMOUS DRIVING MODE,"B60W60/00,B60W40/08",WAYMO LLC,"Aspects of the disclosure relate to analyzing head movements in a test driver tasked with monitoring the driving of a vehicle operating in an autonomous driving mode. For instance, a sensor may be used to capture sensor data of a test driver's head for a period of time. The sensor data may be analyzed to determine whether the test driver's head moved sufficiently enough to suggest that the test driver is engaged in monitoring the driving of the vehicle. Based on the determination of whether the test driver's head moved sufficiently enough, an intervention response may be initiated."
52,16405420,2019.05.07,,,11106207,2021.08.31,11106207,2021.08.31,Apparatus and method for controlling autonomous driving of a vehicle,"G05D1/00,G06K9/00","HYUNDAI MOTOR COMPANY,KIA MOTORS CORPORATION","An apparatus for controlling autonomous driving of a vehicle includes a communication device configured to receive a first determination value, which is calculated based on information obtained as surroundings are sensed, from a surrounding vehicle or configured to receive a second determination value from a server. The apparatus includes a sensor configured to sense surroundings of a subject vehicle. The apparatus includes a controller configured to: calculate a third determination value based on information sensed by the sensor; to calculate a final determination value based on at least one of the first determination value and the second determination value, and the third determination value; and to control the autonomous driving by using the final determination value."
53,16262289,2019.01.30,,,11073399,2021.07.27,11073399,2021.07.27,Method for estimating position of ego vehicle for autonomous driving and autonomous driving apparatus,"G01C21/30,G05D1/02,G01C21/28,G01C21/36,G05D1/00,G01C21/32","ThorDrive, Inc.",The present invention relates to a method for estimating a position of an ego vehicle for autonomous driving including the steps of: receiving first sensor inputs from first sensors to extract visual road information; allowing the extracted visual road information to match first map data to produce a first matching score group; receiving second sensor inputs from second sensors; allowing the received second sensor inputs to match the second map data to produce a second matching score group; checking whether the first matching score group is consistent to the second matching score group; and estimating any one of the position candidates in the position candidate group of the ego vehicle as the position of the ego vehicle according to the consistency checking result.
54,16485423,2019.07.22,20210024096,2021.01.28,20210024096,2021.01.28,,,SYSTEM FOR SENSOR SYNCHRONIZATION DATA ANALYSIS IN AN AUTONOMOUS DRIVING VEHICLE,"B60W60/00,G06K9/00","Baidu USA LLC,Baidu.com Times Technology (Beijing) Co., Ltd.","The disclosure describes various embodiments for online system-level validation of sensor synchronization. According to an embodiment, an exemplary method of analyzing sensor synchronization in an autonomous driving vehicle (ADV) include the operations of acquiring raw sensor data from a first sensor and a second sensor mounted on the ADV, the raw sensor data describing a target object in a surrounding environment of the ADV; and generating an accuracy map based on the raw sensor data in view of timestamps extracted from the raw sensor data. The method further includes the operations of generating a first bounding box and a second bounding box around the target object using the raw sensor data; and performing an analysis of the first and second bounding boxes and the accuracy map using a predetermined algorithm in view of one or more pre-configured sensor settings to determine whether the first sensor and the second sensor are synchronized with each other."
55,17024651,2020.09.17,20210001841,2021.01.07,20210001841,2021.01.07,,,Obstacle Avoidance Method and Apparatus for Autonomous Driving Vehicle,"B60W30/09,B60W60/00,G06K9/00","Baidu Online Network Technology (Beijing) Co., Ltd.","An obstacle avoidance method and apparatus for an autonomous driving vehicle is provided. The method includes: in response to determining that there is an obstacle in a preset driving path, sending obstacle information to a preset terminal device so that the preset terminal device displays the obstacle information in a display page thereof, the obstacle information including an image of the obstacle and location information; receiving obstacle category information sent by the preset terminal device and inputted according to the displayed obstacle information; and determining an obstacle avoidance instruction for the autonomous driving vehicle according to the obstacle category indicated by the category information."
56,16989576,2020.08.10,20200402323,2020.12.24,20200402323,2020.12.24,,,INTERVENTION IN OPERATION OF A VEHICLE HAVING AUTONOMOUS DRIVING CAPABILITIES,"G07C5/00,G05D1/00,G06N20/00,G06N5/00",nuTonomy Inc.,"Among other things, a determination is made that intervention in an operation of one or more autonomous driving capabilities of a vehicle is appropriate. Based on the determination, a person is enabled to provide information for an intervention. The intervention is caused in the operation of the one or more autonomous driving capabilities of the vehicle."
57,16448497,2019.06.21,20200401150,2020.12.24,20200401150,2020.12.24,,,AUTONOMOUS TRANSPORTATION VEHICLE IMAGE AUGMENTATION,"G05D1/02,G06N3/08,G06T19/00,G01C21/36","VOLKSWAGEN AG,AUDI AG,PORSCHE AG","Devices, systems, and methods related to autonomous transportation vehicle operation may include image augmentation arrangements for training and/or evaluating autonomous operations. Such augmentations may include artificial impressions of driving conditions which can prompt recovery operations."
58,16906528,2020.06.19,20200401154,2020.12.24,20200401154,2020.12.24,,,"METHOD FOR CONTROLLING VEHICLE SPEED FOR AUTONOMOUS DRIVING, ELECTRONIC DEVICE, AND COMPUTER-READABLE STORAGE MEDIUM",G05D1/02,"WeRide Corp.,WeRide Corp","Disclosed are a method and apparatus for controlling a vehicle speed for autonomous driving, an electronic device and a computer-readable storage medium. The method includes: obtaining a basic vehicle speed control instruction output by a central controller of a target vehicle in real time; generating an ideal speed parameter matching the basic vehicle speed control instruction according to a preset processing delay; generating an additional vehicle speed control instruction to perform vehicle speed control on the target vehicle according to a difference between the ideal speed parameter and a real-time speed parameter of the target vehicle; and returning to perform the operation of generating the ideal speed parameter matching the basic vehicle speed control instruction according to the preset processing delay until the real-time speed parameter of the target vehicle tends to be consistent with the ideal speed parameter."
59,16853713,2020.04.20,20200387155,2020.12.10,20200387155,2020.12.10,,,INTERVENTION IN OPERATION OF A VEHICLE HAVING AUTONOMOUS DRIVING CAPABILITIES,"G05D1/00,G07C5/00,G07C5/08",nuTonomy Inc.,"Among other things, a determination is made that intervention in an operation of one or more autonomous driving capabilities of a vehicle is appropriate. Based on the determination, a person is enabled to provide information for an intervention. The intervention is caused in the operation of the one or more autonomous driving capabilities of the vehicle."
60,16391343,2019.04.23,20200341474,2020.10.29,20200341474,2020.10.29,,,METHOD AND DEVICE FOR GENERATING AN AUTONOMOUS DRIVING TRAJECTORY OF A VEHICLE,"G05D1/02,G05D1/00,B60W30/09,B60W30/095",WeRide Corp.,"A method and device for generating an autonomous driving trajectory of a vehicle are provided. The method comprises: acquiring information of an external environment wherein the vehicle is currently traveling; defining an envelope based on the information of the external environment, wherein the envelope defines a predicted travelable region of the vehicle in a subsequent predetermined time period; generating a reference path for the subsequent predetermined time period based on the envelope; and modifying the reference path based on a current lateral state of the vehicle or a road marker within the external environment, so as to generate the autonomous driving trajectory of the vehicle."
61,16911100,2020.06.24,20200326667,2020.10.15,20200326667,2020.10.15,,,ROBUST MULTIMODAL SENSOR FUSION FOR AUTONOMOUS DRIVING VEHICLES,"G05B13/02,G06N3/08,G06N7/00,G06N5/04,G06K9/62",Intel Corporation,"Techniques are disclosed for using neural network architectures to estimate predictive uncertainty measures, which quantify how much trust should be placed in the deep neural network (DNN) results. The techniques include measuring reliable uncertainty scores for a neural network, which are widely used in perception and decision-making tasks in automated driving. The uncertainty measurements are made with respect to both model uncertainty and data uncertainty, and may implement Bayesian neural networks or other types of neural networks."
62,16375610,2019.04.04,20200319636,2020.10.08,20200319636,2020.10.08,,,CONTROLLING DRIVING CONDITION COMPONENTS OF AN AUTONOMOUS VEHICLE BASED ON A CURRENT DRIVING MODE AND CURRENT CONDITIONS,"G05D1/00,B60W50/00,B60W10/30","TOYOTA RESEARCH INSTITUTE, INC.",A method for controlling a driving condition component of an autonomous vehicle is presented. The method includes determining whether current conditions would limit a driver's visibility. The method also includes predicting whether the driver will enable a manual mode during the current conditions. The method further includes controlling the driving condition component to mitigate the current conditions prior to the driver enabling the manual mode.
63,16731990,2019.12.31,20200250468,2020.08.06,10776673,2020.09.15,10776673,2020.09.15,"Learning method and learning device for sensor fusion to integrate information acquired by radar capable of distance estimation and information acquired by camera to thereby improve neural network for supporting autonomous driving, and testing method and testing device using the same","G06K9/00,G06K9/62,G01S13/86,G01S7/41,G01S13/931,G06N20/00,G06N7/00,G06T7/70","Stradvision, Inc.","A method for training a CNN by using a camera and a radar together, to thereby allow the CNN to perform properly even when an object depiction ratio of a photographed image acquired through the camera is low due to a bad condition of a photographing circumstance is provided. And the method includes steps of: (a) a learning device instructing a convolutional layer to apply a convolutional operation to a multichannel integrated image, to thereby generate a feature map; (b) the learning device instructing an output layer to apply an output operation to the feature map, to thereby generate estimated object information; and (c) the learning device instructing a loss layer to generate a loss by using the estimated object information and GT object information corresponding thereto, and to perform backpropagation by using the loss, to thereby learn at least part of parameters in the CNN."
64,16854546,2020.04.21,20200247399,2020.08.06,20200247399,2020.08.06,,,AUTONOMOUS DRIVING CONTROL APPARATUS AND AUTONOMOUS DRIVING CONTROL METHOD FOR VEHICLE,"B60W30/09,G05D1/02,B60W30/095,B60W60/00,B60W10/20,G08G1/16",DENSO CORPORATION,"An autonomous driving control apparatus installable in a vehicle includes a path determining section, an obstacle determining section that determines whether an obstacle on the planned driving path is a passage acceptable obstacle or a passage unacceptable obstacle, the passage acceptable obstacle being previously set as an obstacle that the vehicle is allowed to come into contact with while passing, the passage unacceptable obstacle being previously set as an obstacle that the vehicle is not allowed to come into contact with while passing, and a control instructing section that gives an instruction of control to a maneuver controller to perform at least one of controlling a speed of the vehicle and controlling a steering of the vehicle to control a maneuver of the vehicle. If the obstacle is determined to be the passage acceptable obstacle, the control instructing section gives an instruction of the control to pass over the obstacle."
65,16702799,2019.12.04,20200183391,2020.06.11,20200183391,2020.06.11,,,CONFIGURATION OF A CONTROL SYSTEM FOR AN AT LEAST PARTIALLY AUTONOMOUS TRANSPORTATION VEHICLE,"G05D1/00,G06N3/08,G05D1/02,G06N3/04,G06Q50/30","VOLKSWAGEN AKTIENGESELLSCHAFT,VOLKSWAGEN AKTIENGESELLSCHAFT","A method, a computer program with instructions, and an apparatus for configuring a control system for an at least partially autonomous transportation vehicle. Data relating to the driving situation are captured, selection criteria are then determined from the available data, two or more AI modules are selected from a library of AI modules during driving based on selection criteria, and combined execution of the selected two or more AI modules by the control system is initiated."
66,16405420,2019.05.07,20200166931,2020.05.28,20200166931,2020.05.28,,,APPARATUS AND METHOD FOR CONTROLLING AUTONOMOUS DRIVING OF A VEHICLE,"G05D1/00,G06K9/00","HYUNDAI MOTOR COMPANY,KIA MOTORS CORPORATION,HYUNDAI MOTOR COMPANY,KIA MOTORS CORPORATION","An apparatus for controlling autonomous driving of a vehicle includes a communication device configured to receive a first determination value, which is calculated based on information obtained as surroundings are sensed, from a surrounding vehicle or configured to receive a second determination value from a server. The apparatus includes a sensor configured to sense surroundings of a subject vehicle. The apparatus includes a controller configured to: calculate a third determination value based on information sensed by the sensor; to calculate a final determination value based on at least one of the first determination value and the second determination value, and the third determination value; and to control the autonomous driving by using the final determination value."
67,16681011,2019.11.12,20200079366,2020.03.12,20200079366,2020.03.12,,,AUTOMATIC DRIVING CONTROL SYSTEM FOR VEHICLE,"B60W30/09,B60W30/095,B60W30/18,B60W40/08,B60W10/20,G06K9/00,G08G1/16","DENSO CORPORATION,DENSO CORPORATION","An automatic driving control system includes power sources, a relay device changing connection states of the power sources, a relay control device controlling the relay device, a status recognizing unit recognizing a status of the own vehicle on a planned traveling route, and an automatic driving control unit controlling automatic driving. The status recognizing unit recognizes that a collision probability of a collision with an object during the automatic driving is a predetermined threshold or more, and also recognizes a damage-expected power source included in the power sources and expected to be damaged in a collision with the object. When the collision probability is the predetermined threshold or more, the automatic driving control unit instructs the relay control device to disconnect the damage-expected power source from particular auxiliary units and to connect, to the particular auxiliary units, a power source that is not the damage-expected power source."
68,16580201,2019.09.24,20200017115,2020.01.16,20200017115,2020.01.16,,,AUTONOMOUS DRIVING CONTROL SYSTEM FOR VEHICLE,"B60W50/038,B60W50/02,B60R16/023,G05D1/00,G07C5/08","DENSO CORPORATION,DENSO CORPORATION","An autonomous driving control system is configured to perform autonomous driving of a vehicle. The autonomous driving control system includes: an electric power supply circuit including a plurality of electric power supplies, electric power supply lines respectively belonging to a plurality of systems and a relay device; a fault detector configured to detect a fault state of the relay device; an electric power supply controller configured to control the electric power supply circuit; and an autonomous driving control unit provided to control the autonomous driving of the vehicle. The autonomous driving control unit is configured to perform, upon detection by the fault detector of occurrence of a fault corresponding to a specific fault pattern in the relay device, a restricted autonomous driving control in which part of a control function of the autonomous driving is restricted compared to when no fault corresponding to the specific fault pattern is detected."
69,16398900,2019.04.30,20190258246,2019.08.22,20190258246,2019.08.22,,,INTERVENTION IN OPERATION OF A VEHICLE HAVING AUTONOMOUS DRIVING CAPABILITIES,"G05D1/00,G07C5/08,G07C5/00",nuTonomy Inc.,"Among other things, a determination is made that intervention in an operation of one or more autonomous driving capabilities of a vehicle is appropriate. Based on the determination, a person is enabled to provide information for an intervention. The intervention is caused in the operation of the one or more autonomous driving capabilities of the vehicle."
70,16262289,2019.01.30,20190234745,2019.08.01,20190234745,2019.08.01,,,METHOD FOR ESTIMATING POSITION OF EGO VEHICLE FOR AUTONOMOUS DRIVING AND AUTONOMOUS DRIVING APPARATUS,G01C21/30,"ThorDrive, Inc.",The present invention relates to a method for estimating a position of an ego vehicle for autonomous driving including the steps of: receiving first sensor inputs from first sensors to extract visual road information; allowing the extracted visual road information to match first map data to produce a first matching score group; receiving second sensor inputs from second sensors; allowing the received second sensor inputs to match the second map data to produce a second matching score group; checking whether the first matching score group is consistent to the second matching score group; and estimating any one of the position candidates in the position candidate group of the ego vehicle as the position of the ego vehicle according to the consistency checking result.
71,16670575,2019.10.31,20210133947,2021.05.06,20210133947,2021.05.06,,,DEEP NEURAL NETWORK WITH IMAGE QUALITY AWARENESS FOR AUTONOMOUS DRIVING,"G06T7/00,G06K9/00,G05D1/00,G01S17/89,G01S17/87,G01S17/93,G05D1/02","Dalong Li,Stephen Horton,Neil R Garbacik","An autonomous driving technique comprises determining an image quality metric for each image frame of a series of image frames of a scene outside of a vehicle captured by a camera system and determining an image quality threshold based on the image quality metrics for the series of image frames. The technique then determines whether the image quality metric for a current image frame satisfies the image quality threshold. When the image quality metric for the current image frame satisfies the image quality threshold, object detection is performed by at least utilizing a first deep neural network (DNN) with the current image frame. When the image quality metric for the current image frame fails to satisfy the image quality threshold, object detection is performed by utilizing a second, different DNN with the information captured by another sensor system and without utilizing the first DNN or the current image frame."
72,16731066,2019.12.31,,,10636295,2020.04.28,10636295,2020.04.28,"Method and device for creating traffic scenario with domain adaptation on virtual driving environment for testing, validating, and training autonomous vehicle","G08G1/01,G06K9/00,G06N3/08,G06N3/04","STRADVISION, INC.","A method for creating a traffic scenario in a virtual driving environment is provided. The method includes steps of: a traffic scenario-generating device, (a) on condition that driving data have been acquired which are created using previous traffic data corresponding to discrete traffic data extracted by a vision-based ADAS from a past driving video and detailed traffic data corresponding to sequential traffic data from sensors of data-collecting vehicles in a real driving environment, inputting the driving data into a scene analyzer to extract driving environment information and into a vehicle information extractor to extract vehicle status information on an ego vehicle, and generating sequential traffic logs according to a driving sequence; and (b) inputting the sequential traffic logs into a scenario augmentation network to augment the sequential traffic logs using critical events, and generate the traffic scenario, verifying the traffic scenario, and mapping the traffic scenario onto a traffic simulator."
73,16729335,2019.12.28,20200130711,2020.04.30,20200130711,2020.04.30,,,"AUTONOMOUS VEHICLE SYSTEM FOR DETECTING SAFETY DRIVING MODEL COMPLIANCE STATUS OF ANOTHER VEHICLE, AND PLANNING ACCORDINGLY","B60W60/00,B60W30/095,B60W40/105,G05D1/00",Intel Corporation,"An Autonomous Vehicle (AV) system, including: a tracking subsystem configured to detect and track relative positioning of another vehicle that is behind or lateral to an AV configured to comply with a safety driving model, and to check a safety driving model compliance status of the other vehicle; and a risk reduction subsystem configured to plan, based on the safety driving model compliance status of the other vehicle, an AV action, wherein if the safety driving model compliance status of the other vehicle is unknown or is known to be non-compliant, the AV action is administration of a safety driving model compliance test to the other vehicle, or is a maneuver by the AV to reduce risk of collision with a leading vehicle positioned in front of the AV."
74,17515452,2021.10.30,20220051489,2022.02.17,20220051489,2022.02.17,,,AUTOMATIC DETECTION OF DATA FOR ANNOTATION FOR AUTONOMOUS VEHICLE PERCEPTION,"G07C5/00,G06K9/00,G05D1/02,G05B13/02,G05D1/00","GM Cruise Holdings, LLC","Various technologies described herein pertain to detecting sensor data to be annotated for autonomous vehicle perception algorithm training. A label identifying a type of an object is assigned to an object at a particular location in an environment based on sensor data generated by a sensor system of an autonomous vehicle for a given time. The label is assigned based on a confidence score assigned to the type of the object by a computer-implemented perception algorithm. The computer-implemented perception algorithm assigns the confidence score to the type of the object based on the sensor data corresponding to the particular location in the environment for the given time. An output of a heuristic is generated based on the label and/or the confidence score, and the output of the heuristic is used to control whether to cause the sensor data for the given time to be annotated."
75,16458005,2019.06.29,,,11164399,2021.11.02,11164399,2021.11.02,Automatic detection of data for annotation for autonomous vehicle perception,"G07C5/00,G05D1/02,G06K9/00,G05B13/02,G05D1/00",GM Cruise Holdings LLC,"Various technologies described herein pertain to detecting sensor data to be annotated for autonomous vehicle perception algorithm training. A label identifying a type of an object is assigned to an object at a particular location in an environment based on sensor data generated by a sensor system of an autonomous vehicle for a given time. The label is assigned based on a confidence score assigned to the type of the object by a computer-implemented perception algorithm. The computer-implemented perception algorithm assigns the confidence score to the type of the object based on the sensor data corresponding to the particular location in the environment for the given time. An output of a heuristic is generated based on the label and/or the confidence score, and the output of the heuristic is used to control whether to cause the sensor data for the given time to be annotated."
76,16458078,2019.06.30,,,11164400,2021.11.02,11164400,2021.11.02,Automatic detection of data for annotation for autonomous vehicle perception,"G05D1/00,G05D1/02,G05B13/02,G07C5/00,G06K9/00",GM Cruise Holdings LLC,"Various technologies described herein pertain to detecting sensor data to be annotated for autonomous vehicle perception algorithm training. A label identifying a type of an object is assigned to an object at a particular location in an environment based on sensor data generated by a sensor system of an autonomous vehicle for a given time. The label is assigned based on a confidence score assigned to the type of the object by a computer-implemented perception algorithm. The computer-implemented perception algorithm assigns the confidence score to the type of the object based on the sensor data corresponding to the particular location in the environment for the given time. An output of a heuristic is generated based on the label and/or the confidence score, and the output of the heuristic is used to control whether to cause the sensor data for the given time to be annotated."
77,16458078,2019.06.30,20200409364,2020.12.31,20200409364,2020.12.31,,,AUTOMATIC DETECTION OF DATA FOR ANNOTATION FOR AUTONOMOUS VEHICLE PERCEPTION,"G05D1/00,G05D1/02,G05B13/02",GM Cruise Holdings LLC,"Various technologies described herein pertain to detecting sensor data to be annotated for autonomous vehicle perception algorithm training. A label identifying a type of an object is assigned to an object at a particular location in an environment based on sensor data generated by a sensor system of an autonomous vehicle for a given time. The label is assigned based on a confidence score assigned to the type of the object by a computer-implemented perception algorithm. The computer-implemented perception algorithm assigns the confidence score to the type of the object based on the sensor data corresponding to the particular location in the environment for the given time. An output of a heuristic is generated based on the label and/or the confidence score, and the output of the heuristic is used to control whether to cause the sensor data for the given time to be annotated."
78,16458005,2019.06.29,20200410784,2020.12.31,20200410784,2020.12.31,,,AUTOMATIC DETECTION OF DATA FOR ANNOTATION FOR AUTONOMOUS VEHICLE PERCEPTION,"G07C5/00,G05D1/02,G06K9/00",GM Cruise Holdings LLC,"Various technologies described herein pertain to detecting sensor data to be annotated for autonomous vehicle perception algorithm training. A label identifying a type of an object is assigned to an object at a particular location in an environment based on sensor data generated by a sensor system of an autonomous vehicle for a given time. The label is assigned based on a confidence score assigned to the type of the object by a computer-implemented perception algorithm. The computer-implemented perception algorithm assigns the confidence score to the type of the object based on the sensor data corresponding to the particular location in the environment for the given time. An output of a heuristic is generated based on the label and/or the confidence score, and the output of the heuristic is used to control whether to cause the sensor data for the given time to be annotated."
79,16731085,2019.12.31,20200242479,2020.07.30,10872297,2020.12.22,10872297,2020.12.22,"Learning method and learning device for generating training data from virtual data on virtual world by using generative adversarial network, to thereby reduce annotation cost required in training processes of neural network for autonomous driving, and a testing method and a testing device using the same","G06N3/08,G06F16/58,G05D1/00,G06K9/00,G06K9/62","STRADVISION, INC.","A learning method for transforming a virtual video on a virtual world to a more real-looking video is provided. And the method includes steps of: (a) a learning device instructing a generating CNN to apply a convolutional operation to an N-th virtual training image, N-th meta data and (N-K)-th reference information to generate an N-th feature map; (b) the learning device instructing the generating CNN to apply a deconvolutional operation to the N-th feature map to generate an N-th transformed image; (c) the learning device instructing a discriminating CNN to apply a discriminating CNN operation to the N-th transformed image to generate a category score vector; (d) the learning device instructing the generating CNN to generate a generating CNN loss by referring to the category score vector and its corresponding GT, and to perform backpropagation by referring to the generating CNN loss to learn parameters of the generating CNN."
80,16721963,2019.12.20,,,10633007,2020.04.28,10633007,2020.04.28,Autonomous driving assistance glasses that assist in autonomous driving by recognizing humans` status and driving environment through image analysis based on deep neural network,"B60W50/14,G02B27/01,G06K9/00,G06T7/73,G06T7/10","STRADVISION, INC.","A method for providing safe-driving information via eyeglasses of a driver of a vehicle is provided. The method includes steps of: a safe-driving information analyzing device, (a) if a visual-dependent driving image, corresponding to a perspective of the driver, from a camera on the eyeglasses, acceleration information and gyroscope information from sensors are acquired, inputting the visual-dependent driving image into a convolution network to generate a feature map, and inputting the feature map into a detection network, a segmentation network, and a recognition network, to allow the detection network to detect an object, the segmentation network to detect lanes, and the recognition network to detect driving environment, inputting the acceleration information and the gyroscope information into a recurrent network to generate status information on the driver and (b) notifying the driver of information on a probability of a collision, lane departure information, and the driving environment, and giving a warning."
81,16388871,2019.04.19,,,11375041,2022.06.28,11375041,2022.06.28,Autonomous vehicle ad-hoc networking and data processing,"G06F15/173,H04L67/61,H04L43/0817,H04W28/24,H04L43/10,H04W28/02,H04W84/20,H04W80/12,H04L67/12,H04W4/40","SafeAI, Inc.","In one aspect, In one aspect, a method for data transfer and processing communications is provided. The method includes the step of providing a machine-to-everything (M2X) application layer on each machine of the plurality of machines. The method includes the step of providing a plurality of communication nodes on each machine for communication between the plurality of machines with every other machine, the plurality of machines and any infrastructure at a work site, and a plurality of communication nodes communicating using the at least one application layer. The method includes the step of providing a communication processing system for receiving a data transfer and processing communications. The communication processing system includes a plurality of processing stations, one or more multiple data management protocols, a plurality of network protocols, a plurality of databases and plurality of data processing network architectures."
82,16995973,2020.08.18,20210294341,2021.09.23,20210294341,2021.09.23,,,METHOD AND APPARATUS FOR GENERATING U-TURN PATH IN DEEP LEARNING-BASED AUTONOMOUS VEHICLE,"G05D1/02,G05D1/00,G06N3/08,G06N3/04","Hyundai Motor Company,Kia Motors Corporation","A method for generating a U-turn path in an autonomous vehicle includes calculating a drivable area, generating multiple paths drivable in the drivable area, filtering a driving strategy path among the multiple paths based on deep learning, and determining a final path from the filtered candidate paths."
83,16388871,2019.04.19,20200336565,2020.10.22,20200336565,2020.10.22,,,AUTONOMOUS VEHICLE AD-HOC NETWORKING AND DATA PROCESSING,"H04L29/08,H04L12/26,H04W28/24,H04W4/40,H04W84/20,H04W80/12,H04W28/02","SafeAl, Inc.,SafeAl, Inc.","In one aspect, In one aspect, a method for data transfer and processing communications is provided. The method includes the step of providing a machine-to-everything (M2X) application layer on each machine of the plurality of machines. The method includes the step of providing a plurality of communication nodes on each machine for communication between the plurality of machines with every other machine, the plurality of machines and any infrastructure at a work site, and a plurality of communication nodes communicating using the at least one application layer. The method includes the step of providing a communication processing system for receiving a data transfer and processing communications. The communication processing system includes a plurality of processing stations, one or more multiple data management protocols, a plurality of network protocols, a plurality of databases and plurality of data processing network architectures."
84,17071115,2020.10.15,20210114627,2021.04.22,20210114627,2021.04.22,,,NEURAL NETWORKS FOR NAVIGATION OF AUTONOMOUS VEHICLES BASED UPON PREDICTED HUMAN INTENTS,"B60W60/00,G06N3/04,G06K9/00","Perceptive Automata, Inc.","A system uses neural networks to determine intents of traffic entities (e.g., pedestrians, bicycles, vehicles) in an environment surrounding a vehicle (e.g., an autonomous vehicle) and generates commands to control the vehicle based on the determined intents. The system receives images of the environment captured by sensors on the vehicle, and processes the images using neural network models to determine overall intents or predicted actions of the one or more traffic entities within the images. The system generates commands to control the vehicle based on the determined overall intents of the traffic entities."
85,16458999,2019.07.01,20210001843,2021.01.07,20210001843,2021.01.07,,,NEURAL NETWORK WITH LANE AGGREGATION FOR LANE SELECTION PREDICTION OF MOVING OBJECTS DURING AUTONOMOUS DRIVING,"B60W30/095,G08G1/16,G06K9/00,G05D1/02,G06N3/08",Baidu USA LLC,"In one embodiment, an autonomous driving system of an ADV perceives a driving environment surrounding the ADV based on sensor data obtained from various sensors, including detecting one or more lanes and at least a moving obstacle or moving object. For each of the lanes identified, an NN lane feature encoder is applied to the lane information of the lane to extract a set of lane features. For a given moving obstacle, an NN obstacle feature encoder is applied to the obstacle information of the obstacle to extract a set of obstacle features. Thereafter, a lane selection predictive model is applied to the lane features of each lane and the obstacle features of the moving obstacle to predict which of the lanes the moving obstacle intends to select."
86,16564919,2019.09.09,20200370893,2020.11.26,20200370893,2020.11.26,,,DEVICE AND METHOD FOR COMPENSATING FOR ROUTE OF AUTONOMOUS VEHICLE,"G01C21/20,G01C21/34,G06N3/04,G05D1/00,G05D1/02,G08G1/0968","Hyundai Motor Company,Kia Motors Corporation","A device and a method for compensating a route of an autonomous vehicle are provided in which a normal route pattern for each section and abnormal route patterns for each section are learned based on a deep neural network (DNN). A compensated route pattern is obtained by changing a weighted value of each of a plurality of sensors for the abnormal route patterns for each section is learned, and the route of the autonomous vehicle is compensated based on the learning result to detect which sensor has an error when the route of the autonomous vehicle is abnormal."
87,17007648,2020.08.31,20220068050,2022.03.03,20220068050,2022.03.03,,,SYSTEM AND METHOD FOR MONITORING TEST DATA FOR AUTONOMOUS OPERATION OF SELF-DRIVING VEHICLES,"G07C5/08,G07C5/00,G05D1/02,G06F11/36","TOYOTA RESEARCH INSTITUTE, INC.,TOYOTA RESEARCH INSTITUTE, INC.","A method for autonomous vehicle test data distribution and analysis is described. The method includes uploading driving session data from a computer of a drive site to a network attached storage of the drive site. The method also includes uploading the driving session data from the network attached storage of the drive site to a cloud-based storage location. The method further includes distributing the driving session data from the cloud-based storage location and a work unit to at least one research site separate from the drive site. The method also includes processing, by the at least one research site, the driving session data according to an analysis/processing task associated with the work unit."
88,16457820,2019.06.28,,,11055540,2021.07.06,11055540,2021.07.06,Method for determining anchor boxes for training neural network object detection models for autonomous driving,"G06K9/00,G06K9/62",Baidu USA LLC,"In one embodiment, a set of bounding box candidates are plotted onto a 2D space based on their respective dimension (e.g., widths and heights). The bounding box candidates are clustered on the 2D space based on the distribution density of the bounding box candidates. For each of the clusters of the bounding box candidates, an anchor box is determined to represent the corresponding cluster. A neural network model is trained based on the anchor boxes representing the clusters. The neural network model is utilized to detect or recognize objects based on images and/or point clouds captured by a sensor (e.g., camera, LIDAR, and/or RADAR) of an autonomous driving vehicle."
89,16457820,2019.06.28,20200410252,2020.12.31,20200410252,2020.12.31,,,METHOD FOR DETERMINING ANCHOR BOXES FOR TRAINING NEURAL NETWORK OBJECT DETECTION MODELS FOR AUTONOMOUS DRIVING,"G06K9/00,G06K9/62",Baidu USA LLC,"In one embodiment, a set of bounding box candidates are plotted onto a 2D space based on their respective dimension (e.g., widths and heights). The bounding box candidates are clustered on the 2D space based on the distribution density of the bounding box candidates. For each of the clusters of the bounding box candidates, an anchor box is determined to represent the corresponding cluster. A neural network model is trained based on the anchor boxes representing the clusters. The neural network model is utilized to detect or recognize objects based on images and/or point clouds captured by a sensor (e.g., camera, LIDAR, and/or RADAR) of an autonomous driving vehicle."
90,16724428,2019.12.23,20200249671,2020.08.06,10831189,2020.11.10,10831189,2020.11.10,"Learning method and learning device for providing functional safety by warning driver about potential dangerous situation by using explainable AI which verifies detection processes of autonomous driving network, and testing method and testing device using the same","G06N3/08,G06N3/04,G06K9/46,G06K9/62,G05D1/00,G06K9/32","StradVision, Inc.","A learning method for providing a functional safety by warning a driver about a potential dangerous situation by using an explainable AI which verifies detection processes of a neural network for an autonomous driving is provided. And the learning method includes steps of: (a) a learning device for verification, if at least one training image for verification is acquired, instructing a property extraction module to apply extraction operation to the training image for verification to extract property information on characteristics of the training image for verification to thereby generate a quality vector; (b) the learning device for verification instructing the neural network for verification to apply first neural network operations to the quality vector, to thereby generate predicted safety information; and (c) the learning device for verification instructing a loss module to generate a loss, and perform a backpropagation by using the loss, to thereby learn parameters included in the neural network for verification."
91,16263168,2019.01.31,,,10423840,2019.09.24,10423840,2019.09.24,Post-processing method and device for detecting lanes to plan the drive path of autonomous vehicle by using segmentation score map and clustering map,"G06K9/00,G06T7/73,G06K9/62,G08G1/04,G08G1/16","Stradvision, Inc.","A post-processing method for detecting lanes to plan the drive path of an autonomous vehicle by using a segmentation score map and a clustering map is provided. The method includes steps of: a computing device acquiring the segmentation score map and the clustering map from a CNN; instructing a post-processing module to detect lane elements including pixels forming the lanes referring to the segmentation score map and generate seed information referring to the lane elements, the segmentation score map, and the clustering map; instructing the post-processing module to generate base models referring to the seed information and generate lane anchors referring to the base models; instructing the post-processing module to generate lane blobs referring to the lane anchors; and instructing the post-processing module to detect lane candidates referring to the lane blobs and generate a lane model by line-fitting operations on the lane candidates."
92,16263123,2019.01.31,,,10373004,2019.08.06,10373004,2019.08.06,"Method and device for detecting lane elements to plan the drive path of autonomous vehicle by using a horizontal filter mask, wherein the lane elements are unit regions including pixels of lanes in an input image","G06K9/00,G06T7/73,G08G1/16,G08G1/04","Stradvision, Inc.","A method for detecting lane elements, which are unit regions including pixels of lanes in an input image, to plan the drive path of an autonomous vehicle by using a horizontal filter mask is provided. The method includes steps of: a computing device acquiring a segmentation score map from a CNN using the input image; instructing a post-processing module, capable of performing data processing at an output end of the CNN, to generate a magnitude map by using the segmentation score map and the horizontal filter mask; instructing the post-processing module to determine each of lane element candidates per each of rows of the segmentation score map by referring to values of the magnitude map; and instructing the post-processing module to apply estimation operations to each of the lane element candidates per each of the rows, to thereby detect each of the lane elements."
93,16712287,2019.12.12,,,11372417,2022.06.28,11372417,2022.06.28,Method for predicting exiting intersection of moving obstacles for autonomous driving vehicles,"G05D1/02,G08G1/01,G05D1/00,G08G1/16,G06N3/04,G06N3/08",Baidu USA LLC,"A moving obstacle such as a vehicle within a proximity of an intersection and one or more exits of the intersection are identified. An obstacle state evolution of a spatial position of the moving obstacle over a period of time is determined. For each of the exits, an intersection exit encoding of the exit is determined based on intersection exit features of the exit. An aggregated exit encoding based on aggregating all of the intersection exit encodings for the exits is determined. For each of the exits, an exit probability of the exit that the moving obstacle likely exits the intersection through the exit is determined based on the obstacle state evolution and the aggregated exit encoding. Thereafter, a trajectory of the ADV is planned to control the ADV to avoid a collision with the moving obstacle based on the exit probabilities of the exits."
94,17644748,2021.12.16,20220107652,2022.04.07,20220107652,2022.04.07,,,DATA PIPELINE AND DEEP LEARNING SYSTEM FOR AUTONOMOUS DRIVING,"G05D1/02,G05D1/00,G06N3/04","Tesla, Inc.",An image captured using a sensor on a vehicle is received and decomposed into a plurality of component images. Each component image of the plurality of component images is provided as a different input to a different layer of a plurality of layers of an artificial neural network to determine a result. The result of the artificial neural network is used to at least in part autonomously operate the vehicle.
95,16712287,2019.12.12,20210181749,2021.06.17,20210181749,2021.06.17,,,METHOD FOR PREDICTING EXITING INTERSECTION OF MOVING OBSTACLES FOR AUTONOMOUS DRIVING VEHICLES,"G05D1/02,G08G1/01,G05D1/00,G08G1/16,G06N3/04,G06N3/08",Baidu USA LLC,"A moving obstacle such as a vehicle within a proximity of an intersection and one or more exits of the intersection are identified. An obstacle state evolution of a spatial position of the moving obstacle over a period of time is determined. For each of the exits, an intersection exit encoding of the exit is determined based on intersection exit features of the exit. An aggregated exit encoding based on aggregating all of the intersection exit encodings for the exits is determined. For each of the exits, an exit probability of the exit that the moving obstacle likely exits the intersection through the exit is determined based on the obstacle state evolution and the aggregated exit encoding. Thereafter, a trajectory of the ADV is planned to control the ADV to avoid a collision with the moving obstacle based on the exit probabilities of the exits."
96,16731093,2019.12.31,,,10650548,2020.05.12,10650548,2020.05.12,Method and device for localization of autonomous vehicle for route planning by using attention-driven landmark detection,"G06K9/00,G06T7/73,G01C21/36,G06N3/04,G06N3/08","STRADVISION, INC.","A method for detecting a location of a subject vehicle capable of an autonomous driving by using a landmark detection. And the method includes steps of: (a) a computing device, if a live feature map is acquired, detecting each of feature map coordinates on the live feature map per each of reference objects included in a subject data region corresponding to a location and a posture of the subject vehicle, by referring to (i) reference feature maps corresponding to the reference objects, and (ii) the live feature map; (b) the computing device detecting image coordinates of the reference objects on a live image by referring to the feature map coordinates; and (c) the computing device detecting an optimized subject coordinate of the subject vehicle by referring to 3-dimensional coordinates of the reference objects in a real world."
97,16831957,2020.03.27,,,11460847,2022.10.04,11460847,2022.10.04,"Controller for an autonomous vehicle, and network component","G05D1/02,B60W60/00,G01C21/34",Intel Corporation,"A controller for an autonomous vehicle may include: one or more processors configured to: determine a maneuver planned for the vehicle based on a safety driving model and based on a first message from a network component external to the vehicle, the first message including a respective assessment for each proposed maneuver of at least two maneuvers proposed for the vehicle, and provide an in-vehicle instruction to perform the maneuver planned for the vehicle."
98,17204287,2021.03.17,,,11157813,2021.10.26,11157813,2021.10.26,Method and device for on-vehicle active learning to be used for training perception network of autonomous vehicle,"G06N3/08,G06N3/04,G05D1/02","Stradvision, Inc.","A method of on-vehicle active learning for training a perception network of an autonomous vehicle is provided. The method includes steps of: an on-vehicle active learning device, (a) if a driving video and sensing information are acquired from a camera and sensors on an autonomous vehicle, inputting frames of the driving video and the sensing information into a scene code assigning module to generate scene codes including information on scenes in the frames and on driving events; and (b) at least one of selecting a part of the frames, whose object detection information satisfies a condition, as specific frames by using the scene codes and the object detection information and selecting a part of the frames, matching a training policy, as the specific frames by using the scene codes and the object detection information, and storing the specific frames and specific scene codes in a frame storing part."
99,17204287,2021.03.17,20210334652,2021.10.28,20210334652,2021.10.28,,,METHOD AND DEVICE FOR ON-VEHICLE ACTIVE LEARNING TO BE USED FOR TRAINING PERCEPTION NETWORK OF AUTONOMOUS VEHICLE,"G06N3/08,G06N3/04","Stradvision, Inc.","A method of on-vehicle active learning for training a perception network of an autonomous vehicle is provided. The method includes steps of: an on-vehicle active learning device, (a) if a driving video and sensing information are acquired from a camera and sensors on an autonomous vehicle, inputting frames of the driving video and the sensing information into a scene code assigning module to generate scene codes including information on scenes in the frames and on driving events; and (b) at least one of selecting a part of the frames, whose object detection information satisfies a condition, as specific frames by using the scene codes and the object detection information and selecting a part of the frames, matching a training policy, as the specific frames by using the scene codes and the object detection information, and storing the specific frames and specific scene codes in a frame storing part."
100,16831957,2020.03.27,20200249683,2020.08.06,20200249683,2020.08.06,,,"CONTROLLER FOR AN AUTONOMOUS VEHICLE, AND NETWORK COMPONENT","G05D1/02,G01C21/34,B60W60/00",Intel Corporation,"A controller for an autonomous vehicle may include: one or more processors configured to: determine a maneuver planned for the vehicle based on a safety driving model and based on a first message from a network component external to the vehicle, the first message including a respective assessment for each proposed maneuver of at least two maneuvers proposed for the vehicle, and provide an in-vehicle instruction to perform the maneuver planned for the vehicle."
101,16366120,2019.03.27,20190220003,2019.07.18,20190220003,2019.07.18,,,COLLABORATIVE 3-D ENVIRONMENT MAP FOR COMPUTER-ASSISTED OR AUTONOMOUS DRIVING VEHICLES,"G05D1/00,H04W4/46,G06N7/00,G06K9/62,G06K9/00",Intel Corporation,"Disclosures herein may be directed to a method, technique, or apparatus directed to a CA/AD that includes a system controller, disposed in a first CA/AD vehicle, to manage a collaborative three-dimensional (3-D) map of an environment around the first CA/AD vehicle, wherein the system controller is to receive, from another CA/AD vehicle proximate to the first CA/AD vehicle, an indication of at least a portion of another 3-D map of another environment around both the first CA/AD vehicle and the other CA/AD vehicle and incorporate the at least the portion of the 3-D map proximate to the first CA/AD vehicle and the other CA/AD vehicle into the 3-D map of the environment of the first CA/AD vehicle managed by the system controller."
102,17668492,2022.02.10,20220266831,2022.08.25,20220266831,2022.08.25,,,"METHOD, SYSTEM AND COMPUTER PROGRAM PRODUCT FOR AUTOMATICALLY ADAPTING AT LEAST ONE DRIVING ASSISTANCE FUNCTION OF A VEHICLE TO A TRAILER OPERATING STATE","B60W30/182,B60W30/12,B60W30/14,B60W30/16,B60W30/18,B60W10/20,B60W10/18,G06V20/56,G06V10/82,H04W4/44",Dr. Ing. h.c. F. Porsche Aktiengesellschaft,A method is provided for automatically adapting at least one driving assistance function of a vehicle to a trailer operating state of the vehicle. The method includes using at least one camera of a sensor and camera device for recording data in a recording region in which a trailer could be situated and communicating the data to an evaluation module. The method then includes evaluating the data using evaluation algorithms of the evaluation module for determining whether a trailer is connected to the vehicle and a trailer operating state thus exists. The method proceeds by communicating a trailer operating state from the evaluation module to at least one driving assistance module with at least one driving assistance function if a trailer operating state is determined. The method concludes using the driving assistance module for calculating a mode of the respective driving assistance function adapted to the trailer operating state.
103,17338359,2021.06.03,20210354726,2021.11.18,20210354726,2021.11.18,,,System and method for improving interaction of a plurality of autonomous vehicles with a driving environment including said vehicles,"B60W60/00,B60W40/09,B60W50/06","Huawei Technologies Co., Ltd.",The disclosure relates to technology for determining vehicle environment interaction metrics and/or passenger behavioral metrics for autonomous vehicles in a driving environment. A group of one or more autonomous vehicles independently determine a VEI score for a target vehicle within a predefined vicinity of the group of one or more vehicles. A target vehicle may determine a VPB score based on passengers within the target vehicle. VEI scores and/or VPB scores determined for a target vehicle may be used by the target vehicle to reinforce and/or correct driving actions of the target vehicle.
104,16599636,2019.10.11,20210107500,2021.04.15,20210107500,2021.04.15,,,Control of Autonomous Vehicles Adaptive to User Driving Preferences,"B60W50/08,B60W40/08","Mitsubishi Electric Research Laboratories, Inc.,Mitsubishi Electric Research Laboratories, Inc.","A system for controlling an autonomous vehicle includes a memory configured to store parameters of a g-g plot defining admissible space of values of longitudinal and lateral accelerations. The g-g plot parameters define a mapping between user driving preferences and constrained control of the autonomous vehicle. The g-g plot parameters include a maximum forward acceleration, a maximum backward acceleration, a maximum lateral acceleration and a shape parameter defining profile of curves connecting maximum values of forward, backward, and lateral accelerations. The system accepts a comfort level as a feedback from a passenger of the vehicle, determines a dominant parameter corresponding to the feedback, updates the dominant parameter of the g-g plot based on the comfort level indicated in the feedback, and controls the vehicle to maintain dynamics of the vehicle within the admissible space defined by the parameters of the updated g-g plot."
105,16724302,2019.12.22,20200250514,2020.08.06,10817777,2020.10.27,10817777,2020.10.27,"Learning method and learning device for integrating object detection information acquired through V2V communication from other autonomous vehicle with object detection information generated by present autonomous vehicle, and testing method and testing device using the same","G06N3/04,G06K9/00,G06K9/62,G06N3/08","STRADVISION, INC.","A learning method for generating integrated object detection information by integrating first object detection information and second object detection information is provided. And the method includes steps of: (a) a learning device instructing a concatenating network to generate one or more pair feature vectors; (b) the learning device instructing a determining network to apply FC operations to the pair feature vectors, to thereby generate (i) determination vectors and (ii) box regression vectors; (c) the learning device instructing a loss unit to generate an integrated loss by referring to the determination vectors, the box regression vectors and their corresponding GTs, and performing backpropagation processes by using the integrated loss, to thereby learn at least part of parameters included in the DNN."
106,16494738,2019.08.30,,,11488389,2022.11.01,11488389,2022.11.01,Verifying timing of sensors used in autonomous driving vehicles,"G06V20/56,B60W60/00,B60W50/04,G01S7/40","Baidu USA LLC,Baidu.com Times Technology (Beijing) Co., Ltd.","In some implementations, a method of verifying operation of a sensor is provided. The method includes causing a sensor to obtain sensor data at a first time, wherein the sensor obtains the sensor data by emitting waves towards a detector. The method also includes determining that the detector has detected the waves at a second time. The method further includes receiving the sensor data from the sensor at a third time. The method further includes verifying operation of the sensor based on at least one of the first time, the second time, or the third time."
107,16665650,2019.10.28,,,11423340,2022.08.23,11423340,2022.08.23,On-demand transport selection process facilitating third-party autonomous vehicles,"G06Q10/06,G01C21/34,G01C21/28,G06Q30/02","Uber Technologies, Inc.","A network computing system can coordinate on-demand transport serviced by transport providers operating throughout a transport service region. The transport providers can comprise a set of internal autonomous vehicles (AVs) and a set of third-party AVs. The system can receive a transport request from a requesting user of the transport service region, where the transport request indicates a pick-up location and a destination. The system can determine a subset of the transport providers to service the respective transport request, and executing a selection process among the subset of the transport providers to select a transport provider to service the transport request. The system may then transmit a transport assignment to the selected transport provider to cause the selected transport provider to service the transport request."
108,17696450,2022.03.16,20220340177,2022.10.27,20220340177,2022.10.27,,,SYSTEMS AND METHODS FOR COOPERATIVE DRIVING OF CONNECTED AUTONOMOUS VEHICLES IN SMART CITIES USING RESPONSIBILITY-SENSITIVE SAFETY RULES,"B60W60/00,B60W30/18","Arizona Board of Regents on Behalf of Arizona State University,National Taiwan University",Various embodiments for systems and methods for cooperative driving of connected autonomous vehicles using responsibility-sensitive safety (RSS) rules are disclosed herein. The CAV system integrates proposed RSS rules with CAV's motion planning algorithm to enable cooperative driving of CAVs. The CAV system further integrates a deadlock detection and resolution system for resolving traffic deadlocks between CAVs. The CAV system reduces redundant calculation of dependency graphs.
109,17148254,2021.01.13,20220219704,2022.07.14,20220219704,2022.07.14,,,AUDIO-BASED TECHNIQUE TO SENSE AND DETECT THE ROAD CONDITION FOR AUTONOMOUS DRIVING VEHICLES,"B60W40/068,B60W60/00,B60W30/14,H04R1/22,H04S7/00,G06N3/08",Baidu USA LLC,Sound signals are received by one or more microphones disposed at an ADV. The sound signals are analyzed to extract a feature of a road on which the ADV is driving. A road condition of the road is determined based on the extracted feature. A path planning and speed planning is performed to generate a trajectory based on the road condition. The ADV is controlled to drive autonomously according to the generated trajectory.
110,17152601,2021.01.19,20220227397,2022.07.21,20220227397,2022.07.21,,,DYNAMIC MODEL EVALUATION PACKAGE FOR AUTONOMOUS DRIVING VEHICLES,"B60W60/00,B60W30/18",Baidu USA LLC,"Disclosed are performance metrics for evaluating the accuracy of a dynamic model in predicting the trajectory of ADV when simulating the behavior of the ADV under the control commands. The performance metrics may indicate the degree of similarity between the predicted trajectory of the dynamic model and the actual trajectory of the vehicle when applied with identical control commands. The performance metrics measure deviations of the predicted trajectory of the dynamic model from the actual trajectory based on the ground truths. The performance metrics may include cumulative or mean absolute trajectory error, end-pose difference (ED), two-sigma defect rate (ε  2σ  ), the Hausdirff Distance (HAU), the longest common sub-sequence error (LCSS), or dynamic time warping (DTW). The two-sigma defect rate represents the ratio of the number of points with true location error falling out of the 2σ range of the predicted location error over the total number of points in the trajectory."
111,17229350,2021.04.13,,,11203361,2021.12.21,11203361,2021.12.21,Method for performing on-device learning of machine learning network on autonomous vehicle by using multi-stage learning with adaptive hyper-parameter sets and device using the same,"B60W60/00,G06K9/62,G06N20/00","Stradvision, Inc.","A method for performing on-device learning of embedded machine learning network of autonomous vehicle by using multi-stage learning with adaptive hyper-parameter sets is provided. The processes include: (a) dividing the current learning into a 1-st stage learning to an n-th stage learning, assigning 1-st stage training data to n-th stage training data, generating a 1_1-st hyper-parameter set candidate to a 1_h-th hyper-parameter set candidate, training the embedded machine learning network in the 1-st stage learning, and determining a 1-st adaptive hyper-parameter set; (b) generating a k_1-st hyper-parameter set candidate to a k_h-th hyper-parameter set candidate, training the (k−1)-th stage-completed machine learning network in the k-th stage learning, and determining a k-th adaptive hyper-parameter set; and (c) generating an n-th adaptive hyper-parameter set, and executing the n-th stage learning, to thereby complete the current learning."
112,16494738,2019.08.30,20210383133,2021.12.09,20210383133,2021.12.09,,,VERIFYING TIMING OF SENSORS USED IN AUTONOMOUS DRIVING VEHICLES,"G06K9/00,B60W60/00,B60W50/04","Baidu USA LLC,Baidu.com Times Technology (Beijing) Co., Ltd.","In some implementations, a method of verifying operation of a sensor is provided. The method includes causing a sensor to obtain sensor data at a first time, wherein the sensor obtains the sensor data by emitting waves towards a detector. The method also includes determining that the detector has detected the waves at a second time. The method further includes receiving the sensor data from the sensor at a third time. The method further includes verifying operation of the sensor based on at least one of the first time, the second time, or the third time."
113,16879305,2020.05.20,20210362749,2021.11.25,20210362749,2021.11.25,,,HARDWARE ACCELERATED NETWORK INTERFACE FOR AN AUTONOMOUS VEHICLE SWITCHED-NETWORK,"B60W60/00,G06K9/00,G01C21/34",GM Cruise Holdings LLC,"The subject disclosure relates to features that reduce computational overhead needed to transport sensor data through an autonomous vehicle (AV) network. In some aspects, a process of the disclosed technology includes steps for receiving a plurality of sensor packets at an accelerated AV network pipeline, extracting frame information associated with the plurality of sensor packets, and extracting payload data from the plurality of sensor packets based on the associated frame information to produce a plurality of de-capsulated sensor packets. Systems and machine-readable media are also provided."
114,16494735,2019.08.30,20210354719,2021.11.18,20210354719,2021.11.18,,,SYNCHRONIZING SENSORS OF AUTONOMOUS DRIVING VEHICLES,"B60W60/00,G06K9/00","Baidu USA LLC,Baidu.com Times Technology (Beijing) Co., Ltd.","In some implementations, a method is provided. The method includes determining a first set of data acquisition characteristics of a first sensor of an autonomous driving vehicle. The method also includes determining a second set of data acquisition characteristics of a second sensor of the autonomous driving vehicle. The method further includes synchronizing a first data acquisition time of the first sensor and a second data acquisition time of the second sensor, based on the first set of data acquisition characteristics and the second set of data acquisition characteristics. The first sensor obtains first sensor data at the first data acquisition time. The second sensor obtains second sensor data at the second data acquisition time."
115,17229350,2021.04.13,20210347379,2021.11.11,20210347379,2021.11.11,,,Method for Performing On-Device Learning of Machine Learning Network on Autonomous Vehicle by Using Multi-Stage Learning with Adaptive Hyper-Parameter Sets and Device Using the Same,"B60W60/00,G06K9/62,G06N20/00","Stradvision, Inc.","A method for performing on-device learning of embedded machine learning network of autonomous vehicle by using multi-stage learning with adaptive hyper-parameter sets is provided. The processes include: (a) dividing the current learning into a 1-st stage learning to an n-th stage learning, assigning 1-st stage training data to n-th stage training data, generating a 1_1-st hyper-parameter set candidate to a 1_h-th hyper-parameter set candidate, training the embedded machine learning network in the 1-st stage learning, and determining a 1-st adaptive hyper-parameter set; (b) generating a k_1-st hyper-parameter set candidate to a k_h-th hyper-parameter set candidate, training the (k−1)-th stage-completed machine learning network in the k-th stage learning, and determining a k-th adaptive hyper-parameter set; and (c) generating an n-th adaptive hyper-parameter set, and executing the n-th stage learning, to thereby complete the current learning."
116,17132578,2020.12.23,20210300418,2021.09.30,20210300418,2021.09.30,,,COLLABORATIVE SAFETY DRIVING MODEL FOR AUTONOMOUS VEHICLES,"B60W60/00,G08G1/16,G08G1/01,G05D1/02,B60W50/14,B60W30/18,H04W4/80,H04L29/08",Intel Corporation,"A system of a collaborative Autonomous Vehicle (AV) Safety Driving Model (SDM) system, including at least one processor; and a non-transitory computer-readable storage medium including instructions that, when executed by the at least one processor, cause the at least one processor to: generate, in response to a condition being satisfied, an SDM message including encoded data representing a warning or a safety parameter; and cause a transceiver to transmit the generated SDM message."
117,16274201,2019.02.12,,,11119492,2021.09.14,11119492,2021.09.14,Automatically responding to emergency service vehicles by an autonomous vehicle,"G05D1/02,G08G1/0965,G05D1/00,B60Q9/00","SF Motors, Inc.","An autonomous vehicle that automatically responds to an emergency service vehicle. Perception data is captured or received by the autonomous vehicle (AV) cameras, sensors, and microphones. The perception data is used to detect lanes in a road, generate a list of objects, classify one or more of the objects, and determine a state for the classified objects. In response to detecting an emergency service vehicle such as a law enforcement vehicle, a responsive action may be planned by the AV. The responsive action may include sending an acknowledgement signal, notifying passengers of the AV, generating a planned trajectory based on the emergency service vehicle location, an emergency service vehicle detected intention, and other information. A safety check may be performed, and commands may be generated by a control module to navigate the AV along the planned trajectory. The commands may then be executed by a DBW module."
118,16832802,2020.03.27,20210034065,2021.02.04,20210034065,2021.02.04,,,DRIVING SURFACE PROTRUSION PATTERN DETECTION FOR AUTONOMOUS VEHICLES,"G05D1/02,B60W40/06,G01C21/36",Intel Corporation,"A component of an Autonomous Vehicle (AV) system, the component having at least one processor; and a non-transitory computer-readable storage medium including instructions that, when executed by the at least one processor, cause the at least one processor to decode data encoded in a signal, wherein the data identifies a pattern of protrusions embedded in a driving surface, the signal being received from at least one vehicle sensor resulting from a vehicle driving over the pattern of protrusions in the driving surface."
119,16274201,2019.02.12,20200257299,2020.08.13,20200257299,2020.08.13,,,AUTOMATICALLY RESPONDING TO EMERGENCY SERVICE VEHICLES BY AN AUTONOMOUS VEHICLE,"G05D1/02,G08G1/0965,G05D1/00,B60Q9/00","SF Motors, Inc.,Chongqing Jinkang New Energy Vehicle, Ltd.,SF Motors, Inc.","An autonomous vehicle that automatically responds to an emergency service vehicle. Perception data is captured or received by the autonomous vehicle (AV) cameras, sensors, and microphones. The perception data is used to detect lanes in a road, generate a list of objects, classify one or more of the objects, and determine a state for the classified objects. In response to detecting an emergency service vehicle such as a law enforcement vehicle, a responsive action may be planned by the AV. The responsive action may include sending an acknowledgement signal, notifying passengers of the AV, generating a planned trajectory based on the emergency service vehicle location, an emergency service vehicle detected intention, and other information. A safety check may be performed, and commands may be generated by a control module to navigate the AV along the planned trajectory. The commands may then be executed by a DBW module."
120,16777386,2020.01.30,20200241545,2020.07.30,20200241545,2020.07.30,,,AUTOMATIC BRAKING OF AUTONOMOUS VEHICLES USING MACHINE LEARNING BASED PREDICTION OF BEHAVIOR OF A TRAFFIC ENTITY,"G05D1/02,B60W30/095,B60W30/09,G05D1/00,B60W40/09,G06N20/00","Perceptive Automata, Inc.","An autonomous vehicle uses machine learning based models to predict hidden context attributes associated with traffic entities. The system uses the hidden context to predict behavior of people near a vehicle in a way that more closely resembles how human drivers would judge the behavior. The system determines an activation threshold value for a braking system of the autonomous vehicle based on the hidden context. The system modifies a world model based on the hidden context predicted by the machine learning based model. The autonomous vehicle is safely navigated, such that the vehicle stays at least a threshold distance away from traffic entities."
121,16665650,2019.10.28,20200134525,2020.04.30,20200134525,2020.04.30,,,On-Demand Transport Selection Process Facilitating Third-Party Autonomous Vehicles,"G06Q10/06,G06Q30/02,G01C21/28,G01C21/34","UATC, LLC","A network computing system can coordinate on-demand transport serviced by transport providers operating throughout a transport service region. The transport providers can comprise a set of internal autonomous vehicles (AVs) and a set of third-party AVs. The system can receive a transport request from a requesting user of the transport service region, where the transport request indicates a pick-up location and a destination. The system can determine a subset of the transport providers to service the respective transport request, and executing a selection process among the subset of the transport providers to select a transport provider to service the transport request. The system may then transmit a transport assignment to the selected transport provider to cause the selected transport provider to service the transport request."
122,16831095,2020.03.26,20210300393,2021.09.30,20210300393,2021.09.30,,,AUTOMATIC TESTING OF AUTONOMOUS VEHICLES,"B60W50/04,G07C5/00,G07C5/08,G06N20/00",GM Cruise Holdings LLC,"The present technology is effective to cause at least one processor to instruct an autonomous vehicle to navigate a specific course and to record diagnostic measurements while navigating the specific course, receive the diagnostic measurements from the autonomous vehicle, and analyze the diagnostic measurements from the autonomous vehicle in a context provided by a collection of diagnostic measurement data collected from a fleet of similar autonomous vehicles navigating the specific course."
123,17064890,2020.10.07,20210018924,2021.01.21,20210018924,2021.01.21,,,"POWER MANAGEMENT, DYNAMIC ROUTING AND MEMORY MANAGEMENT FOR AUTONOMOUS DRIVING VEHICLES","G05D1/02,G05D1/00,B60L58/12","Micron Technology, Inc.","The invention relates to a system and method for navigating an autonomous driving vehicle (ADV) that utilizes an-onboard computer and/or one or more ADV control system nodes in an ADV network platform. The on-board computer receives battery monitoring and management data concerning a battery stack. The on-board computer, utilizing a battery management system, determines the current state of charge (SOC) and other information concerning the battery stack and determines if the estimated total amount of electrical power required to navigate an ADV along a generated route to reach the predetermined destination is available. In response to determining that the ADV cannot reach the predetermined destination, the on-board computer automatically initiates a dynamic routing algorithm, which utilizes artificial intelligence, to generate alternative routes in an effort to find a route that the ADV can navigate to reach the destination utilizing the current state of charge (SOC) of the battery stack."
124,17610101,2020.04.08,20220227379,2022.07.21,20220227379,2022.07.21,,,NETWORK FOR DETECTING EDGE CASES FOR USE IN TRAINING AUTONOMOUS VEHICLE CONTROL SYSTEMS,"B60W50/04,B60W50/02,B60W60/00,B60W40/09,B60W40/02,G06N3/08",LGN Innovations Limited,"Embodiments relate to the detection of edge cases through application of a neural network to predict future vehicle environment data and identifying an edge case when the prediction error exceeds a given threshold. This allows edge cases to be identified based on unexpected vehicle environmental conditions or conditions that otherwise cause the neural network to make inaccurate predictions. These edge cases can then be utilised to better train machine learning systems, for instance, to train autonomous vehicle control systems. Alternatively, the identification of an edge case can highlight the need for remedial action, and can therefore trigger an alert to a vehicle control system to take remedial action. Further methods and systems described herein improve environmental sensing by providing a computationally efficient and accurate means for fusing sensor data and using this fused data to control sensors to focus on areas that would most reduce the uncertainty in the sensing system."
125,16389360,2019.04.19,,,11222389,2022.01.11,11222389,2022.01.11,Coordinating on-demand transportation with autonomous vehicles,"G06Q50/30,G08G1/00,G05D1/00","Uber Technologies, Inc.","An on-demand transport facilitation system can receive transport requests from requesting users throughout a given region, and select autonomous vehicles (AVs) and human driver to service the transport requests. The AV can operate on a mapped and labeled autonomy grid within the given region. For a given transport request, the transport system can determine an optimal pick-up location along the autonomy grid based on the current location of the requesting user and a current location of a selected AV, and transmit data indicating walking directions from the current location of the requesting user to the optimal pick-up location. The transport system may then coordinate the rendezvous by monitoring progress made by the requesting user and AV to the optimal pick-up location, and controlling the pace of the AV."
126,16399457,2019.04.30,,,11182623,2021.11.23,11182623,2021.11.23,Flexible hardware design for camera calibration and image pre-procesing in autonomous driving vehicles,"G06K9/00,G05D1/02,G06K9/54,G05D1/00",Baidu USA LLC,"A sensor unit includes a sensor interface, host interface, and pre-processing hardware. The sensor interface is coupled to a plurality of cameras configured to capture images around an autonomous driving vehicle (ADV). The host interface is coupled to a perception and planning system. The pre-processing hardware is coupled to the sensor interface to receive images from the plurality of cameras and to perform one or more pre-processing functions on the images and to transmit pre-processed images to the perception and planning system via the host interface. The perception and planning system is configured to perceive a driving environment surrounding the ADV based on the pre-processed images and to plan a path to control the ADV to navigate through the driving environment. The pre-processing functions can adjust for different calibrations and formats across the plurality of cameras."
127,16830090,2020.03.25,20210300427,2021.09.30,20210300427,2021.09.30,,,GROUP AND COMBINE OBSTACLES FOR AUTONOMOUS DRIVING VEHICLES,"B60W60/00,G05D1/00,G05D1/02,B60W30/09",Baidu USA LLC,"In one embodiment, a plurality of obstacles is sensed in an environment of an automated driving vehicle (ADV). One or more representations are formed to represent corresponding groupings of the plurality of obstacles. A vehicle route is determined in view of the one or more representations, rather than each and every one of the obstacles individually."
128,16678387,2019.11.08,20210139022,2021.05.13,20210139022,2021.05.13,,,DELAY DECISION MAKING FOR AUTONOMOUS DRIVING VEHICLES IN RESPONSE TO OBSTACLES BASED ON CONFIDENCE LEVEL AND DISTANCE,"B60W30/095,B60W30/09,B60W30/18,G05D1/00,G06K9/00",Baidu USA LLC,"In one embodiment, a process is performed during controlling Autonomous Driving Vehicle (ADV). A confidence level associated with a sensed obstacle is determined. If the confidence level is below a confidence threshold, and a distance between the ADV and a potential point of contact with the sensed obstacle is below a distance threshold, then performance of a driving decision is delayed. Otherwise, the driving decision is performed to reduce risk of contact with the sensed obstacle."
129,17073808,2020.10.19,20210048826,2021.02.18,20210048826,2021.02.18,,,"DEEP LEARNING-BASED AUTONOMOUS VEHICLE CONTROL DEVICE, SYSTEM INCLUDING THE SAME, AND METHOD THEREOF","G05D1/02,G05B23/02,G06N3/04","HYUNDAI MOTOR COMPANY,KIA MOTORS CORPORATION","A deep learning-based autonomous vehicle control system includes: a processor determining an autonomous driving control based on deep learning, correcting an error in determination of the deep learning-based autonomous driving control based on determination of an autonomous driving control based on a predetermined expert rule, and controlling an autonomous vehicle; and a non-transitory computer-readable storage medium storing data for the determination of the deep learning-based autonomous driving control, data for the determination of the expert rule-based autonomous driving control, and information about the error in the determination of the deep learning-based autonomous driving control."
130,16376569,2019.04.05,20190227564,2019.07.25,10915110,2021.02.09,10915110,2021.02.09,Motor vehicle control apparatus and method for operating a control apparatus for autonomously driving a motor vehicle,"G05D1/02,B60W30/16,B62D15/02,B60W30/10,B60W30/14,B60W30/18,B60K31/00,G01S13/931",VOLKSWAGEN AG,"A method for operating a control device for the autonomous guidance of a motor vehicle, wherein a nominal speed is predetermined as a driving speed to be set by the control device and another vehicle driving in front more slowly than the nominal speed is detected by a detection device of the control device, wherein a speed difference of a driving speed of the other vehicle with respect to the nominal speed is greater than zero but smaller than a predetermined maximum value. In this case, an accumulator value is set to a starting value and a current speed value of the speed difference is detected and depending on the speed value, an advantage value is formed and the advantage value is added to the accumulator value. If the accumulator value meets a predetermined overtaking criterion, an overtaking signal is generated for allowing an overtaking maneuver."
131,17073813,2020.10.19,20210034064,2021.02.04,20210034064,2021.02.04,,,"DEEP LEARNING-BASED AUTONOMOUS VEHICLE CONTROL DEVICE, SYSTEM INCLUDIG THE SAME, AND METHOD THEREOF","G05D1/02,G05B23/02,G06N3/04","HYUNDAI MOTOR COMPANY,KIA MOTORS CORPORATION","A deep learning-based autonomous vehicle control system includes: a processor determining an autonomous driving control based on deep learning, correcting an error in determination of the deep learning-based autonomous driving control based on determination of an autonomous driving control based on a predetermined expert rule, and controlling an autonomous vehicle; and a non-transitory computer-readable storage medium storing data for the determination of the deep learning-based autonomous driving control, data for the determination of the expert rule-based autonomous driving control, and information about the error in the determination of the deep learning-based autonomous driving control."
132,16522515,2019.07.25,20210027629,2021.01.28,20210027629,2021.01.28,,,BLIND AREA PROCESSING FOR AUTONOMOUS DRIVING VEHICLES,"G08G1/16,G05D1/00,G05D1/02,G08G1/01,G08G1/052",Baidu USA LLC,"According to one embodiment, a driving environment surrounding an ADV is perceived based on sensor data obtained from various sensors mounted on the ADV including detecting one or more obstacles. The obstacles of the detected obstacles are determined and tracked based on the perception process, where the obstacle states of the obstacles may be maintained in an obstacle state buffer associated with the obstacles. When it is detected that a first moving obstacle is blocked by an object by the sensors, the further movement of the first moving obstacle is predicted based on the prior obstacle states of the first moving obstacle, while the first moving obstacle is blocked in view by the object. A trajectory is planned for the ADV in view of the predicted movement of the first moving obstacle while the first moving obstacle is in the blind area."
133,16460192,2019.07.02,20210004643,2021.01.07,20210004643,2021.01.07,,,METHOD FOR AUTOMATICALLY LABELING OBJECTS IN PAST FRAMES BASED ON OBJECT DETECTION OF A CURRENT FRAME FOR AUTONOMOUS DRIVING,"G06K9/62,G06K9/00",Baidu USA LLC,"A list of images is received. The images were captured by a sensor of an ADV chronologically while driving through a driving environment. A first image of the images is identified that includes a first object in a first dimension (e.g., larger size) detected by an object detector using an object detection algorithm. In response to the detection of the first object, the images in the list are traversed backwardly in time from the first image to identify a second image that includes a second object in a second dimension (e.g., smaller size) based on a moving trail of the ADV represented by the list of images. The second object is then labeled or annotated in the second image equivalent to the first object in the first image. The list of images having the labeled second image can be utilized for subsequent object detection during autonomous driving."
134,16457847,2019.06.28,20200406893,2020.12.31,20200406893,2020.12.31,,,METHOD FOR AUTONOMOUSLY DRIVING A VEHICLE BASED ON MOVING TRAILS OF OBSTACLES SURROUNDING THE VEHICLE,"B60W30/095,B60W30/09,G06K9/00,G05D1/00",Baidu USA LLC,"During the autonomous driving, the movement trails or moving history of obstacles, as well as, an autonomous driving vehicle (ADV) may be maintained in a corresponding buffer. For each of the obstacles or objects and the ADV, the vehicle states at different points in time are maintained and stored in one or more buffers. The vehicle states representing the moving trails or moving history of the obstacles and the ADV may be utilized to reconstruct a history trajectory of the obstacles and the ADV, which may be used for a variety of purposes. For example, the moving trails or history of obstacles may be utilized to determine lane configuration of one or more lanes of a road, particularly, in a rural area where the lane markings are unclear. The moving history of the obstacles may also be utilized predict the future movement of the obstacles, tailgate an obstacle, and infer a lane line."
135,16738320,2020.01.09,20200249675,2020.08.06,10824151,2020.11.03,10824151,2020.11.03,Method and device for providing personalized and calibrated adaptive deep learning model for the user of an autonomous vehicle,"G05D1/00,B60W60/00,B60W50/00,G06K9/62,G06N20/00","StradVision, Inc.","A method for providing a dynamic adaptive deep learning model other than a fixed deep learning model, to thereby support at least one specific autonomous vehicle to perform a proper autonomous driving according to surrounding circumstances is provided. And the method includes steps of: (a) a managing device which interworks with autonomous vehicles instructing a fine-tuning system to acquire a specific deep learning model to be updated; (b) the managing device inputting video data and its corresponding labeled data to the fine-tuning system as training data, to thereby update the specific deep learning model; and (c) the managing device instructing an automatic updating system to transmit the updated specific deep learning model to the specific autonomous vehicle, to thereby support the specific autonomous vehicle to perform the autonomous driving by using the updated specific deep learning model other than a legacy deep learning model."
136,16399457,2019.04.30,20200349361,2020.11.05,20200349361,2020.11.05,,,FLEXIBLE HARDWARE DESIGN FOR CAMERA CALIBRATION AND IMAGE PRE-PROCESING IN AUTONOMOUS DRIVING VEHICLES,"G06K9/00,G05D1/02,G05D1/00,G06K9/54",Baidu USA LLC,"Flexible hardware designs for camera calibration and image pre-processing are disclosed for vehicles including autonomous driving (AD) vehicles. For one example, a sensor unit includes a sensor interface, host interface, and pre-processing hardware. The sensor interface is coupled to a plurality of cameras configured to capture images around an autonomous driving vehicle (ADV). The host interface is coupled to a perception and planning system. The pre-processing hardware is coupled to the sensor interface to receive images from the plurality of cameras and to perform one or more pre-processing functions on the images and to transmit pre-processed images to the perception and planning system via the host interface. The perception and planning system is configured to perceive a driving environment surrounding the ADV based on the pre-processed images and to plan a path to control the ADV to navigate through the driving environment. The pre-processing functions can adjust for different calibrations and formats across the plurality of cameras."
137,16712918,2019.12.12,20200193368,2020.06.18,20200193368,2020.06.18,,,TRANSPORTING OBJECTS USING AUTONOMOUS VEHICLES,"G06Q10/08,G06Q50/30,H04W4/021,H04W4/40,B60R25/10,G06Q10/02,B60R25/25",Aptiv Technologies Limited,"Techniques are disclosed for transporting objects using autonomous vehicles. In an embodiment, a customer makes a reservation with a transportation service provider (e.g., via an online booking application). The customer provides a pick-up date/pick-up time window, a destination and a description of the object(s) (e.g., luggage/cargo) that the customer will be transporting with or without themselves in the autonomous vehicle. After the computer system identifies the physical characteristics of the object(s), it identifies an autonomous vehicle with the appropriate amount of storage/container space with respect to the identified physical characteristics, and then assigns the vehicle to the customer. On or around the pick-up day, the computer system configures the assigned autonomous vehicle with reservation details including a description of the objects. At the pick-up location, sensors are used to authenticate/identify/localize/track each passenger and their respective objects, and to determine if any object is unsafe or illegal to transport."
138,16263511,2019.01.31,,,10503174,2019.12.10,10503174,2019.12.10,"Method and device for optimized resource allocation in autonomous driving on the basis of reinforcement learning using data from lidar, radar, and camera sensor","G05D1/02,G06T7/521,G01S13/93,G01S17/93,B60R11/04,G06N3/08","Stradvision, Inc.","A method for efficient resource allocation in autonomous driving by reinforcement learning is provided for reducing computation via a heterogeneous sensor fusion. This attention-based method includes steps of: a computing device instructing an attention network to perform a neural network operation by referring to attention sensor data, to calculate attention scores; instructing a detection network to acquire video data by referring to the attention scores and to generate decision data for the autonomous driving; instructing a drive network to operate the autonomous vehicle by referring to the decision data, to acquire circumstance data, and to generate a reward by referring to the circumstance data; and instructing the attention network to adjust parameters used for the neural network operation by referring to the reward. Thus, a virtual space where the autonomous vehicle optimizes the resource allocation can be provided by the method."
139,16389360,2019.04.19,20190244320,2019.08.08,20190244320,2019.08.08,,,Coordinating On-Demand Transportation with Autonomous Vehicles,"G06Q50/30,G05D1/00","Uber Technologies, Inc.","An on-demand transport facilitation system can receive transport requests from requesting users throughout a given region, and select autonomous vehicles (AVs) and human driver to service the transport requests. The AV can operate on a mapped and labeled autonomy grid within the given region. For a given transport request, the transport system can determine an optimal pick-up location along the autonomy grid based on the current location of the requesting user and a current location of a selected AV, and transmit data indicating walking directions from the current location of the requesting user to the optimal pick-up location. The transport system may then coordinate the rendezvous by monitoring progress made by the requesting user and AV to the optimal pick-up location, and controlling the pace of the AV."
140,17645725,2021.12.22,20220111870,2022.04.14,20220111870,2022.04.14,,,SYSTEMS AND METHODS FOR BROKERING PEER-ASSISTED SAFETY MODELS FOR AUTONOMOUS AND ASSISTED-DRIVING VEHICLES,B60W60/00,"Amar Srivastava,Christian Maciocco,Kshitij Arun Doshi,Ignacio J. Alvarez","Disclosed herein are systems and methods for peer-assisted safety models for autonomous and assisted-driving vehicles. In an embodiment, a safety-model service receives a safety-model request for a safety model from a target vehicle. The safety-model service identifies, responsive to receiving the safety-model request, one or more source vehicles as safety-model input sources. The safety-model service receives safety-model data associated with the identified one or more source vehicles. The safety-model service generates, based on the safety-model request and the received safety-model data, a target-vehicle safety model for the target vehicle. The safety-model service transmits the target-vehicle safety model to the target vehicle for use by the target vehicle."
141,17479197,2021.09.20,,,11400958,2022.08.02,11400958,2022.08.02,Learning to identify safety-critical scenarios for an autonomous vehicle,"B60W60/00,B60W50/02,G06N3/08,G06V20/56,B60W50/00",Motional AD LLC,"Provided are methods for learning to identify safety-critical scenarios for autonomous vehicles. First state information representing a first state of a driving scenario is received. The information includes a state of a vehicle and a state of an agent in the vehicle's environment. The first state information is processed with a neural network to determine at least one action to be performed by the agent, including a perception degradation action causing misperception of the agent by a perception system of the vehicle. Second state information representing a second state of the driving scenario is received after performance of the at least one action. A reward for the action is determined. First and second distances between the vehicle and the agent are determined and compared to determine the reward for the at least one action. At least one weight of the neural network is adjusted based on the reward."
142,17593618,2019.10.24,20220196414,2022.06.23,20220196414,2022.06.23,,,GLOBAL PATH PLANNING METHOD AND DEVICE FOR AN UNMANNED VEHICLE,"G01C21/34,G05B13/02","GOERTEK INC.,GOERTEK INC.","A global path planning method and device for an unmanned vehicle are disclosed. The method comprises: establishing an object model through a reinforcement learning method, wherein the object model includes: a state of the unmanned vehicle, an environmental state described by a map picture, and an evaluation index of a path planning result; building a deep reinforcement learning neural network based on the object model established, to obtain a stable neural network model; inputting the map picture of the environment state and the state of the unmanned vehicle into the deep reinforcement learning neural network after trained, and generating a motion path of the unmanned vehicle. According to the present disclosure, the environment information in the scene is marked through the map picture, and the map features are extracted through the deep neural network, thereby simplifying the modeling process of the map scene."
143,17491453,2021.09.30,20220019221,2022.01.20,20220019221,2022.01.20,,,AUTONOMOUS VEHICLE CONTROLLED BASED UPON A LIDAR DATA SEGMENTATION SYSTEM,"G05D1/00,B60W10/18,G05D1/02,B60W10/20,G06N3/08,B60W10/06,G01S17/931",GM GLOBAL TECHNOLOGY OPERATIONS LLC,"An autonomous vehicle is described herein. The autonomous vehicle includes a lidar sensor system. The autonomous vehicle additionally includes a computing system that executes a lidar segmentation system, wherein the lidar segmentation system is configured to identify objects that are in proximity to the autonomous vehicle based upon output of the lidar sensor system. The computing system further includes a deep neural network (DNN), where the lidar segmentation system identifies the objects in proximity to the autonomous vehicle based upon output of the DNN."
144,17226123,2021.04.09,20210223402,2021.07.22,20210223402,2021.07.22,,,AUTONOMOUS VEHICLE CONTROLLED BASED UPON A LIDAR DATA SEGMENTATION SYSTEM,"G01S17/931,G06K9/62,G05D1/00,G06N3/02,G06K9/00,G05D1/02",GM GLOBAL TECHNOLOGY OPERATIONS LLC,"An autonomous vehicle is described herein. The autonomous vehicle includes a lidar sensor system. The autonomous vehicle additionally includes a computing system that executes a lidar segmentation system, wherein the lidar segmentation system is configured to identify objects that are in proximity to the autonomous vehicle based upon output of the lidar sensor system. The computing system further includes a deep neural network (DNN), where the lidar segmentation system identifies the objects in proximity to the autonomous vehicle based upon output of the DNN."
145,16732053,2019.12.31,20200250450,2020.08.06,10776647,2020.09.15,10776647,2020.09.15,Method and device for attention-driven resource allocation by using AVM to thereby achieve safety of autonomous driving,"G06K9/00,G06K9/62,G06N3/08,G06K9/32,G05D1/02,G06K9/20","Stradvision, Inc.","A method for achieving better performance in an autonomous driving while saving computing powers, by using confidence scores representing a credibility of an object detection which is generated in parallel with an object detection process is provided. And the method includes steps of: (a) a computing device acquiring at least one circumstance image on surroundings of a subject vehicle, through at least one panorama view sensor installed on the subject vehicle; (b) the computing device instructing a Convolutional Neural Network (CNN) to apply at least one CNN operation to the circumstance image, to thereby generate initial object information and initial confidence information on the circumstance image; and (c) the computing device generating final object information on the circumstance image by referring to the initial object information and the initial confidence information."
146,16739767,2020.01.10,20200250442,2020.08.06,20200250442,2020.08.06,,,METHOD AND DEVICE FOR ATTENTION-DRIVEN RESOURCE ALLOCATION BY USING AVM AND REINFORCEMENT LEARNING TO THEREBY ACHIEVE SAFETY OF AUTONOMOUS DRIVING,"G06K9/00,G06N3/04,G06K9/62,G06N3/08,G06F17/18,G06T7/70","Stradvision, Inc.","A method for achieving better performance in an autonomous driving while saving computing powers, by using confidence scores representing a credibility of an object detection which is generated in parallel with an object detection process is provided. And the method includes steps of: (a) a computing device acquiring at least one circumstance image on surroundings of a subject vehicle, through at least one panorama view sensor installed on the subject vehicle; (b) the computing device instructing a Convolutional Neural Network (CNN) to apply at least one CNN operation to the circumstance image, to thereby generate initial object information and initial confidence information on the circumstance image; and (c) the computing device generating final object information on the circumstance image by referring to the initial object information and the initial confidence information, with a support of an RL agent."
147,16739767,2020.01.10,,,10726279,2020.07.28,10726279,2020.07.28,Method and device for attention-driven resource allocation by using AVM and reinforcement learning to thereby achieve safety of autonomous driving,"G06K9/00,G06N3/04,G06K9/62,G06F17/18,G06T7/70,G06N3/08","Stradvision, Inc.","A method for achieving better performance in an autonomous driving while saving computing powers, by using confidence scores representing a credibility of an object detection which is generated in parallel with an object detection process is provided. And the method includes steps of: (a) a computing device acquiring at least one circumstance image on surroundings of a subject vehicle, through at least one panorama view sensor installed on the subject vehicle; (b) the computing device instructing a Convolutional Neural Network(CNN) to apply at least one CNN operation to the circumstance image, to thereby generate initial object information and initial confidence information on the circumstance image; and (c) the computing device generating final object information on the circumstance image by referring to the initial object information and the initial confidence information, with a support of an RL agent."
148,17093909,2020.11.10,20210300430,2021.09.30,20210300430,2021.09.30,,,APPARATUS FOR SWITCHING CONTROL AUTHORITY OF AUTONOMOUS VEHICLE AND METHOD THEREOF,"B60W60/00,B60W40/09,B60W30/18,G06N20/00","Hyundai Motor Company,Kia Motors Corporation","An apparatus for switching driving control authority of an autonomous vehicle and a method thereof are provided to deeply learn a normal driving pattern of the autonomous vehicle corresponding to a driving situation, detect a matching degree of the driving pattern of a driver based on the deep learning result, and determine whether to retrieve the driving control authority of the driver corresponding to the detected matching degree. Accordingly, the driving control authority of the driver is retrieved to prevent an accident in advance even if there is no request to activate an autonomous driving mode of the driver."
149,16852827,2020.04.20,,,11091161,2021.08.17,11091161,2021.08.17,Apparatus for controlling lane change of autonomous vehicle and method thereof,"B60W30/18,B60W30/095,B60W60/00,B60W40/04,G06K9/00,G07C5/08,G05D1/02","HYUNDAI MOTOR COMPANY,KIA MOTORS CORPORATION","An apparatus for controlling a lane change of an autonomous vehicle and a method thereof. The apparatus includes a learning device that performs deep learning by subdividing situation information into groups to be considered when the autonomous vehicle changes a lane, and a controller that controls the lane change of the autonomous vehicle based on a learning result of the learning device."
150,16852827,2020.04.20,20210107487,2021.04.15,20210107487,2021.04.15,,,APPARATUS FOR CONTROLLING LANE CHANGE OF AUTONOMOUS VEHICLE AND METHOD THEREOF,"B60W30/18,B60W30/095,B60W60/00,B60W40/04,G05D1/02,G06K9/00,G07C5/08","HYUNDAI MOTOR COMPANY,KIA MOTORS CORPORATION","An apparatus for controlling a lane change of an autonomous vehicle and a method thereof. The apparatus includes a learning device that performs deep learning by subdividing situation information into groups to be considered when the autonomous vehicle changes a lane, and a controller that controls the lane change of the autonomous vehicle based on a learning result of the learning device."
151,16685156,2019.11.15,20210011481,2021.01.14,20210011481,2021.01.14,,,APPARATUS FOR CONTROLLING BEHAVIOR OF AUTONOMOUS VEHICLE AND METHOD THEREOF,"G05D1/02,G05D1/00,B60W40/04,G06K9/00,G06N3/04","HYUNDAI MOTOR COMPANY,KIA MOTORS CORPORATION","Disclosed are an apparatus for controlling the behavior of an autonomous vehicle and a method thereof. The apparatus includes a learning device that learns a behavior of a vehicle in a situation of avoiding an obstacle located on a road, and a controller that controls the behavior of the autonomous vehicle based on a learning result of the learning device."
152,16591233,2019.10.02,20210004016,2021.01.07,20210004016,2021.01.07,,,U-TURN CONTROL SYSTEM FOR AUTONOMOUS VEHICLE AND METHOD THEREFOR,"G05D1/02,B60W30/045","Hyundai Motor Company,Kia Motors Corporation",A U-turn control system for an autonomous vehicle is provided. The U-turn control system includes a learning device that subdivides information regarding situations to be considered when the autonomous vehicle executes a U-turn for each of a plurality of groups and performs deep learning. A controller executes a U-turn of the autonomous vehicle based on the result learned by the learning device.
153,16731083,2019.12.31,20200241544,2020.07.30,10890916,2021.01.12,10890916,2021.01.12,Location-specific algorithm selection for optimized autonomous driving,"G05D1/00,G05D1/02,B60W50/08,G06N3/08","STRADVISION, INC.","A learning method for performing a seamless parameter switch by using a location-specific algorithm selection for an optimized autonomous driving is provided. And the method includes steps of: (a) a learning device instructing a K-th convolutional layer to apply a convolution operation to K-th training images, to thereby generate K-th feature maps; (b) the learning device instructing a K-th output layer to apply a K-th output operation to the K-th feature maps, to thereby generate K-th estimated autonomous driving source information; (c) the learning device instructing a K-th loss layer to generate a K-th loss by using the K-th estimated autonomous driving source information and its corresponding GT, and then to perform backpropagation by using the K-th loss, to thereby learn K-th parameters of the K-th CNN; and (d) the learning device storing the K-th CNN in a database after tagging K-th location information to the K-th CNN."
154,16684090,2019.11.14,20210001858,2021.01.07,20210001858,2021.01.07,,,LANE CHANGE CONTROL DEVICE AND METHOD FOR AUTONOMOUS VEHICLE,"B60W30/18,G05D1/00,G06N3/08,G06N3/04","HYUNDAI MOTOR COMPANY,KIA MOTORS CORPORATION,HYUNDAI MOTOR COMPANY,KIA MOTORS CORPORATION","A lane change control device and a method for an autonomous vehicle improve safety and accuracy in changing lanes on a road. In particular, the lane change control device includes: a learning device that learns an environment in which the autonomous vehicle is able to change lanes on a road; and a controller that controls a lane change of the autonomous vehicle, based on a learned result of the learning device."
155,16406214,2019.05.08,,,11157784,2021.10.26,11157784,2021.10.26,Explainable learning system and methods for autonomous driving,"G06K9/72,G05D1/00,G06K9/62,G06N3/02,G06K9/00",GM Global Technology Operations LLC,"System and method for explaining driving behavior actions of autonomous vehicles. Combined sensor information collected at a scene understanding module is used to produce a state representation. The state representation includes predetermined types of image representations that, along with a state prediction, are used by a decision making module for determining one or more weighted behavior policies. A driving behavior action is selected and performed based on the determined one or more behavior policies. Information is then provided indicating why the selected driving behavior action was chosen in a particular driving context of the autonomous vehicle. In one or more embodiments, a user interface is configured to depict the predetermined types of image representations corresponding with the driving behavior action performed via the autonomous vehicle."
156,16893657,2020.06.05,20210300416,2021.09.30,20210300416,2021.09.30,,,Autonomous Vehicle Computing System Compute Architecture for Assured Processing,"B60W60/00,G06N3/08,G06N3/04,G06N3/063","UATC, LLC",Systems and methods are directed to an autonomy computing system of an autonomous vehicle. The autonomy computing system can include first functional circuitry configured to generate a first output associated with a first autonomous compute function of the autonomous vehicle based on sensor data using first neural networks. The autonomy computing system can include second functional circuitry configured to generate a second output associated with the first autonomous compute function of the autonomous vehicle based on the sensor data and neural networks. The autonomy computing system can include monitoring circuitry configured to determine a difference between the first output of the first functional circuitry and the second output of the second functional circuitry. The autonomy computing system can include a vehicle control system configured to generate vehicle control signals for the autonomous vehicle based on the outputs.
157,16406214,2019.05.08,20200356828,2020.11.12,20200356828,2020.11.12,,,EXPLAINABLE LEARNING SYSTEM &#x26; METHODS FOR AUTONOMOUS DRIVING,"G06K9/72,G05D1/00,G06K9/00,G06K9/62,G06N3/02",GM Global Technology Operations LLC,"System and method for explaining driving behavior actions of autonomous vehicles. Combined sensor information collected at a scene understanding module is used to produce a state representation. The state representation includes predetermined types of image representations that, along with a state prediction, are used by a decision making module for determining one or more weighted behavior policies. A driving behavior action is selected and performed based on the determined one or more behavior policies. Information is then provided indicating why the selected driving behavior action was chosen in a particular driving context of the autonomous vehicle. In one or more embodiments, a user interface is configured to depict the predetermined types of image representations corresponding with the driving behavior action performed via the autonomous vehicle."
158,16738680,2020.01.09,20200250541,2020.08.06,10824947,2020.11.03,10824947,2020.11.03,"Learning method for supporting safer autonomous driving without danger of accident by estimating motions of surrounding objects through fusion of information from multiple sources, learning device, testing method and testing device using the same","G06N20/10,G06N3/08,G06N3/04,G06N20/20,G06K9/62,G05D1/00,B60W60/00,B60W50/00","StradVision, Inc.",A learning method for supporting a safer autonomous driving through a fusion of information acquired from images and communications is provided. And the method includes steps of: (a) a learning device instructing a first neural network and a second neural network to generate an image-based feature map and a communication-based feature map by using a circumstance image and circumstance communication information; (b) the learning device instructing a third neural network to apply a third neural network operation to the image-based feature map and the communication-based feature map to generate an integrated feature map; (c) the learning device instructing a fourth neural network to apply a fourth neural network operation to the integrated feature map to generate estimated surrounding motion information; and (d) the learning device instructing a first loss layer to train parameters of the first to the fourth neural networks.
159,16739201,2020.01.10,20200250492,2020.08.06,10762393,2020.09.01,10762393,2020.09.01,"Learning method and learning device for learning automatic labeling device capable of auto-labeling image of base vehicle using images of nearby vehicles, and testing method and testing device using the same","G06K9/62,G06N3/08,G06N3/04","StradVision, Inc.","A method for learning an automatic labeling device for auto-labeling a base image of a base vehicle using sub-images of nearby vehicles is provided. The method includes steps of: a learning device inputting the base image and the sub-images into previous trained dense correspondence networks to generate dense correspondences; and into encoders to output convolution feature maps, inputting the convolution feature maps into decoders to output deconvolution feature maps; with an integer k from 1 to n, generating a k-th adjusted deconvolution feature map by translating coordinates of a (k+1)-th deconvolution feature map using a k-th dense correspondence; generating a concatenated feature map by concatenating the 1-st deconvolution feature map and the adjusted deconvolution feature maps; and inputting the concatenated feature map into a masking layer to output a semantic segmentation image and instructing a 1-st loss layer to calculate 1-st losses and updating decoder weights and encoder weights."
160,16709788,2019.12.10,20200247432,2020.08.06,20200247432,2020.08.06,,,SYMBOLIC MODELING AND SIMULATION OF NON-STATIONARY TRAFFIC OBJECTS FOR TESTING AND DEVELOPMENT OF AUTONOMOUS VEHICLE SYSTEMS,"B60W60/00,G06K9/00,G08G1/01,G06N3/08","Perceptive Automata, Inc.","A system performs modeling and simulation of non-stationary traffic entities for testing and development of modules used in an autonomous vehicle system. The system uses a machine learning based model that predicts hidden context attributes for traffic entities that may be encountered by a vehicle in traffic. The system generates simulation data for testing and development of modules that help navigate autonomous vehicles. The generated simulation data may be image or video data including representations of traffic entities, for example, pedestrians, bicyclists, and other vehicles. The system may generate simulation data using generative adversarial neural networks."
161,16455965,2019.06.28,20200004255,2020.01.02,20200004255,2020.01.02,,,METHOD AND ARRANGEMENT FOR GENERATING CONTROL COMMANDS FOR AN AUTONOMOUS ROAD VEHICLE,"G05D1/02,G05D1/00","ZENUITY AB,ZENUITY AB","Described herein is a method and arrangement (  1  ) for generating validated control commands (  2  ) for an autonomous road vehicle (  3  ). An end-to-end trained neural network system (  4  ) is arranged to receive an input of raw sensor data (  5  ) from on-board sensors (  6  ) of the autonomous road vehicle (  3  ) as well as object-level data (  7  ) and tactical information data (  8  ). The end-to-end trained neural network system (  4  ) is further arranged to map input data (  5, 7, 8  ) to control commands (  10  ) for the autonomous road vehicle (  3  ) over pre-set time horizons. A safety module (  9  ) is arranged to receive the control commands (  10  ) for the autonomous road vehicle (  3  ) over the pre-set time horizons and perform risk assessment of planned trajectories resulting from the control commands (  10  ) for the autonomous road vehicle (  3  ) over the pre-set time horizons. The safety module (  9  ) is further arranged to validate as safe and output validated control commands (  2  ) for the autonomous road vehicle (  3  )."
162,16437827,2019.06.11,20190383945,2019.12.19,20190383945,2019.12.19,,,AUTONOMOUS VEHICLE LOCALIZATION USING A LIDAR INTENSITY MAP,"G01S17/89,G01S17/93,G05D1/02,G05D1/00,G01S19/51,G01S7/486","Uber Technologies, Inc.","Aspects of the present disclosure involve systems, methods, and devices for autonomous vehicle localization using a Lidar intensity map. A system is configured to generate a map embedding using a first neural network and to generate an online Lidar intensity embedding using a second neural network. The map embedding is based on input map data comprising a Lidar intensity map, and the Lidar sweep embedding is based on online Lidar sweep data. The system is further configured to generate multiple pose candidates based on the online Lidar intensity embedding and compute a three-dimensional (3D) score map comprising a match score for each pose candidate that indicates a similarity between the pose candidate and the map embedding. The system is further configured to determine a pose of a vehicle based on the 3D score map and to control one or more operations of the vehicle based on the determined pose."
163,17574240,2022.01.12,20220229954,2022.07.21,20220229954,2022.07.21,,,AUTONOMOUS VEHICLE TRAFFIC SIMULATION AND ROAD NETWORK MODELING,G06F30/20,"Ford Global Technologies, LLC,Ford Global Technologies, LLC","A method for improving computational speed of a vehicle modeling processor, includes discretizing a continuous space road map by generating a first graph node associated with a first infrastructure feature and a first area and generating a second graph node associated with a second infrastructure feature and a second area. The system determines a first graph node area associated with the first graph node, determines a second graph node area associated with the second graph node, and determines a connecting link type that connects the first graph node to the second graph node, and computing a set of probabilities for nodes occupied by a vehicle agent of a plurality of vehicle agents. The system generates a simulation that models a vehicle agent driving action based on set of driving actions probabilities. Processing performance of the modeling computer is improved by omitting computations for non-occupied nodes using cellular automata rules."
164,16254545,2019.01.22,,,10373317,2019.08.06,10373317,2019.08.06,Learning method and learning device for attention-driven image segmentation by using at least one adaptive loss weight map to be used for updating HD maps required to satisfy level 4 of autonomous vehicles and  testing method and testing device using the same,"G06K9/46,G06K9/62,G06N3/04,G06N7/00,G06T7/11","Stradvision, Inc.","A method for an attention-driven image segmentation by using at least one adaptive loss weight map is provided to be used for updating HD maps required to satisfy level  4  of autonomous vehicles. By this method, vague objects such as lanes and road markers at distance may be detected more accurately. Also, this method can be usefully performed in military, where identification of friend or foe is important, by distinguishing aircraft marks or military uniforms at distance. The method includes steps of: a learning device instructing a softmax layer to generate softmax scores; instructing a loss weight layer to generate loss weight values by applying loss weight operations to predicted error values generated therefrom; and instructing a softmax loss layer to generate adjusted softmax loss values by referring to initial softmax loss values, generated by referring to the softmax scores and their corresponding GTs, and the loss weight values."
165,16838442,2020.04.02,,,11442456,2022.09.13,11442456,2022.09.13,Apparatus for determining lane change path of autonomous vehicle and method thereof,"G05D1/02,B60W30/09,B60W60/00,B60W30/18","Hyundai Motor Company,Kia Motors Corporation","An apparatus for determining a lane change path of an autonomous vehicle is provided. The apparatus includes a learning device configured to learn lane change paths corresponding to a lane change strategy of the autonomous vehicle, and a controller configured to interwork with the learning device to extract at least two lane change paths corresponding to the lane change strategy among a plurality of lane change paths in a drivable area of the autonomous vehicle and determine a final lane change path based on properties of the extracted lane change paths."
166,16595626,2019.10.08,,,11294386,2022.04.05,11294386,2022.04.05,Device and method for determining U-turn strategy of autonomous vehicle,"G05D1/02,G05D1/00,G05D1/08,G06K9/00,G06N3/08","HYUNDAI MOTOR COMPANY,KIA MOTORS CORPORATION","A device and a method for determining a U-turn strategy of an autonomous driving vehicle is disclosed. The device for determining a U-turn strategy of an autonomous driving vehicle includes a learning device that learns a U-turn strategy for each situation by dividing situation information to be considered in a U-turn of the autonomous driving vehicle into groups, and a controller that determines the U-turn strategy of the autonomous driving vehicle based on the U-turn strategy for each situation learned by the learning device."
167,16929905,2020.07.15,,,11131994,2021.09.28,11131994,2021.09.28,Debugging an autonomous driving machine learning model,"G05D1/00,G06K9/00,G06N20/00","TOYOTA RESEARCH INSTITUTE, INC.","A method for improving an autonomous driving system for an autonomous vehicle is disclosed. The method includes sub-sampling a frame generated by an output of a sensor and transmitting, to a remote device, the sub-sampled frame and classification data corresponding to the sub-sampled frame. The method also includes receiving, from the remote device, an adjustment to the autonomous driving system in response to the transmitted sub-sampled frame and classification data. The method further includes controlling an action of the autonomous vehicle based on the adjusted autonomous driving system."
168,16839884,2020.04.03,20210107486,2021.04.15,20210107486,2021.04.15,,,APPARATUS FOR DETERMINING LANE CHANGE STRATEGY OF AUTONOMOUS VEHICLE AND METHOD THEREOF,"B60W30/18,B60W60/00","HYUNDAI MOTOR COMPANY,KIA MOTORS CORPORATION,HYUNDAI MOTOR COMPANY,KIA MOTORS CORPORATION",An apparatus for determining a lane change strategy of an autonomous vehicle includes: a learning device that classifies situation information into a plurality of groups and learns a lane change strategy for each situation corresponding to respective groups of the plurality of groups when an autonomous vehicle changes lanes; and a controller that periodically determines a lane change strategy suitable for a current situation based on the learned lane change strategy for each situation.
169,16838442,2020.04.02,20210109536,2021.04.15,20210109536,2021.04.15,,,Apparatus for Determining Lane Change Path of Autonomous Vehicle and Method Thereof,"G05D1/02,B60W30/18,B60W30/09,B60W60/00","Hyundai Motor Company,Kia Motors Corporation","An apparatus for determining a lane change path of an autonomous vehicle is provided. The apparatus includes a learning device configured to learn lane change paths corresponding to a lane change strategy of the autonomous vehicle, and a controller configured to interwork with the learning device to extract at least two lane change paths corresponding to the lane change strategy among a plurality of lane change paths in a drivable area of the autonomous vehicle and determine a final lane change path based on properties of the extracted lane change paths."
170,16595626,2019.10.08,20210004011,2021.01.07,20210004011,2021.01.07,,,DEVICE AND METHOD FOR DETERMINING U-TURN STRATEGY OF AUTONOMOUS VEHICLE,"G05D1/02,G05D1/00,G05D1/08,G06K9/00,G06N3/08","HYUNDAI MOTOR COMPANY,KIA MOTORS CORPORATION,HYUNDAI MOTOR COMPANY,KIA MOTORS CORPORATION","A device and a method for determining a U-turn strategy of an autonomous driving vehicle is disclosed. The device for determining a U-turn strategy of an autonomous driving vehicle includes a learning device that learns a U-turn strategy for each situation by dividing situation information to be considered in a U-turn of the autonomous driving vehicle into groups, and a controller that determines the U-turn strategy of the autonomous driving vehicle based on the U-turn strategy for each situation learned by the learning device."
171,16929905,2020.07.15,20200348670,2020.11.05,20200348670,2020.11.05,,,DEBUGGING AN AUTONOMOUS DRIVING MACHINE LEARNING MODEL,"G05D1/00,G06K9/00,G06N20/00","TOYOTA RESEARCH INSTITUTE, INC.,TOYOTA RESEARCH INSTITUTE, INC.","A method for improving an autonomous driving system for an autonomous vehicle is disclosed. The method includes sub-sampling a frame generated by an output of a sensor and transmitting, to a remote device, the sub-sampled frame and classification data corresponding to the sub-sampled frame. The method also includes receiving, from the remote device, an adjustment to the autonomous driving system in response to the transmitted sub-sampled frame and classification data. The method further includes controlling an action of the autonomous vehicle based on the adjusted autonomous driving system."
172,16704807,2019.12.05,20200192392,2020.06.18,20200192392,2020.06.18,,,AUTONOMOUS DRIVING METHODS AND APPARATUSES,"G05D1/02,G06N3/04,G06N3/08,G05D1/00","Samsung Electronics Co., Ltd.,Samsung Electronics Co., Ltd.","An autonomous driving apparatus for accompanied driving in an environment that includes a companion and an obstacle includes a sensor, processing circuitry, and a driver. The sensor may generate sensor data. The processing circuitry may define a current state of the autonomous driving apparatus based on processing the sensor data to determine respective positions of the companion and the obstacle in the environment and select a first tracking point of a plurality of tracking points at least partially surrounding the position of the companion in the environment based on the current state, a position of each tracking point of the plurality of tracking points in the environment defined by the position of the companion in the environment. The driving apparatus drive mechanism may move the autonomous driving apparatus to the first tracking point to cause the autonomous driving apparatus to accompany the companion in the environment."
173,16545645,2019.08.20,20190369643,2019.12.05,20190369643,2019.12.05,,,AUTONOMOUS DRIVING SYSTEM,"G05D1/02,B60W30/182,G08G1/01,G05D1/00,B60W40/04",LG ELECTRONICS INC.,"There is disclosed an autonomous driving method, including: deriving surrounding environment information of a vehicle and traffic signal information that the vehicle is predicted to have faced, based on data received from at least one of a Vehicle to Everything (V2X) network and a vehicle sensor; determining whether or not it is possible to control driving of the vehicle by utilizing the surrounding environment information and the traffic signal information; displaying contents for receiving an input of a user, in a case where it is determined that it is not possible to control driving of the vehicle; and generating a driving control signal of the vehicle based on the input of the user, the surrounding environment information, and traffic signal information."
174,17377761,2021.07.16,20220324477,2022.10.13,20220324477,2022.10.13,,,METHOD AND SYSTEM FOR RECOGNIZING ACTIVITIES IN SURROUNDING ENVIRONMENT FOR CONTROLLING NAVIGATION OF AUTONOMOUS VEHICLE,"B60W60/00,G06K9/00,G06T7/246,G06N3/04","Wipro Limited,Indian Institute of Science","A method and activity recognition system for recognising activities in surrounding environment for controlling navigation of an autonomous vehicle is disclosed. The activity recognition system receives first data feed from neuromorphic event-based camera and second data feed from frame-based RGB video camera. The first data feed comprises high-speed temporal information encoding motion associated with change in surrounding environment at each spatial location, and second data feed comprises spatio-temporal data providing scene-level contextual information associated with surrounding environment. An adaptive sampling of second data feed is performed with respect to foreground activity rate based on amount of foreground motion encoded in first data feed. Further, the activity recognition system recognizes activities associated with at least one object in surrounding environment by identifying correlation between both data feed by using two-stream neural network model. Thereafter, based on the determined activities, the activity recognition system controls the navigation of the autonomous vehicle."
175,16917440,2020.06.30,,,11377125,2022.07.05,11377125,2022.07.05,Vehicle rideshare localization and passenger identification for autonomous vehicles,"B60W60/00,B60W40/08,G01S19/42,G01C21/34,G08G1/123,H04N7/18,H04W4/024,G01S19/40","Rivian IP Holdings, LLC","Various disclosed embodiments include methods of locating an intended passenger of an automotive vehicle and vehicle-based systems for locating an intended passenger of an automotive vehicle. In an illustrative embodiment, a method of locating an intended passenger of an automotive vehicle includes: moving an automotive vehicle to an approximate location of an intended passenger based on a location signal from the intended passenger received via a wireless network; after moving to the approximate location of the intended passenger, receiving, by the vehicle, an image from an electronic device of the intended passenger, the image being an image of the intended passenger or an image of local physical surroundings of the intended passenger; processing the image to determine additional location information of the intended passenger based on matching the image against one or more reference images; and accepting by the vehicle, the intended passenger responsive to the image processing."
176,17518400,2021.11.03,20220153303,2022.05.19,20220153303,2022.05.19,,,Methods and Systems for Determining a Maneuver to be Executed by an Autonomous Vehicle,"B60W60/00,B60W30/095,G06F9/30,G06N3/063",Aptiv Technologies Limited,A computer implemented method for determining a maneuver to be executed by an autonomous vehicle comprises the following steps carried out by computer hardware components: determining a plurality of potential maneuvers; determining a subset of the potential maneuvers based on a pre-determined condition; determining a mask based on the subset; determining an output of a fully connected layer of a neural network; determining a dot product of the output of the fully connected layer and the mask; and determining the maneuver to be executed based on the dot product.
177,16917440,2020.06.30,20210403055,2021.12.30,20210403055,2021.12.30,,,VEHICLE RIDESHARE LOCALIZATION AND PASSENGER IDENTIFICATION FOR AUTONOMOUS VEHICLES,"B60W60/00,B60W40/08,G01S19/42,G01C21/34,G01S19/40,G08G1/123,H04N7/18,H04W4/024","Rivian IP Holdings, LLC","Various disclosed embodiments include methods of locating an intended passenger of an automotive vehicle and vehicle-based systems for locating an intended passenger of an automotive vehicle. In an illustrative embodiment, a method of locating an intended passenger of an automotive vehicle includes: moving an automotive vehicle to an approximate location of an intended passenger based on a location signal from the intended passenger received via a wireless network; after moving to the approximate location of the intended passenger, receiving, by the vehicle, an image from an electronic device of the intended passenger, the image being an image of the intended passenger or an image of local physical surroundings of the intended passenger; processing the image to determine additional location information of the intended passenger based on matching the image against one or more reference images; and accepting by the vehicle, the intended passenger responsive to the image processing."
178,17463175,2021.08.31,20210397184,2021.12.23,20210397184,2021.12.23,,,AUTONOMOUS VEHICLE ROUTING BASED UPON RISK OF AUTONOMOUS VEHICLE TAKEOVER,"G05D1/00,G05D1/02,G01C21/34,G01C21/20",GM Cruise Holdings LLC,"Various technologies described herein pertain to routing an autonomous vehicle based upon risk of takeover of the autonomous vehicle by a human operator. A computing system receives an origin location and a destination location of the autonomous vehicle. The computing system identifies a route for the autonomous vehicle to follow from the origin location to the destination location based upon output of a computer-implemented model. The computer-implemented model is generated based upon labeled data indicative of instances in which autonomous vehicles are observed to transition from operating autonomously to operating based upon conduction by human operators while the autonomous vehicles are executing predefined maneuvers. The computer-implemented model takes, as input, an indication of a maneuver in the predefined maneuvers that is performed by the autonomous vehicle when the autonomous vehicle follows a candidate route. The autonomous vehicle then follows the route from the origin location to the destination location."
179,16280599,2019.02.20,,,11112794,2021.09.07,11112794,2021.09.07,Autonomous vehicle routing based upon risk of autonomous vehicle takeover,"G05D1/00,G05D1/02,G01C21/34,G01C21/20",GM Cruise Holdings LLC,"Various technologies described herein pertain to routing an autonomous vehicle based upon risk of takeover of the autonomous vehicle by a human operator. A computing system receives an origin location and a destination location of the autonomous vehicle. The computing system identifies a route for the autonomous vehicle to follow from the origin location to the destination location based upon output of a computer-implemented model. The computer-implemented model is generated based upon labeled data indicative of instances in which autonomous vehicles are observed to transition from operating autonomously to operating based upon conduction by human operators while the autonomous vehicles are executing predefined maneuvers. The computer-implemented model takes, as input, an indication of a maneuver in the predefined maneuvers that is performed by the autonomous vehicle when the autonomous vehicle follows a candidate route. The autonomous vehicle then follows the route from the origin location to the destination location."
180,16853151,2020.04.20,20210004012,2021.01.07,20210004012,2021.01.07,,,Goal-Directed Occupancy Prediction for Autonomous Driving,"G05D1/02,G01C21/34,G05D1/00,B60W60/00","UATC, LLC","An autonomous vehicle can obtain state data associated with an object in an environment, obtain map data including information associated with spatial relationships between at least a subset of lanes of a road network, and determine a set of candidate paths that the object may follow in the environment based at least in part on the spatial relationships between at least two lanes of the road network. Each candidate path can include a respective set of spatial cells. The autonomous vehicle can determine, for each candidate path, a predicted occupancy for each spatial cell of the respective set of spatial cells of such candidate path during at least a portion of a prediction time horizon. The autonomous vehicle can generate prediction data associated with the object based at least in part on the predicted occupancy for each spatial cell of the respective set of spatial cells for at least one candidate path."
181,16431842,2019.06.05,20200387161,2020.12.10,20200387161,2020.12.10,,,SYSTEMS AND METHODS FOR TRAINING AN AUTONOMOUS VEHICLE,"G05D1/02,G06N3/08,G06K9/62","GM GLOBAL TECHNOLOGY OPERATIONS LLC,GM GLOBAL TECHNOLOGY OPERATIONS LLC","Systems and method are provided for training an autonomous vehicle. In various embodiments, a method includes: storing, in a data storage device, real world data including a sequence of images of a road environment, the sequence of images generated based on a vehicle traversing the road environment; processing, in an offline simulation environment, the sequence of images with a deep reinforcement learning agent associated with a control feature of the autonomous vehicle to obtain an optimized set of control policies; and training the autonomous vehicle based on the optimized set of control polices."
182,16280415,2019.02.20,20200264619,2020.08.20,20200264619,2020.08.20,,,AUTONOMOUS VEHICLE ROUTING BASED UPON SPATIOTEMPORAL FACTORS,"G05D1/02,G01C21/20,G01C21/34,G05D1/00,G01C21/36",GM Cruise Holdings LLC,"Various technologies described herein pertain to routing autonomous vehicles based upon spatiotemporal factors. A computing system receives an origin location and a destination location of an autonomous vehicle. The computing system identifies a route for the autonomous vehicle to follow from the origin location to the destination location based upon output of a spatiotemporal statistical model. The spatiotemporal statistical model is generated based upon historical data from autonomous vehicles when the autonomous vehicles undergo operation-influencing events. The spatiotemporal statistical model takes, as input, a location, a time, and a direction of travel of the autonomous vehicle. The spatiotemporal statistical model outputs a score that is indicative of a likelihood that the autonomous vehicle will undergo an operation-influencing event due to the autonomous vehicle encountering a spatiotemporal factor along a candidate route. The autonomous vehicle then follows the route from the origin location to the destination location."
183,16280599,2019.02.20,20200264605,2020.08.20,20200264605,2020.08.20,,,AUTONOMOUS VEHICLE ROUTING BASED UPON RISK OF AUTONOMOUS VEHICLE TAKEOVER,"G05D1/00,G05D1/02,G01C21/20,G01C21/34",GM Cruise Holdings LLC,"Various technologies described herein pertain to routing an autonomous vehicle based upon risk of takeover of the autonomous vehicle by a human operator. A computing system receives an origin location and a destination location of the autonomous vehicle. The computing system identifies a route for the autonomous vehicle to follow from the origin location to the destination location based upon output of a computer-implemented model. The computer-implemented model is generated based upon labeled data indicative of instances in which autonomous vehicles are observed to transition from operating autonomously to operating based upon conduction by human operators while the autonomous vehicles are executing predefined maneuvers. The computer-implemented model takes, as input, an indication of a maneuver in the predefined maneuvers that is performed by the autonomous vehicle when the autonomous vehicle follows a candidate route. The autonomous vehicle then follows the route from the origin location to the destination location."
184,16724424,2019.12.23,20200250853,2020.08.06,20200250853,2020.08.06,,,METHOD AND DEVICE FOR SUPPORTING ADMINISTRATORS TO EVALUATE OBJECT DETECTING PROCESSES OF OBJECT DETECTORS TO PROVIDE LOGICAL GROUNDS OF AUTONOMOUS DRIVING,"G06T7/73,G06K9/62,G06N3/04,G06N3/08","StradVision, Inc.","A method for supporting at least one administrator to evaluate detecting processes of object detectors to provide logical grounds of an autonomous driving is provided. And the method includes steps of: (a) a computing device instructing convolutional layers, included in an object detecting CNN which has been trained before, to generate reference convolutional feature maps by applying convolutional operations to reference images inputted thereto, and instructing ROI pooling layers included therein to generate reference ROI-Pooled feature maps by pooling at least part of values corresponding to ROIs on the reference convolutional feature maps; and (b) the computing device instructing a representative selection unit to classify the reference ROI-Pooled feature maps by referring to information on classes of objects included in their corresponding ROIs on the reference images, and to generate at least one representative feature map per each class."
185,17359425,2021.06.25,,,11237558,2022.02.01,11237558,2022.02.01,Online machine learning for autonomous earth moving vehicle control,"E01C19/00,E01C21/00,E01C23/00,E02F3/00,E02F5/00,E21C49/02,G05D1/00,G06N20/00,G05D1/02",Built Robotics Inc.,"An autonomous earth moving system can determine a desired state for a portion of the EMV including at least one control surface. Then the EMV selects a set of control signals for moving the portion of the EMV from the current state to the desired state using a machine learning model trained to generate control signals for moving the portion of the EMV to the desired state based on the current state. After the EMV executes the selected set of control signals, the system measures an updated state of the portion of the EMV. In some cases, this updated state of the EMV is used to iteratively update the machine learning model using an online learning process."
186,16410822,2019.05.13,,,11144054,2021.10.12,11144054,2021.10.12,Safety controls for network connected autonomous vehicle,"G05D1/00,G05D1/02,B60W30/18",THE BOEING COMPANY,Method and apparatus for ensuring safety controls for a network-connected autonomous vehicle. The method and apparatus monitor a respective state of each of one or more data communication connections one or more data communication networks. One of a plurality of operational modes for the autonomous vehicle is selected based on the monitored states. Each of the plurality of operational modes defines a respective level of autonomous control for the autonomous vehicle. The method and apparatus transition operation of the autonomous vehicle to the selected operational mode.
187,16410822,2019.05.13,20200142402,2020.05.07,20200142402,2020.05.07,,,SAFETY CONTROLS FOR NETWORK CONNECTED AUTONOMOUS VEHICLE,"G05D1/00,G05D1/02",THE BOEING COMPANY,Method and apparatus for ensuring safety controls for a network-connected autonomous vehicle. The method and apparatus monitor a respective state of each of one or more data communication connections one or more data communication networks. One of a plurality of operational modes for the autonomous vehicle is selected based on the monitored states. Each of the plurality of operational modes defines a respective level of autonomous control for the autonomous vehicle. The method and apparatus transition operation of the autonomous vehicle to the selected operational mode.
188,16521288,2019.07.24,20200031361,2020.01.30,20200031361,2020.01.30,,,Autonomous Efficient Driving Strategy Using Behavior-Based Learning,"B60W50/00,G05B13/02,G05D1/00,B60W30/18,B60W10/04,B60W40/09","Continental Powertrain USA, LLC,Continental Powertrain USA, LLC","A method of modifying one or more parameters of a propulsion system of a vehicle in real time during an autonomous driving mode of the vehicle is provided. The method includes receiving a destination by way of a user interface in communication with the data processing hardware and determining a path from a current vehicle location to the destination. The method includes transmitting to a drive system of the vehicle, driving instructions causing the vehicle to autonomously follow the path. The method includes receiving sensor data from a vehicle sensor system and determining a propulsion adjustment based on an ideal driver behavior and the sensor data. The method also includes transmitting to the propulsion system, propulsion instructions to modify the one or more parameters of the propulsion system to improve vehicle efficiency and/or performance."
189,17855253,2022.06.30,20220332348,2022.10.20,20220332348,2022.10.20,,,"AUTONOMOUS DRIVING METHOD, RELATED DEVICE, AND COMPUTER-READABLE STORAGE MEDIUM","B60W60/00,B60W40/04,B60W50/00,H04W4/44,G06N3/04","HUAWEI TECHNOLOGIES CO., LTD.",The present disclosure provides example autonomous driving apparatuses and computer program products. One example apparatus includes receiving vehicle attribute information and traveling information of a target vehicle from the target vehicle. Layer information of a first road section on which the target vehicle travels is obtained from an autonomous-driving-policy-layer based on the traveling information. A first autonomous driving policy for the target vehicle is obtained based on the layer information of the first road section and the vehicle attribute information of the target vehicle. The first driving policy is sent to the target vehicle.
190,17716697,2022.04.08,20220236729,2022.07.28,20220236729,2022.07.28,,,SELF-MAINTAINING AUTONOMOUS VEHICLE PROCEDURE,"G05B23/02,B60W50/029,B60W50/02,B60W60/00,G06Q10/00",GM Cruise Holdings LLC,"Aspects of the disclosed technology encompass solutions for automatically managing autonomous vehicle (AV) operating and maintenance tasks, such as implementing an alternative operating mode or ordering replacement parts for an AV components. In some aspects, a process of the disclosed technology can include steps for receiving diagnostic data corresponding with an AV component, determining an estimated life cycle of the AV component, and determining whether to generate an action to implement an alternative operating mode or an order request for one or more replacement parts of the AV component, based on the estimated life cycle of the AV component. Systems and machine-readable media are also provided."
191,16420686,2019.05.23,,,11370423,2022.06.28,11370423,2022.06.28,Multi-task machine-learned models for object intention determination in autonomous driving,"B60W30/095,G05D1/02,G06N20/00,G06V20/58","UATC, LLC","Generally, the disclosed systems and methods utilize multi-task machine-learned models for object intention determination in autonomous driving applications. For example, a computing system can receive sensor data obtained relative to an autonomous vehicle and map data associated with a surrounding geographic environment of the autonomous vehicle. The sensor data and map data can be provided as input to a machine-learned intent model. The computing system can receive a jointly determined prediction from the machine-learned intent model for multiple outputs including at least one detection output indicative of one or more objects detected within the surrounding environment of the autonomous vehicle, a first corresponding forecasting output descriptive of a trajectory indicative of an expected path of the one or more objects towards a goal location, and/or a second corresponding forecasting output descriptive of a discrete behavior intention determined from a predefined group of possible behavior intentions."
192,17450914,2021.10.14,20220107651,2022.04.07,20220107651,2022.04.07,,,PREDICTING THREE-DIMENSIONAL FEATURES FOR AUTONOMOUS DRIVING,"G05D1/02,G06N20/00,G06K9/00,G06K9/62,G06T7/20","Tesla, Inc.",A processor coupled to memory is configured to receive image data based on an image captured by a camera of a vehicle. The image data is used as a basis of an input to a trained machine learning model trained to predict a three-dimensional trajectory of a machine learning feature. The three-dimensional trajectory of the machine learning feature is provided for automatically controlling the vehicle.
193,17000128,2020.08.21,20220055663,2022.02.24,20220055663,2022.02.24,,,METHOD AND SYSTEM FOR BEHAVIORAL CLONING OF AUTONOMOUS DRIVING POLICIES FOR SAFE AUTONOMOUS AGENTS,"B60W60/00,B60W30/18,G06K9/00,G06N3/08,B60W10/20","TOYOTA RESEARCH INSTITUTE, INC,,TOYOTA RESEARCH INSTITUTE, INC.","A method for behavior cloned vehicle trajectory planning is described. The method includes perceiving vehicles proximate an ego vehicle in a driving environment, including a scalar confidence value of each perceived vehicle. The method also includes generating a bird's-eye-view (BEV) grid showing the ego vehicle and each perceived vehicle based on each of the scalar confidence value. The method further includes ignoring at least one of the perceived vehicles when the scalar confidence value of the at least one of the perceived vehicles is less than a predetermined value. The method also includes selecting an ego vehicle trajectory based on a cloned expert vehicle behavior policy according to remaining perceived vehicles."
194,16265720,2019.02.01,,,11150664,2021.10.19,11150664,2021.10.19,Predicting three-dimensional features for autonomous driving,"G05D1/02,G06N20/00,G06K9/00,G06K9/62,G06T7/20","Tesla, Inc.",A processor coupled to memory is configured to receive image data based on an image captured by a camera of a vehicle. The image data is used as a basis of an input to a trained machine learning model trained to predict a three-dimensional trajectory of a machine learning feature. The three-dimensional trajectory of the machine learning feature is provided for automatically controlling the vehicle.
195,17216351,2021.03.29,20210216790,2021.07.15,20210216790,2021.07.15,,,DETERMINING AUTONOMOUS VEHICLE STATUS BASED ON MAPPING OF CROWDSOURCED OBJECT DATA,"G06K9/00,G01C21/30,G06N3/02,G05D1/00,G06N20/00,G06F16/29,G01C21/36","Micron Technology, Inc.","A map in a cloud service stores physical objects previously detected by other vehicles that have previously traveled over the same road that a current vehicle is presently traveling on. New data received by the cloud service from the current vehicle regarding new objects that are being encountered by the current vehicle can be compared to the previous object data stored in the map. Based on this comparison, an operating status of the current vehicle is determined. In response to determining the status, an action such as terminating an autonomous navigation mode of the current vehicle is performed."
196,16817068,2020.03.12,20210188316,2021.06.24,20210188316,2021.06.24,,,Systems and Methods for Generating Behavioral Predictions in Reaction to Autonomous Vehicle Movement,"B60W60/00,G06N20/00,G06N3/08","UATC, LLC","Systems and methods are directed to generating behavioral predictions in reaction to autonomous vehicle movement. In one example, a computer-implemented method includes obtaining, by a computing system, local scene data associated with an environment external to an autonomous vehicle, the local scene data including actor data for an actor in the environment external to the autonomous vehicle. The method includes extracting, by the computing system and from the local scene data, one or more actor prediction parameters for the actor using a machine-learned parameter extraction model. The method includes determining, by the computing system, a candidate motion plan for the autonomous vehicle. The method includes generating, by the computing system and using a machine-learned prediction model, a reactive prediction for the actor based at least in part on the one or more actor prediction parameters and the candidate motion plan."
197,16567877,2019.09.11,20200007767,2020.01.02,10855922,2020.12.01,10855922,2020.12.01,Inner monitoring system of autonomous vehicle and system thereof,"H04N7/18,H04N5/232,G06K9/00,G06K9/46",LG Electronics Inc.,"A method of monitoring an interior of an autonomous vehicle using an image sensor including a unit pixel composed of an infrared pixel and three primary color-pixels, according to an embodiment of the present invention, includes the following procedure. Setting an RGB mode boundary value that is expressed in illumination and an infrared mode boundary value having illumination lower than the RGB mode boundary value; acquiring an illumination value of the interior of the vehicle; and creating an RGB image and an infrared image from the image sensor in accordance with the illumination value and driving in a common mode that creates both of the RGB image and the infrared image when the illumination value is less than the RGB mode boundary value and is the infrared mode boundary value or more."
198,16265720,2019.02.01,20200249685,2020.08.06,20200249685,2020.08.06,,,PREDICTING THREE-DIMENSIONAL FEATURES FOR AUTONOMOUS DRIVING,"G05D1/02,G06K9/00,G06T7/20,G06K9/62,G06N20/00","Tesla, Inc.",A processor coupled to memory is configured to receive image data based on an image captured by a camera of a vehicle. The image data is used as a basis of an input to a trained machine learning model trained to predict a three-dimensional trajectory of a machine learning feature. The three-dimensional trajectory of the machine learning feature is provided for automatically controlling the vehicle.
199,16420686,2019.05.23,20190382007,2019.12.19,20190382007,2019.12.19,,,Multi-Task Machine-Learned Models for Object Intention Determination in Autonomous Driving,"B60W30/095,G05D1/02,G06K9/00,G06N20/00","Uber Technologies, Inc.","Generally, the disclosed systems and methods utilize multi-task machine-learned models for object intention determination in autonomous driving applications. For example, a computing system can receive sensor data obtained relative to an autonomous vehicle and map data associated with a surrounding geographic environment of the autonomous vehicle. The sensor data and map data can be provided as input to a machine-learned intent model. The computing system can receive a jointly determined prediction from the machine-learned intent model for multiple outputs including at least one detection output indicative of one or more objects detected within the surrounding environment of the autonomous vehicle, a first corresponding forecasting output descriptive of a trajectory indicative of an expected path of the one or more objects towards a goal location, and/or a second corresponding forecasting output descriptive of a discrete behavior intention determined from a predefined group of possible behavior intentions."
200,16778626,2020.01.31,,,11465611,2022.10.11,11465611,2022.10.11,Autonomous vehicle behavior synchronization,"B60W30/02,G06N5/02,G05D1/00,B60W50/00",International Business Machines Corporation,"A method, system and computer-usable medium are disclosed for autonomous vehicle (AV) behavior synchronization. The AV driving pattern is adjusted to facilitate an occupant's satisfaction by receiving information as to person to form a driving history. The driving history is analyzed to identify preferences and patterns. Based on the driving history a driving preference model is formed for the person. AV driving algorithm(s) are adjusted based on the driving preference model for the person when the person is an occupant of the AV."
201,17848213,2022.06.23,20220319253,2022.10.06,20220319253,2022.10.06,,,Autonomous Vehicle Data Recorders,"G07C5/08,G07C5/00,B60W50/02,B60R21/0136,B60R21/0134,G06V20/58","Micron Technology, Inc.","Systems, methods and apparatus to collect sensor data generated in an autonomous vehicle. Sensors in the vehicle generate a sensor data stream during operations of the vehicle on a road. An advanced driver assistance system (ADAS) of the vehicle uses the sensor data stream to operate the vehicle and generate a trigger signal in response to a fault in object detection, recognition, identification or classification and/or in response to the detection/prediction of an accident. A cyclic buffer buffers at least a portion of the sensor data stream. In response to the trigger signal, a selected segment of the sensor data stream is stored into a non-volatile memory. The selected segment can be partially before the trigger signal and partially after the trigger signal; and selected segment can be longer than what can be fully buffered in the cyclic buffer at the time of the trigger signal."
202,16836235,2020.03.31,,,11422559,2022.08.23,11422559,2022.08.23,Method and system of navigating an autonomous vehicle at an intersection of roads,"G06T7/70,G06V40/20,G05D1/00,G05D1/02,G06N3/08,G06V20/56,G06V40/10",Wipro Limited,"Disclosed subject matter relates to a field of vehicle navigation system that performs a method for navigating an autonomous vehicle at an intersection of roads. An intersection management system may receive sensor data including at least one of depth of an object, images and a video of environment surrounding the autonomous vehicle. Further, traffic police and auxiliary objects associated with each traffic police are detected from plurality of objects of interest present in the images, when the autonomous vehicle is within a predefined distance from an intersection of roads. Thereafter, a correlation matrix comprising inferred data related to each traffic police and the auxiliary objects may be generated. Based on the correlation matrix, the video and the images, a gesture of the traffic police may be determined accurately. Finally, navigation information may be determined based on the correlation matrix and determined gesture, for navigating the autonomous vehicle."
203,16893617,2020.06.05,,,11458997,2022.10.04,11458997,2022.10.04,Autonomous vehicle computing system with processing assurance,"B60W50/04,G06N3/08,B60W60/00,G05D1/00,G06N3/04,G05B13/02,G06N3/063","UATC, LLC","Systems and methods are directed to a method for assured autonomous vehicle compute processing. The method can include providing sensor data to first and second functional circuitry of an autonomy computing system. The first and second functional circuitry can be configured to generate first and second outputs associated with a first autonomous compute function. The method can include generating, by the first and second functional circuitry in response to the sensor data, first and second output data associated with the first autonomous compute function. The method can include generating, by monitoring circuitry of the autonomy computing system, comparative data associated with differences between the first output data and the second output data. The method can include generating one or more vehicle control signals for the autonomous vehicle based at least in part on the comparative data."
204,16263403,2019.01.31,,,11410475,2022.08.09,11410475,2022.08.09,Autonomous vehicle data recorders,"G07C5/08,G07C5/00,B60W50/02,B60R21/0136,B60R21/0134,B60R21/00,G06K9/00,G06V20/58","Micron Technology, Inc.","Systems, methods and apparatus to collect sensor data generated in an autonomous vehicle. Sensors in the vehicle generate a sensor data stream during operations of the vehicle on a road. An advanced driver assistance system (ADAS) of the vehicle uses the sensor data stream to operate the vehicle and generate a trigger signal in response to a fault in object detection, recognition, identification or classification and/or in response to the detection/prediction of an accident. A cyclic buffer buffers at least a portion of the sensor data stream. In response to the trigger signal, a selected segment of the sensor data stream is stored into a non-volatile memory. The selected segment can be partially before the trigger signal and partially after the trigger signal; and selected segment can be longer than what can be fully buffered in the cyclic buffer at the time of the trigger signal."
205,17009656,2020.09.01,20220063666,2022.03.03,20220063666,2022.03.03,,,SCORING AUTONOMOUS VEHICLE TRAJECTORIES USING REASONABLE CROWD DATA,"B60W60/00,G06N3/08,G05D1/02,G01C21/34,G01C21/36,G05D1/00,G06K9/00,G06K9/62",Motional AD LLC,"Enclosed are embodiments for scoring one or more trajectories of a vehicle through a given traffic scenario using a machine learning model that predicts reasonableness scores for the trajectories. In an embodiment, human annotators, referred to as a “reasonable crowd,” are presented with renderings of two or more vehicle trajectories traversing through the same or different traffic scenarios. The annotators are asked to indicate their preference for one trajectory over the other(s). Inputs collected from the human annotators are used to train the machine learning model to predict reasonableness scores for one or more trajectories for a given traffic scenario. These predicted trajectories can be used to rank trajectories generated by a route planner based on their scores, compare AV software stacks, or used by any other application that could benefit from a machine learning model that scores vehicle trajectories."
206,17555941,2021.12.20,20220204033,2022.06.30,20220204033,2022.06.30,,,SCORING AUTONOMOUS VEHICLE TRAJECTORIES USING REASONABLE CROWD DATA,"B60W60/00,G06N3/08,G05D1/00,G01C21/36,G06K9/62,G01C21/34,G05D1/02,G06V20/40,G06V20/56",Motional AD LLC,"Enclosed are embodiments for scoring one or more trajectories of a vehicle through a given traffic scenario using a machine learning model that predicts reasonableness scores for the trajectories. In an embodiment, human annotators, referred to as a “reasonable crowd,” are presented with renderings of two or more vehicle trajectories traversing through the same or different traffic scenarios. The annotators are asked to indicate their preference for one trajectory over the other(s). Inputs collected from the human annotators are used to train the machine learning model to predict reasonableness scores for one or more trajectories for a given traffic scenario. These predicted trajectories can be used to rank trajectories generated by a route planner based on their scores, compare AV software stacks, or used by any other application that could benefit from a machine learning model that scores vehicle trajectories."
207,16442904,2019.06.17,,,11294387,2022.04.05,11294387,2022.04.05,Systems and methods for training a vehicle to autonomously drive a route,"G05D1/02,G05B13/02,G05D1/00","Toyota Research Institute, Inc.","A system for determining when a vehicle has learned a route is provided. The system includes at least one camera configured to capture image data of an external environment, a processor and a memory module storing one or more processor-readable instructions that, when executed by the processor, cause the system to: generate one or more predictions about objects in the external environment as the vehicle proceeds along the route based on the image data, determine a prediction error based on an accuracy of the one or more predictions, determine a confidence level for the route based on the prediction error, and determine that the vehicle has learned the route in response to the confidence level exceeding a confidence level threshold."
208,17553209,2021.12.16,20220107641,2022.04.07,20220107641,2022.04.07,,,Labeling Autonomous Vehicle Data,"G05D1/00,G05D1/02,G06N20/00","Aurora Operations, Inc.","Sensor data collected from an autonomous vehicle data can be labeled using sensor data collected from an additional vehicle. The additional vehicle can include a non-autonomous vehicle mounted with a removable hardware pod. In many implementations, removable hardware pods can be vehicle agnostic. In many implementations, generated labels can be utilized to train a machine learning model which can generate one or more control signals for the autonomous vehicle."
209,17039156,2020.09.30,20220097708,2022.03.31,20220097708,2022.03.31,,,SYSTEMS AND METHODS FOR CONTROLLING THE OPERATION OF AN AUTONOMOUS VEHICLE USING MULTIPLE TRAFFIC LIGHT DETECTORS,"B60W30/18,H04W4/44,G06K9/00","Toyota Research Institute, Inc.","Systems and methods for controlling the operation of an autonomous vehicle are disclosed herein. One embodiment performs traffic light detection at an intersection using a sensor-based traffic light detector to produce a sensor-based detection output, the sensor-based detection output having an associated first confidence level; performs traffic light detection at the intersection using a vehicle-to-infrastructure-based (V2I-based) traffic light detector to produce a V2I-based detection output, the V2I-based detection output having an associated second confidence level; performs one of (1) selecting as a final traffic-light-detection output whichever of the sensor-based detection output and the V2I-based detection output has a higher associated confidence level and (2) generating the final traffic-light-detection output by fusing the sensor-based detection output and the V2I-based detection output using a first learning-based classifier; and controls the operation of the autonomous vehicle based, at least in part, on the final traffic-light-detection output."
210,17498637,2021.10.11,20220024493,2022.01.27,20220024493,2022.01.27,,,Sensor Fusion to Determine Reliability of Autonomous Vehicle Operation,"B60W60/00,B60W50/02,B60W50/035","Micron Technology, Inc.","A method for an autonomous vehicle includes: receiving first object data from a first sensor module; receiving second object data from a second sensor module; comparing the first object data to the second object data; determining, based on comparing the first object data to the second object data, whether the first object data corresponds to the second object data; and in response to determining that the first object data does not correspond to the second object data, performing an action for the autonomous vehicle."
211,16271381,2019.02.08,,,11209821,2021.12.28,11209821,2021.12.28,Labeling autonomous vehicle data,"G05D1/02,G05D1/00,G06N20/00","Aurora Innovation, Inc.","Sensor data collected from an autonomous vehicle data can be labeled using sensor data collected from an additional vehicle. The additional vehicle can include a non-autonomous vehicle mounted with a removable hardware pod. In many implementations, removable hardware pods can be vehicle agnostic. In many implementations, generated labels can be utilized to train a machine learning model which can generate one or more control signals for the autonomous vehicle."
212,17336685,2021.06.02,,,11203362,2021.12.21,11203362,2021.12.21,Scoring autonomous vehicle trajectories using reasonable crowd data,"G06K9/62,B60W60/00,G06N3/08,G05D1/00,G06K9/00,G01C21/36,G01C21/34,G05D1/02",Motional AD LLC,"Enclosed are embodiments for scoring one or more trajectories of a vehicle through a given traffic scenario using a machine learning model that predicts reasonableness scores for the trajectories. In an embodiment, human annotators, referred to as a “reasonable crowd,” are presented with renderings of two or more vehicle trajectories traversing through the same or different traffic scenarios. The annotators are asked to indicate their preference for one trajectory over the other(s). Inputs collected from the human annotators are used to train the machine learning model to predict reasonableness scores for one or more trajectories for a given traffic scenario. These predicted trajectories can be used to rank trajectories generated by a route planner based on their scores, compare AV software stacks, or used by any other application that could benefit from a machine learning model that scores vehicle trajectories."
213,16666251,2019.10.28,,,11181913,2021.11.23,11181913,2021.11.23,Autonomous vehicle fleet model training and testing,"G05D1/00,G05D1/02,G08G1/123,G07C5/00","Zoox, Inc.","A method and system of using excess computational resources on autonomous vehicles. Such excess computational resources may be available during periods of low demand, or other periods of idleness (e.g., parking). Where portions of computing resources are available amongst a fleet of vehicles, such excess computing resources may be pooled as a single resource. The excess computational resources may be used, for example, to train and/or test machine-learning models. Performance metrics of such models may be determined using hardware and software on the autonomous vehicle, for example sensors. Models having performance metrics outperforming current models may be considered as validated models. Validated models may be transmitted to a remote computing system for dissemination to a fleet of vehicles."
214,16893617,2020.06.05,20210300405,2021.09.30,20210300405,2021.09.30,,,Autonomous Vehicle Computing System with Processing Assurance,"B60W60/00,G06N3/063,G06N3/08,G06N3/04","UATC, LLC","Systems and methods are directed to a method for assured autonomous vehicle compute processing. The method can include providing sensor data to first and second functional circuitry of an autonomy computing system. The first and second functional circuitry can be configured to generate first and second outputs associated with a first autonomous compute function. The method can include generating, by the first and second functional circuitry in response to the sensor data, first and second output data associated with the first autonomous compute function. The method can include generating, by monitoring circuitry of the autonomy computing system, comparative data associated with differences between the first output data and the second output data. The method can include generating one or more vehicle control signals for the autonomous vehicle based at least in part on the comparative data."
215,16893630,2020.06.05,20210300425,2021.09.30,20210300425,2021.09.30,,,Asynchronous Processing for Autonomous Vehicle Computing Systems,"B60W60/00,G05D1/00,B60W50/04,G05B13/02,G06N3/04","UATC, LLC","Systems and methods are directed to an autonomy computing system for an autonomous vehicle. The autonomy computing system can include functional circuits associated with a first compute function of the autonomous vehicle. Each of the functional circuits can be configured to obtain sensor data that describes one or more aspects of an environment external to the autonomous vehicle at a current time. Each of the functional circuits can be configured to generate, over a time period and based on the sensor data, a respective output according to the specified order. The autonomy computing system can include monitoring circuits configured to evaluate an output consistency of the respective outputs, and in response to detecting an output inconsistency between two or more of the respective outputs, generate data indicative of a detected anomaly associated with the first autonomous compute function."
216,17322056,2021.05.17,20210302997,2021.09.30,20210302997,2021.09.30,,,COMPUTER-ASSISTED OR AUTONOMOUS DRIVING ASSISTED BY ROADWAY NAVIGATION BROADCAST,"G05D1/02,H04W4/44,G08G1/01,H04W4/029,B60W30/00,H04W4/38",Intel Corporation,"The present disclosure may be directed to a computer-assisted or autonomous driving (CA/AD) vehicle that receives a plurality of indications of a condition of one or more features of a plurality of locations of a roadway, respectively, encoded in a plurality of navigation signals broadcast by a plurality of transmitters as the CA/AD vehicle drives past the locations enroute to a destination. The CA/AD vehicle may then determine, based in part on the received indications, driving adjustments to be made and send indications of the driving adjustments to a driving control unit of the CA/AD vehicle."
217,17013482,2020.09.04,20210232913,2021.07.29,20210232913,2021.07.29,,,INTERPRETABLE AUTONOMOUS DRIVING SYSTEM AND METHOD THEREOF,"G06N3/08,G06N5/04,B60W60/00,B60W50/06,G01C21/34","Honda Motor Co., Ltd.","In some examples, a dynamic system, including a vehicle, may be represented using a graph-based representation. One or more nodes in the graph-based representation may correspond to one or more agents in the dynamic system, and one or more edges between the nodes in the graph-based representation may correspond to one or more interactions between the agents in the dynamic system. The interactions may be defined based on human domain knowledge of the dynamic system. The dynamic system may be modeled using a respective machine learning model that includes a reward decoder that operates on the graph-based representation and evaluates one or more reward functions for the dynamic system. The one or more reward functions may be defined based on the human domain knowledge of the dynamic system. Autonomous operation of the vehicle may be controlled based on the modeling of the dynamic system."
218,16285717,2019.02.26,,,11047698,2021.06.29,11047698,2021.06.29,Autonomous driving apparatus and method thereof,"G01C21/34,G05D1/02,G06N20/00,G05D1/00","SAMSUNG ELECTRONICS CO., LTD.","A method for controlling an autonomous driving apparatus of a vehicle includes receiving a destination for setting a route, obtaining driving history of a user and traffic information, determining a driving route to the destination based on information on the destination, information on the driving history, and the traffic information provided to a model trained through an artificial intelligence algorithm as input data, and performing autonomous driving along the determined driving route."
219,17135214,2020.12.28,20210117451,2021.04.22,20210117451,2021.04.22,,,PROGRAMMATICALLY IDENTIFYING A PERSONALITY OF AN AUTONOMOUS VEHICLE,"G06F16/28,G05D1/00,G06N20/00,G06F16/248,G06F16/242","Micron Technology, Inc.","Systems and methods for assigning personalities to autonomous vehicles are disclosed. In one embodiment, a method is disclosed comprising receiving data from an autonomous vehicle; generating a vector representing the autonomous vehicle based on the data; classifying the vector into one or more personalities; receiving a search query from a user; identifying one or more autonomous vehicles responsive to the search query based on personalities assigned to the one or more autonomous vehicles, the one or more autonomous vehicles including the autonomous vehicle; and transmitting the one or more autonomous vehicles to the user."
220,16729342,2019.12.28,20200156660,2020.05.21,10940871,2021.03.09,10940871,2021.03.09,Contextual autonomous vehicle support through pictorial interaction,"B60W50/14,G05D1/00,B60K35/00",GM GLOBAL TECHNOLOGY OPERATIONS LLC,"An autonomous vehicle including a sensor system that outputs a sensor signal indicative of a condition of the autonomous vehicle. The vehicle also includes a user interface device with a display. A computing system determines, based upon a profile of the passenger, that support is to be provided pictorially to the passenger when the support is provided to the passenger. The computing system further detects occurrence of an event that has been identified as potentially causing discomfort to the passenger. The computing system yet further sets a predefined pictorial support message defined in an account corresponding to the event maintained in a database prior to occurrence of the event as a pictorial support message to be presented to the passenger. The computing system additionally causes the display to present the pictorial support message, wherein the pictorial support message solicits feedback from the passenger of the autonomous vehicle."
221,16442904,2019.06.17,20200393842,2020.12.17,20200393842,2020.12.17,,,SYSTEMS AND METHODS FOR TRAINING A VEHICLE TO AUTONOMOUSLY DRIVE A ROUTE,"G05D1/02,G05B13/02,G05D1/00","Toyota Research Institute, Inc.,Toyota Research Institute, Inc.","A system for determining when a vehicle has learned a route is provided. The system includes at least one camera configured to capture image data of an external environment, a processor and a memory module storing one or more processor-readable instructions that, when executed by the processor, cause the system to: generate one or more predictions about objects in the external environment as the vehicle proceeds along the route based on the image data, determine a prediction error based on an accuracy of the one or more predictions, determine a confidence level for the route based on the prediction error, and determine that the vehicle has learned the route in response to the confidence level exceeding a confidence level threshold."
222,16940118,2020.07.27,20200357194,2020.11.12,20200357194,2020.11.12,,,PROVIDING AUTONOMOUS VEHICLE MAINTENANCE,"G07C5/00,G01C21/34,G06Q10/00,G07C5/08","Micron Technology, Inc.","Systems and methods for providing autonomous vehicle assistance are disclosed. In one embodiment, a method is disclosed comprising detecting a service condition in response to a fault occurring at an autonomous vehicle at a first location; coordinating service with a nearby service provider, the service provider providing a time window and a second location; predicting that the autonomous vehicle will be free to fulfill the service; driving the autonomous vehicle to the second location of the service provider during the time window; and returning the autonomous vehicle to the first location after the service is completed."
223,16947184,2020.07.22,20200348667,2020.11.05,20200348667,2020.11.05,,,CONTROL SYSTEM FOR SEMI-AUTONOMOUS CONTROL OF VEHICLE ALONG LEARNED ROUTE,"G05D1/00,B60W50/14,G05D1/02,B60W30/10,B60W30/16,B60W50/00",MAGNA ELECTRONICS INC.,"A vehicular control system for controlling a vehicle includes a vehicle control, an acceleration sensor and a camera. The vehicle control includes an image processor for processing image data captured by the camera as the vehicle is driven along a route by a driver of the vehicle. The vehicle control detects traffic and road topography and determines acceleration of the vehicle as the vehicle is driven along the route by the driver. The vehicle control learns the route during multiple repetitive drives of the route by the driver of the vehicle. The vehicle control increases a confidence level of the learned route during multiple repetitive drives of the route by the vehicle. When the confidence level exceeds a threshold value, the vehicle control is operable to at least semi-autonomously control the vehicle to drive the vehicle along the route."
224,16263403,2019.01.31,20200250902,2020.08.06,20200250902,2020.08.06,,,Autonomous Vehicle Data Recorders,"G07C5/08,G07C5/00,B60W50/02,B60R21/0134,B60R21/0136,G06K9/00","Micron Technology, Inc.","Systems, methods and apparatus to collect sensor data generated in an autonomous vehicle. Sensors in the vehicle generate a sensor data stream during operations of the vehicle on a road. An advanced driver assistance system (ADAS) of the vehicle uses the sensor data stream to operate the vehicle and generate a trigger signal in response to a fault in object detection, recognition, identification or classification and/or in response to the detection/prediction of an accident. A cyclic buffer buffers at least a portion of the sensor data stream. In response to the trigger signal, a selected segment of the sensor data stream is stored into a non-volatile memory. The selected segment can be partially before the trigger signal and partially after the trigger signal; and selected segment can be longer than what can be fully buffered in the cyclic buffer at the time of the trigger signal."
225,16752594,2020.01.24,20200241552,2020.07.30,20200241552,2020.07.30,,,USING CLASSIFIED SOUNDS AND LOCALIZED SOUND SOURCES TO OPERATE AN AUTONOMOUS VEHICLE,"G05D1/02,G10L25/18,G10L25/51,H04R1/40,H04R3/00,G05D1/00,G06N20/00",Aptiv Technologies Limited,"An ambient sound environment is captured by a microphone array of an autonomous vehicle traveling in the ambient sound environment. A perception module of the autonomous vehicle classifies sounds and localizes sound sources in the ambient sound environment. Classification is performed using spectrum analysis and/or machine learning. In an embodiment, sound sources within a field of view (FOV) of an image sensor of the autonomous vehicle are localized in a visual scene generated by the perception module. In an embodiment, one or more sound sources outside the FOV of the image sensors are localized in a static digital map. Localization is performed using parametric or non-parametric techniques and/or machine learning. The output of the perception module is input into a planning module of the autonomous vehicle to plan a route or trajectory for the autonomous vehicle in the ambient sound environment."
226,16836235,2020.03.31,20200225662,2020.07.16,20200225662,2020.07.16,,,METHOD AND SYSTEM OF NAVIGATING AN AUTONOMOUS VEHICLE AT AN INTERSECTION OF ROADS,"G05D1/00,G05D1/02,G06K9/00,G06T7/70,G06N3/08",Wipro Limited,"Disclosed subject matter relates to a field of vehicle navigation system that performs a method for navigating an autonomous vehicle at an intersection of roads. An intersection management system may receive sensor data including at least one of depth of an object, images and a video of environment surrounding the autonomous vehicle. Further, traffic police and auxiliary objects associated with each traffic police are detected from plurality of objects of interest present in the images, when the autonomous vehicle is within a predefined distance from an intersection of roads. Thereafter, a correlation matrix comprising inferred data related to each traffic police and the auxiliary objects may be generated. Based on the correlation matrix, the video and the images, a gesture of the traffic police may be determined accurately. Finally, navigation information may be determined based on the correlation matrix and determined gesture, for navigating the autonomous vehicle."
227,16587004,2019.09.29,20200156656,2020.05.21,10703385,2020.07.07,10703385,2020.07.07,Contextual autonomous vehicle support through written interaction,"B60Q1/00,B60W50/14,G05D1/00,B60K35/00",GM GLOBAL TECHNOLOGY OPERATIONS LLC,"An autonomous vehicle including a sensor system that outputs a sensor signal indicative of a condition of the autonomous vehicle. The vehicle also includes a user interface device with a display. A computing system determines, based upon a profile of the passenger, that support is to be provided textually to the passenger when the support is provided to the passenger. The computing system further detects occurrence of an event that has been identified as potentially causing discomfort to the passenger. The computing system yet further sets a predefined support message defined in an account corresponding to the event maintained in a database prior to occurrence of the event as a support message to be presented to the passenger. The computing system additionally causes the display to present the support message textually, wherein the textual support message solicits feedback from the passenger of the autonomous vehicle."
228,16816854,2020.03.12,20200209867,2020.07.02,20200209867,2020.07.02,,,Labeling Autonomous Vehicle Data,G05D1/02,"Aurora Innovation, Inc.","One or more instances of sensor data collected using an autonomous vehicle sensor suite can be labeled using corresponding instance(s) of sensor data collected using an additional sensor suite. The additional vehicle can include a second autonomous vehicle as well as a non-autonomous vehicle mounted with a removable hardware pod. In many implementations, an object in the sensor data captured using the autonomous vehicle can be labeled by mapping a label corresponding to the same object captured using the additional vehicle. In various implementations, labeled instances of sensor data can be utilized to train a machine learning model to generate one or more control signals for autonomous vehicle control."
229,16685994,2019.11.15,20200159220,2020.05.21,20200159220,2020.05.21,,,INTEGRATED PLATFORM AND COMMON SOFTWARE STRUCTURAL ARCHITECTURE FOR AUTONOMOUS AGRICULTURAL VEHICLE AND MACHINERY OPERATION,"G05D1/00,G06Q10/04,G06Q50/02,G06N5/02,G05D1/02,A01B79/00,A01B69/04,H04W4/40,H04Q9/02","RAVEN INDUSTRIES, INC.","An integrated technology platform includes multiple hardware and software components that enable any application of autonomous agricultural equipment operation in an agricultural or other off-road setting, within a common software structural architecture. The integrated technology platform represents a technology stack that is a modular architecture that can be leveraged across multiple use cases and vehicle types. The integrated technology platform includes a vehicle interface component responsible for the physical interface to agricultural equipment, a telematics component that enables stable in-field communications between all aspects of the integrated technology platform, and a perception component that operates as a safety mechanism and includes object detection and classification. Additionally, a cloud-side application performs account management and field setup and as well as syncing of field equipment and operating systems in a common operating system. The integrated technology platform also includes an executive control layer that enables rapid porting from one platform to another, so that software applications in the integrated technology platform can work with hardware of any manufacture."
230,16271381,2019.02.08,20200142408,2020.05.07,20200142408,2020.05.07,,,Labeling Autonomous Vehicle Data,"G05D1/00,G06N20/00,G05D1/02","Aurora Innovation, Inc.","Sensor data collected from an autonomous vehicle data can be labeled using sensor data collected from an additional vehicle. The additional vehicle can include a non-autonomous vehicle mounted with a removable hardware pod. In many implementations, removable hardware pods can be vehicle agnostic. In many implementations, generated labels can be utilized to train a machine learning model which can generate one or more control signals for the autonomous vehicle."
231,16598233,2019.10.10,20200117194,2020.04.16,20200117194,2020.04.16,,,"CONTROL METHOD OF AUTOMATIC DRIVING IMPORTED ""SMART GAINS"" MODEL, DEVICE AND PROGRAM","G05D1/00,G06N5/04,G06N20/00,G05D1/02","Apollo Japan Co., Ltd.","The invention proposes a control method of automatic driving imported “Smart Gains” model, which is characterized by that it can bypass the NP problem caused by the high complexity that currently troubles the automatic driving control, and though the prior knowledge generated by the Gaussian process machine learning model with the maximum probability, it can carry out the closed-loop control of automatic driving with a given trajectory, which can solve the nonlinear adjustment problem of the actuators of the automatic driving vehicle, and the optimization control problem of the randomness of the control object, and can make the automatic driving vehicle run smoothly, save energy, be comfortable and fast, and desire to get the level of automatic driving above L4."
232,16666251,2019.10.28,20200064842,2020.02.27,20200064842,2020.02.27,,,AUTONOMOUS VEHICLE FLEET MODEL TRAINING AND TESTING,"G05D1/00,G07C5/00,G08G1/123,G05D1/02","Zoox, Inc.","A method and system of using excess computational resources on autonomous vehicles. Such excess computational resources may be available during periods of low demand, or other periods of idleness (e.g., parking). Where portions of computing resources are available amongst a fleet of vehicles, such excess computing resources may be pooled as a single resource. The excess computational resources may be used, for example, to train and/or test machine-learning models. Performance metrics of such models may be determined using hardware and software on the autonomous vehicle, for example sensors. Models having performance metrics outperforming current models may be considered as validated models. Validated models may be transmitted to a remote computing system for dissemination to a fleet of vehicles."
233,16285717,2019.02.26,20190265060,2019.08.29,20190265060,2019.08.29,,,AUTONOMOUS DRIVING APPARATUS AND METHOD THEREOF,"G01C21/34,G05D1/00,G05D1/02,G06N20/00","SAMSUNG ELECTRONICS CO., LTD.","A method for controlling an autonomous driving apparatus of a vehicle includes receiving a destination for setting a route, obtaining driving history of a user and traffic information, determining a driving route to the destination based on information on the destination, information on the driving history, and the traffic information provided to a model trained through an artificial intelligence algorithm as input data, and performing autonomous driving along the determined driving route."
234,16711187,2019.12.11,,,11485376,2022.11.01,11485376,2022.11.01,"Automatic driving processing system, system on chip and method for monitoring processing module","B60W50/04,B60W50/02,B60W50/035","Beijing Baidu Netcom Science And Technology Co., LTD.","An automatic processing system, a system on chip and a method for monitoring a processing module are described herein. The automatic driving processing system comprises: an automatic driving processing module, configured for receiving an input data stream and processing the input data stream based on a deep learning model so as to generate a processing result; a fault detection module, configured for generating a control signal and a fault detection stimulating data stream, and receiving the processing result from the automatic driving processing module; and a multi-way selection module, configured for receiving an automatic driving data stream as well as the control signal and the fault detection stimulating data stream, and selectively outputting the automatic driving data stream or the fault detection stimulating data stream to the automatic driving processing module based on the control signal, as an input data stream."
235,17844842,2022.06.21,20220314876,2022.10.06,20220314876,2022.10.06,,,"METHOD OF WARNING PEDESTRIAN OR VEHICLE TO MAKE AVOIDANCE BY AUTONOMOUS VEHICLE, ELECTRONIC DEVICE AND AUTONOMOUS VEHICLE","B60Q1/50,G06V20/58,G08G1/16","APOLLO INTELLIGENT CONNECTIVITY (BEIJING) TECHNOLOGY CO., LTD.,APOLLO INTELLIGENT CONNECTIVITY (BEIJING) TECHNOLOGY CO., LTD.","A method of warning a pedestrian or a vehicle to make avoidance of an autonomous vehicle, which relates to a field of artificial intelligence, in particular to fields of deep learning, cloud computing, NLP and the like, and is applicable to an automatic driving scenario. The method may include: acquiring a prompt for warning a pedestrian or a vehicle to make avoidance; and displaying the prompt on a display unit of the autonomous vehicle, where the display unit includes at least one selected from: a windshield, a window glass, a projection screen mounted on the windshield, or a projection screen mounted on the window glass."
236,16862630,2020.04.30,,,11301724,2022.04.12,11301724,2022.04.12,Semantic adversarial generation based function testing method in autonomous driving,"G06K9/62,G06N3/08,G06T9/00,G06K9/00",Robert Bosch GmbH,"A system includes a camera configured to obtain image information from objects. The system also includes a processor in communication with the camera and programmed to receive an input data including the image information, encode the input via an encoder, obtain a latent variable defining an attribute of the input data, generate a sequential reconstruction of the input data utilizing at least the latent variable and an adversarial noise, obtain a residual between the input data and the sequential reconstruction utilizing a comparison of at least the input and the reconstruction to learn a mean shift in latent space, and output a mean shift indicating a test result of the input compared to the adversarial noise based on the comparison."
237,17187787,2021.02.27,,,11292490,2022.04.05,11292490,2022.04.05,Contextual autonomous vehicle support through pictorial interaction,"B60W50/14,G05D1/00,B60K35/00",GM GLOBAL TECHNOLOGY OPERATIONS LLC,"An autonomous vehicle including a sensor system that outputs a sensor signal indicative of a condition of the autonomous vehicle. The vehicle also includes a user interface device with a display. A computing system determines, based upon a profile of the passenger, that support is to be provided pictorially to the passenger when the support is provided to the passenger. The computing system further detects occurrence of an event that has been identified as potentially causing discomfort to the passenger. The computing system yet further sets a predefined pictorial support message defined in an account corresponding to the event maintained in a database prior to occurrence of the event as a pictorial support message to be presented to the passenger. The computing system additionally causes the display to present the pictorial support message, wherein the pictorial support message solicits feedback from the passenger of the autonomous vehicle."
238,17082180,2020.10.28,20220126849,2022.04.28,20220126849,2022.04.28,,,FUNCTIONALLY SAFE RATIONALIZATION CHECK FOR AUTONOMOUS VEHICLE MACHINE LEARNING ALGORITHMS,"B60W50/06,G06K9/00,G06K9/62,G06K9/20,G06N20/00,G06N3/08,B60W60/00","Neil Garbacik,Dalong Li","Systems and methods for testing a machine learning algorithm or technique of an autonomous driving feature of a vehicle utilize a sensor system configured to capture input data representative of an environment external to the vehicle and a controller configured to receive the input data from the sensor system and perform a testing procedure for the autonomous driving feature that includes inserting known input data into a target portion of the input data to obtain modified input data, processing the modified input data according to the autonomous driving feature to obtain output data, and determining an accuracy of the autonomous driving features based on a comparison between the output data and the known input data."
239,17461864,2021.08.30,20220058405,2022.02.24,20220058405,2022.02.24,,,COMPUTER-ASSISTED OR AUTONOMOUS DRIVING TRAFFIC SIGN RECOGNITION METHOD AND APPARATUS,"G06K9/00,G07C5/08,G05D1/00,G06F16/532,G06K9/62",Intel Corporation,"Apparatuses, methods and storage medium associated with traffic sign recognition, are disclosed herein. In some embodiments, an apparatus includes an orchestrator, disposed in a CA/AD vehicle, to receive a classification and a location of a traffic sign, while the CA/AD vehicle is enroute to a destination. In response, the orchestrator query a remote sign locator service or a local database on the CA/AD vehicle for a reference description of the traffic sign, determine whether the classification is correct, and output a result of the determination. The classification of the traffic sign is generated based at least in part on computer vision, and the orchestrator includes an anomaly detector to detect anomalies between the classification and the reference description, and determine whether the classification is correct based at least in part on an amount of anomalies detected. Other embodiments are also described and claimed."
240,17301956,2021.04.20,20210385073,2021.12.09,20210385073,2021.12.09,,,AUTONOMOUS DRIVING CONTROLLER ENCRYPTED COMMUNICATIONS,"H04L9/08,B60W50/02","Tesla, Inc.","An autonomous driving controller includes a plurality of parallel processors operating on common input data received from the plurality of autonomous driving sensors. Each of the plurality of parallel processors includes communication circuitry, a general processor, a security processor subsystem (SCS), and a safety subsystem (SMS). The communication circuitry supports communications between the plurality of parallel processors, including inter-processor communications between the general processors of the plurality of parallel processors, communications between the SCSs of the plurality of parallel processors using SCS cryptography, and communications between the SMSs of the plurality of parallel processors using SMS cryptography, the SMS cryptography differing from the SCS cryptography. The SCS and/or the SMS may each include dedicated hardware and/or memory to support the communications."
241,16916055,2020.06.29,,,11192563,2021.12.07,11192563,2021.12.07,Contextual autonomous vehicle support through written interaction,"B60Q1/00,B60W50/14,B60K35/00,G05D1/00",GM GLOBAL TECHNOLOGY OPERATIONS LLC,"An autonomous vehicle including a sensor system that outputs a sensor signal indicative of a condition of the autonomous vehicle. The vehicle also includes a user interface device with a display. A computing system determines, based upon a profile of the passenger, that support is to be provided textually to the passenger when the support is provided to the passenger. The computing system further detects occurrence of an event that has been identified as potentially causing discomfort to the passenger. The computing system yet further sets a predefined support message defined in an account corresponding to the event maintained in a database prior to occurrence of the event as a support message to be presented to the passenger. The computing system additionally causes the display to present the support message textually, wherein the textual support message solicits feedback from the passenger of the autonomous vehicle."
242,16869725,2020.05.08,20210347274,2021.11.11,20210347274,2021.11.11,,,Automatic Electric Vehicle Charging Device,"B60L53/35,B60L53/16,H02K7/116,H02J7/00,B25J9/16,B25J13/08,B25J9/10,B25J18/00","ABB Schweiz AG,ABB Schweiz AG","A charging device autonomously charges an electric vehicle. The charging device includes: a main body and an arm coupled to the main body. The main body is controllably moveable, and the arm is controllably extendable and retractable in a longitudinal direction. A charging plug is included at a distal end of the arm. The charging plug is controllably moveable and insertable into a charging portal of the electric vehicle. The arm comprises: a rigid chain, the rigid chain being compliant in a first direction from a neutral axis and resistant in an opposite second direction past the neutral axis, or at least one scissor arm."
243,16512907,2019.07.16,,,11170525,2021.11.09,11170525,2021.11.09,"Autonomous vehicle based position detection method and apparatus, device and medium","G06K9/00,G06T7/73,G06T7/62,G05D1/00,G06N3/04,G06N3/08","Baidu Online Network Technology (Beijing) Co., Ltd.","The present application provides autonomous vehicle based position detection method and apparatus, a device and a medium, where the method includes: identifying an obtained first visual perception image according to an underlying neural network layer in a slender convolution kernel neural network model to determine feature information of the target linear object image, and identifying the feature information of the target linear object image by using a high-level neural network layer in the slender convolution kernel neural network model to determine size information of the target linear object image; further, matching the size information of the target linear object image with preset coordinate system map information to determine a position of the autonomous vehicle. Embodiments of the present application can accurately determine the position of the autonomous vehicle."
244,16862630,2020.04.30,20210342647,2021.11.04,20210342647,2021.11.04,,,SEMANTIC ADVERSARIAL GENERATION BASED FUNCTION TESTING METHOD IN AUTONOMOUS DRIVING,"G06K9/62,G06N3/08,G06T9/00",Robert Bosch GmbH,"A system includes a camera configured to obtain image information from objects. The system also includes a processor in communication with the camera and programmed to receive an input data including the image information, encode the input via an encoder, obtain a latent variable defining an attribute of the input data, generate a sequential reconstruction of the input data utilizing at least the latent variable and an adversarial noise, obtain a residual between the input data and the sequential reconstruction utilizing a comparison of at least the input and the reconstruction to learn a mean shift in latent space, and output a mean shift indicating a test result of the input compared to the adversarial noise based on the comparison."
245,16516017,2019.07.18,,,11120275,2021.09.14,11120275,2021.09.14,"Visual perception method, apparatus, device, and medium based on an autonomous vehicle","G06K9/00,B60Q9/00,G06N3/08","Baidu Online Network Technology (Beijing) Co., Ltd.","The present disclosure provides a visual perception method, an apparatus, a device and a medium based on an autonomous vehicle, the method includes inputting an obtained first visual perception image collected by the autonomous vehicle into a first neural network model, recognizing multi-channel feature information of at least one target recognition object to be recognized, to eliminate redundant feature information in the first visual perception image; further, inputting the multi-channel feature information of the at least one target recognition object to be recognized into at least one sub-neural network model in a second neural network model respectively, to obtain at least one target recognition object; where there is a one to one correspondence between the target recognition object and the sub-neural network model. The present disclosure improves the speed of recognizing the target recognition object, thereby improving sensitivity of the autonomous vehicle and ensuring driving safety of the autonomous vehicle."
246,17143715,2021.01.07,20210213977,2021.07.15,20210213977,2021.07.15,,,Nearby Driver Intent Determining Autonomous Driving System,"B60W60/00,B60W30/095,G06K9/00,G06N3/08,G06K9/62",Allstate Insurance Company,"An autonomous driving system capable of determining an intent of a nearby human driver and taking an action to avoid a collision is presented. The system may receive a current state of a nearby vehicle, determine an expected action of a human driver of the nearby vehicle by determining a result of a reward function, the reward function being a linear combination of feature functions, where each feature function is a neural network which has been trained to reproduce a corresponding algorithmic feature function, and based on the determined expected action of the human driver, taking an action to avoid a collision."
247,17187787,2021.02.27,20210179132,2021.06.17,20210179132,2021.06.17,,,CONTEXTUAL AUTONOMOUS VEHICLE SUPPORT THROUGH PICTORIAL INTERACTION,"B60W50/14,G05D1/00,B60K35/00",GM GLOBAL TECHNOLOGY OPERATIONS LLC,"An autonomous vehicle including a sensor system that outputs a sensor signal indicative of a condition of the autonomous vehicle. The vehicle also includes a user interface device with a display. A computing system determines, based upon a profile of the passenger, that support is to be provided pictorially to the passenger when the support is provided to the passenger. The computing system further detects occurrence of an event that has been identified as potentially causing discomfort to the passenger. The computing system yet further sets a predefined pictorial support message defined in an account corresponding to the event maintained in a database prior to occurrence of the event as a pictorial support message to be presented to the passenger. The computing system additionally causes the display to present the pictorial support message, wherein the pictorial support message solicits feedback from the passenger of the autonomous vehicle."
248,17135171,2020.12.28,20210146932,2021.05.20,20210146932,2021.05.20,,,Control Of Autonomous Vehicle Based On Determined Yaw Parameter(s) of Additional Vehicle,"B60W40/04,B60W30/095,G05D1/02,G05D1/00,G06N20/00,G06K9/62,G01S17/931,G01S17/89","Aurora Innovation, Inc.","Determining yaw parameter(s) (e.g., at least one yaw rate) of an additional vehicle that is in addition to a vehicle being autonomously controlled, and adapting autonomous control of the vehicle based on the determined yaw parameter(s) of the additional vehicle. For example, autonomous steering, acceleration, and/or deceleration of the vehicle can be adapted based on a determined yaw rate of the additional vehicle. In many implementations, the yaw parameter(s) of the additional vehicle are determined based on data from a phase coherent Light Detection and Ranging (LIDAR) component of the vehicle, such as a phase coherent LIDAR monopulse component and/or a frequency-modulated continuous wave (FMCW) LIDAR component."
249,16711187,2019.12.11,20200353941,2020.11.12,20200353941,2020.11.12,,,"AUTOMATIC DRIVING PROCESSING SYSTEM, SYSTEM ON CHIP AND METHOD FOR MONITORING PROCESSING MODULE","B60W50/04,B60W50/02,B60W50/035","Beijing Baidu Netcom Science And Technology Co., LTD.","An automatic processing system, a system on chip and a method for monitoring a processing module are described herein. The automatic driving processing system comprises: an automatic driving processing module, configured for receiving an input data stream and processing the input data stream based on a deep learning model so as to generate a processing result; a fault detection module, configured for generating a control signal and a fault detection stimulating data stream, and receiving the processing result from the automatic driving processing module; and a multi-way selection module, configured for receiving an automatic driving data stream as well as the control signal and the fault detection stimulating data stream, and selectively outputting the automatic driving data stream or the fault detection stimulating data stream to the automatic driving processing module based on the control signal, as an input data stream."
250,16916055,2020.06.29,20200331489,2020.10.22,20200331489,2020.10.22,,,CONTEXTUAL AUTONOMOUS VEHICLE SUPPORT THROUGH WRITTEN INTERACTION,"B60W50/14,B60K35/00,G05D1/00",GM GLOBAL TECHNOLOGY OPERATIONS LLC,"An autonomous vehicle including a sensor system that outputs a sensor signal indicative of a condition of the autonomous vehicle. The vehicle also includes a user interface device with a display. A computing system determines, based upon a profile of the passenger, that support is to be provided textually to the passenger when the support is provided to the passenger. The computing system further detects occurrence of an event that has been identified as potentially causing discomfort to the passenger. The computing system yet further sets a predefined support message defined in an account corresponding to the event maintained in a database prior to occurrence of the event as a support message to be presented to the passenger. The computing system additionally causes the display to present the support message textually, wherein the textual support message solicits feedback from the passenger of the autonomous vehicle."
251,16534349,2019.08.07,20200050194,2020.02.13,20200050194,2020.02.13,,,APPARATUS AND METHOD FOR SWITCHING CONTROL AUTHORITY OF AUTONOMOUS VEHICLE,"G05D1/00,G06K9/00,B60W40/09,G06N20/00","Hyundai Mobis Co., Ltd.","An apparatus for switching a control authority of an autonomous vehicle may include: a capturing unit configured to capture an image of the inside of a vehicle and provide the captured image; a storage unit configured to store learning information and weights for inferring the presence and age of a passenger and whether a driver holds a steering wheel, based on deep learning; and a control unit configured to determine whether the passenger can drive the vehicle, by inferring the presence and age of the passenger through the learning information and weights stored in the storage unit from the image inputted from the capturing unit according to a manual mode switch request, infer whether the driver holds the steering wheel, and switch the control authority of the vehicle to a manual mode."
252,16516017,2019.07.18,20200005051,2020.01.02,20200005051,2020.01.02,,,"Visual Perception Method, Apparatus, Device, and Medium Based on an Autonomous Vehicle","G06K9/00,G06N3/08,B60Q9/00","Baidu Online Network Technology (Beijing) Co., Ltd.,Baidu Online Network Technology (Beijing) Co., Ltd.","The present disclosure provides a visual perception method, an apparatus, a device and a medium based on an autonomous vehicle, the method includes inputting an obtained first visual perception image collected by the autonomous vehicle into a first neural network model, recognizing multi-channel feature information of at least one target recognition object to he recognized, to eliminate redundant feature information in the first visual perception image; further, inputting the multi-channel feature information of the at least one target recognition object to be recognized into at least one sub-neural network model in a second neural network model respectively, to obtain at least one target recognition object; where there is a one to one correspondence between the target recognition object and the sub-neural network model. The present disclosure improves the speed of recognizing the target recognition object, thereby improving sensitivity of the autonomous vehicle and ensuring driving safety of the autonomous vehicle."
253,16552448,2019.08.27,20190382000,2019.12.19,20190382000,2019.12.19,,,APPARATUS AND METHOD FOR AUTOMATIC DRIVING,"B60W30/02,G05D1/00,B60W40/08",LG Electronics Inc.,"An autonomous driving method includes: inferring a condition of a passenger based on sensor information about the passenger received from a sensor of the vehicle; receiving external environment information of the vehicle from the sensor of the vehicle; controlling the vehicle to allow the internal environment of the vehicle to be adjusted, based on the condition of the passenger and the external environment information determining whether there is a change in the inferred condition of the passenger, after the internal environment of the vehicle is adjusted; and controlling the vehicle to allow the internal environment of the vehicle to be readjusted, based on the determined results, the adjusted internal environment information of the vehicle, and the external environment information."
254,16512907,2019.07.16,20190340783,2019.11.07,20190340783,2019.11.07,,,"Autonomous Vehicle Based Position Detection Method and Apparatus, Device and Medium","G06T7/73,G06N3/08,G06N3/04,G05D1/00,G06T7/62,G06K9/00","Baidu Online Network Technology (Beijing) Co., Ltd.,Baidu Online Network Technology (Beijing) Co., Ltd.","The present application provides autonomous vehicle based position detection method and apparatus, a device and a medium, where the method includes: identifying an obtained first visual perception image according to an underlying neural network layer in a slender convolution kernel neural network model to determine feature information of the target linear object image, and identifying the feature information of the target linear object image by using a high-level neural network layer in the slender convolution kernel neural network model to determine size information of the target linear object image; further, matching the size information of the target linear object image with preset coordinate system map information to determine a position of the autonomous vehicle. Embodiments of the present application can accurately determine the position of the autonomous vehicle."
255,17669250,2022.02.10,20220286614,2022.09.08,20220286614,2022.09.08,,,"VIBRATION TYPE ACTUATOR CONTROL APPARATUS, VIBRATION TYPE DRIVING APPARATUS HAVING THE SAME, INTERCHANGEABLE LENS, IMAGING APPARATUS, AND AUTOMATIC STAGE","H04N5/232,H02N2/00",CANON KABUSHIKI KAISHA,"A vibration type actuator control apparatus, which uses a vibration from a vibrator to move a contact member, includes a control unit and a drive unit. The control unit includes first and second learned models, each having a neural network, and outputs control amounts for the drive unit to move the contact member. When a contact member moving target velocity is input, the first learned model outputs a first control amount as one of the control amounts. When a positional deviation is input, the second learned model outputs a second control amount as one of the control amounts. The drive unit moves the contact member using a value based on the first and second control amounts. The positional deviation is in association with a difference between a target position for moving the contact member and a detected position detected when the contact member is moved relative to the vibrator."
256,16764228,2019.03.11,,,11097813,2021.08.24,11097813,2021.08.24,Unmanned surface vehicle for aquatic ecosystem monitoring and restoration and control method for aquatic ecosystem restoration,"B63B35/00,G01N21/84,G01N33/18",CAS (HEFEI) INSTITUTE OF TECHNOLOGY INNOVATION,"The present invention discloses an Unmanned Surface Vehicle (USV) for aquatic ecosystem monitoring and restoration and a control method for aquatic ecosystem restoration. A control cabin, a water-quality monitoring cabin, and a water treatment equipment compartment are arranged inside a cabin of a hull of the USV for aquatic ecosystem monitoring and restoration, and a water-surface photographing device and a remote communications device are arranged outside the cabin; the control cabin is connected to the water-quality monitoring cabin, the water-surface photographing device, and the water treatment equipment compartment; the water quality parameters include five conventional water quality parameters and eutrophication-based water quality parameters; and the remote communications device is connected to the water-quality monitoring cabin and the water treatment equipment compartment. The present invention can implement real-time, automatic, and dynamic aquatic ecosystem monitoring, early warning of the water pollution, and self-adaptive ecological restoration based on an artificial intelligent control algorithm."
257,16764228,2019.03.11,20210221479,2021.07.22,20210221479,2021.07.22,,,UNMANNED SURFACE VEHICLE FOR AQUATIC ECOSYSTEM MONITORING AND RESTORATION AND CONTROL METHOD FOR AQUATIC ECOSYSTEM RESTORATION,"B63B35/00,G01N33/18,G01N21/84",CAS (HEFEI) INSTITUTE OF TECHNOLOGY INNOVATION,"The present invention discloses an Unmanned Surface Vehicle (USV) for aquatic ecosystem monitoring and restoration and a control method for aquatic ecosystem restoration. A control cabin, a water-quality monitoring cabin, and a water treatment equipment compartment are arranged inside a cabin of a hull of the USV for aquatic ecosystem monitoring and restoration, and a water-surface photographing device and a remote communications device are arranged outside the cabin; the control cabin is connected to the water-quality monitoring cabin, the water-surface photographing device, and the water treatment equipment compartment; the water quality parameters include five conventional water quality parameters and eutrophication-based water quality parameters; and the remote communications device is connected to the water-quality monitoring cabin and the water treatment equipment compartment. The present invention can implement real-time, automatic, and dynamic aquatic ecosystem monitoring, early warning of the water pollution, and self-adaptive ecological restoration based on an artificial intelligent control algorithm."
258,17034809,2020.09.28,20210116922,2021.04.22,20210116922,2021.04.22,,,Integrated Automated Driving System for Maritime Autonomous Surface Ship (MASS),"G05D1/02,B63B49/00,G06N3/08,G06K9/62,H04L12/40","Wuhan University of Technology,Wuhan University of Technology","The present invention discloses an integrated automated driving system for a maritime autonomous surface ship (MASS). The integrated automated driving system for a MASS includes a perception module for perceiving navigational environment of a MASS and obtaining real-time dynamic information of a navigation channel, hydrology, a state of the MASS and traffic environment; a communication system for transmitting data and instructions between the MASS and a shore base as well as between system modules; a data processing module for processing information obtained by the perception module; a decision-making module for identifying a current operating status of the MASS and environment according to data outputted by the data processing module, selecting actions to be taken, and generating operating instructions corresponding to the action; and an execution module for receiving operating instructions sent from the decision-making module and controlling a propeller and a rudder of the MASS through a proportional-integral-derivative (PID) controller."
259,16784009,2020.02.06,20200250485,2020.08.06,20200250485,2020.08.06,,,SEMANTIC OCCUPANCY GRID MANAGEMENT IN  ADAS/AUTONOMOUS DRIVING,"G06K9/62,G06K9/00,G05D1/02",Texas Instruments Incorporated,"In described examples, an apparatus includes an object detection (OD) network that is configured to generate OD polygons in response to a received at least one camera image and a semantic segmentation (SS) network that is configured to generate SS data in response to the received at least one camera image. A processor is configured to generate an updated occupancy grid in response to the OD polygons and the SS data. A vehicle is optionally configured to respond to a driving action generated in response to the updated occupancy grid."
260,17749841,2022.05.20,20220289180,2022.09.15,20220289180,2022.09.15,,,Multi-Task Machine-Learned Models for Object Intention Determination in Autonomous Driving,"B60W30/095,G05D1/02,G06N20/00,G06V20/58","UATC, LLC","Generally, the disclosed systems and methods utilize multi-task machine-learned models for object intention determination in autonomous driving applications. For example, a computing system can receive sensor data obtained relative to an autonomous vehicle and map data associated with a surrounding geographic environment of the autonomous vehicle. The sensor data and map data can be provided as input to a machine-learned intent model. The computing system can receive a jointly determined prediction from the machine-learned intent model for multiple outputs including at least one detection output indicative of one or more objects detected within the surrounding environment of the autonomous vehicle, a first corresponding forecasting output descriptive of a trajectory indicative of an expected path of the one or more objects towards a goal location, and/or a second corresponding forecasting output descriptive of a discrete behavior intention determined from a predefined group of possible behavior intentions."
261,16892853,2020.06.04,,,11467586,2022.10.11,11467586,2022.10.11,Gridlock solver for motion planning system of an autonomous vehicle,"G05D1/02,G01C21/34,G05D1/00,G01C21/20","UATC, LLC","The present disclosure provides autonomous vehicle systems and methods that include or otherwise leverage a motion planning system that solves gridlock as part of determining a motion plan for an autonomous vehicle (AV). In particular, a scenario generator within a motion planning system can determine one or more keep clear areas associated with the lane sequence, each keep clear area indicative of a region along the nominal path in which gridlock prevention is desired. A gridlock constraint can be generated for each of the one or more keep clear areas, each constraint being defined as a constraint area in a multi-dimensional space. A low-cost trajectory path can be determined through a portion of the multi-dimensional space that minimizes exposure to the constraint areas and that is consistent with all constraints generated for the one or more objects of interest and the one or more keep clear areas."
262,16401615,2019.05.02,,,11455891,2022.09.27,11455891,2022.09.27,Reducing autonomous vehicle downtime and idle data usage,"G08G1/00,G08G1/01,G08G1/09,G06Q10/02,G06Q50/30,G08G1/065","Uber Technologies, Inc.","Systems and methods for controlling an autonomous vehicle to reduce idle data usage and vehicle downtime are provided. In one example embodiment, a computing system can obtain data associated with autonomous vehicle(s) that are online with a service entity. The computing system can obtain data indicative of the geographic area with an imbalance in a number of vehicles associated with the geographic area. The computing system can determine a first autonomous vehicle for re-positioning with respect to the geographic area based at least in part on the data associated with the one or more autonomous vehicles and the data indicative of the geographic. The computing system can communicating data indicative of a first re-positioning assignment associated with the first autonomous vehicle. In some implementations, the computing system can generate vehicle service incentive to entice a vehicle provider to re-position its autonomous vehicles with respect to the geographic area."
263,17227002,2021.04.09,20220326023,2022.10.13,20220326023,2022.10.13,,,VERIFYING RELIABILITY OF DATA USED FOR AUTONOMOUS DRIVING,"G01C21/30,G06N20/00,B60W60/00,G01C21/00","Zoox, Inc.,Zoox, Inc.","Techniques for verifying a reliability of map data are discussed herein. In some examples, map data can be used by a vehicle, such as an autonomous vehicle, to traverse an environment. Sensor data (e.g., image data, lidar data, etc.) can be received from a sensor associated with a vehicle and may be used to generate an estimated map and confidence values associated with the estimated map. When the sensor data is image data, images data from multiple perspectives or different time instances may be combined to generate the estimated map. The estimated map may be compared to a stored map or to a proposed vehicle trajectory or corridor to determine a reliability of the stored map data."
264,16669097,2019.10.30,,,11440494,2022.09.13,11440494,2022.09.13,Detecting and responding to autonomous vehicle incidents,"H04L12/28,B60R21/0136,G05D1/00,G07C5/00,G07C5/08,B60R21/34,B60R21/01,B60R21/00",State Farm Mutual Automobile Insurance Company,"Methods and systems for assessing, detecting, and responding to malfunctions involving components of autonomous vehicles and/or smart homes are described herein. Autonomous operation features and related components can be assessed using direct or indirect data regarding operation. Vehicle collision and/or smart home incident monitoring, damage detection, and responses are also described, with particular focus on the particular challenges associated with incident response for unoccupied vehicles and/or smart homes. Operating data associated with the autonomous vehicle and/or smart home may be received. Within the operating, an unusual condition indicative of a likelihood of incident may be detected. Based on the unusual condition, it may be determined that the incident occurred. Accordingly, a response to the incident may be determined. The response may be implemented by the autonomous vehicle and/or smart home."
265,17201235,2021.03.15,20220289248,2022.09.15,20220289248,2022.09.15,,,VEHICLE AUTONOMOUS MODE OPERATING PARAMETERS,"B60W60/00,B60W50/00,G06N20/00,B60K35/00,B60W40/02,B60W50/08","Ford Global Technologies, LLC,Ford Global Technologies, LLC","While an autonomous mode is activated, a vehicle is operated based on operating parameters for the autonomous mode. The operating parameters include at least one of a vehicle speed or a following distance. Upon detecting a user input to control vehicle operation, vehicle operation is transitioned to a nonautonomous mode, and a count of a number of received user inputs to control vehicle operation is incremented. Upon determining that the count of received of user inputs to control vehicle operation is greater than a threshold, the operating parameters for the autonomous mode are updated. Then, upon determining to transition from the nonautonomous mode to the autonomous mode, the vehicle is operated based on the updated operating parameters."
266,16744250,2020.01.16,20220244736,2022.08.04,20220244736,2022.08.04,,,AUTONOMOUS VEHICLE OPERATION FEATURE MONITORING AND EVALUATION OF EFFECTIVENESS,"G05D1/02,B60W30/18,B60W30/09,B60W10/20,G06Q40/08,G06N20/00,G05D1/00,B60W10/04",State Farm Mutual Automobile Insurance Company,"Methods and systems for monitoring use and determining risks associated with operation of a vehicle having one or more autonomous operation features are provided. According to certain aspects, operating data may be recorded during operation of the vehicle. This may include information regarding the vehicle, the vehicle environment, use of the autonomous operation features, and/or control decisions made by the features. The control decisions may include actions the feature would have taken to control the vehicle, but which were not taken because a vehicle operator was controlling the relevant aspect of vehicle operation at the time. The operating data may be recorded in a log, which may then be used to determine risk levels associated with vehicle operation based upon risk levels associated with the autonomous operation features. The risk levels may further be used to adjust an insurance policy associated with the vehicle."
267,17173730,2021.02.11,20220250642,2022.08.11,20220250642,2022.08.11,,,HIGH DEFINITION MAP UPDATES USING ASSETS GENERATED BY AN AUTONOMOUS VEHICLE FLEET,"B60W60/00,G01C21/36,G08G1/00,G01C21/00","GM Cruise Holdings, LLC","The disclosed technology provides solutions for updating high definition maps based on low resolution map assets. In some aspects, a process of receiving a change detection relating to a change in the real world is provided. The process can include steps for receiving autonomous vehicle drive data based on the change in the real world, generating low resolution tile data based on the autonomous vehicle drive data based on the change in the real world, generating updated semantic data based on the low resolution tile data generated, and providing the updated semantic data to an autonomous vehicle to update a proximate area of the change in the real world of a base map of the autonomous vehicle. Systems and machine-readable media are also provided."
268,16863341,2020.04.30,,,11377120,2022.07.05,11377120,2022.07.05,Autonomous vehicle control based on risk-based interactions,"B60W60/00,B60W30/095,B60W30/16,G08G1/00,B60W10/20,B60W10/18","UATC, LLC","Systems, methods, tangible non-transitory computer-readable media, and devices associated with vehicle control based on risk-based interactions are provided. For example, vehicle data and perception data can be accessed. The vehicle data can include the speed of an autonomous vehicle in an environment. The perception data can include location information and classification information associated with an object in the environment. A scenario exposure can be determined based on the vehicle data and perception data. Prediction data including predicted trajectories of the object can be accessed. Expected speed data can be determined based on hypothetical speeds and hypothetical distances between the vehicle and the object. A speed profile that satisfies a threshold criteria can be determining based on the scenario exposure, the prediction data, and the expected speed data, over a distance. A motion plan to control the autonomous vehicle can be generated based on the speed profile."
269,16672277,2019.11.01,,,11392123,2022.07.19,11392123,2022.07.19,Crowd sourcing data for autonomous vehicle navigation,"G01C21/26,G01S17/00,G06F17/00,G05D1/00,G06F16/29,G06F16/23,G01C21/32,G06V20/56,G06V20/62,G06V20/58,B60W30/18,G01C21/14,G05D1/02,G08G1/0967,B62D15/02,G08G1/0962,G08G1/16,G01C21/34,G01C21/36,G01C21/16,G08G1/01,B60W30/14,G08G1/0968,H04L67/12,G06T7/00,G01S19/10",MOBILEYE VISION TECHNOLOGIES LTD.,"Systems and methods are provided for constructing, using, and updating the sparse map for autonomous vehicle navigation. A method may comprise processing, by a mapping server, collected navigation information from a plurality of vehicles obtained by sensors coupled to the plurality of vehicles, wherein the navigation information describes road lanes of a road segment; collecting data about landmarks identified proximate to the road segment, the landmarking including a traffic sign; generating, by the mapping server, an autonomous vehicle map for the road segment, wherein the autonomous vehicle map includes a spline corresponding to a lane in the road segment and the landmarks identified proximate to the road segment; and distributing, by the mapping server, the autonomous vehicle map to an autonomous vehicle for use in autonomous navigation over the road segment."
270,16734947,2020.01.06,,,11385657,2022.07.12,11385657,2022.07.12,Systems and methods for controlling autonomous vehicles that provide a vehicle service to users,"G05D1/02,B60R16/037,B60R25/24,G01C21/34,G01C21/36,G05D1/00,G08G1/00,G08G1/005,G08G1/01,G08G1/09,G08G1/0962,G08G1/0968,G08G1/123,G08G1/14,G08G1/0967,H04W4/46,H04W4/40","Uber Technologies, Inc.","Systems and methods for controlling autonomous vehicles are provided. In one example embodiment, a computer implemented method includes obtaining data indicative of a location associated with a user to which an autonomous vehicle is to travel. The autonomous vehicle is to travel along a first vehicle route that leads to the location. The method includes obtaining traffic data associated with a geographic area that includes the location. The method includes determining an estimated traffic impact of the autonomous vehicle on the geographic area based at least in part on the traffic data. The method includes determining vehicle action(s) based at least in part on the estimated traffic impact and causing the autonomous vehicle to perform the vehicle action(s) that include at least one of stopping the autonomous vehicle at least partially in a travel way within a vicinity of the location or travelling along a second vehicle route."
271,17585650,2022.01.27,20220171390,2022.06.02,20220171390,2022.06.02,,,Discrete Decision Architecture for Motion Planning System of an Autonomous Vehicle,"G05D1/00,B60W30/095,B60W30/12,B60W50/00,B60W30/16,G05D1/02,B60W30/18,G01C21/20,G01C21/34","UATC, LLC","The present disclosure provides autonomous vehicle systems and methods that include or otherwise leverage a motion planning system that generates constraints as part of determining a motion plan for an autonomous vehicle (AV). In particular, a scenario generator within a motion planning system can generate constraints based on where objects of interest are predicted to be relative to an autonomous vehicle. A constraint solver can identify navigation decisions for each of the constraints that provide a consistent solution across all constraints. The solution provided by the constraint solver can be in the form of a trajectory path determined relative to constraint areas for all objects of interest. The trajectory path represents a set of navigation decisions such that a navigation decision relative to one constraint doesn't sacrifice an ability to satisfy a different navigation decision relative to one or more other constraints."
272,17109508,2020.12.02,20220169279,2022.06.02,20220169279,2022.06.02,,,SUNLIGHT PROCESSING FOR AUTONOMOUS VEHICLE CONTROL,"B60W60/00,B60W10/30,B60W50/14,G02B7/00,G02B5/30,G05D1/02,G05D1/00","Micron Technology, Inc.","Systems, methods, and apparatus related to sensor data processing for a vehicle to improve operation when sunlight or other bright light enters a sensor of the vehicle. In one approach, adjustable filtering is configured for a sensor of a vehicle. In one example, an optical filter is positioned on the path of light that reaches an image sensor of a camera. For example, the filtering improves ability to stay in adaptive cruise control when driving into direct sunlight at sunset. The optical filters can have controllable properties such as polarization. In one example, a controller of the vehicle is configured to automatically adjust the properties of the optical filter to improve image quality to improve object recognition. In another example, a camera is configured with composite vision that uses sensors in different radiation spectrums (e.g., visible light, and infrared light). The composite vision can provide enhanced vision capability for an autonomous vehicle that is driving in the direction of the sun."
273,17559422,2021.12.22,20220114805,2022.04.14,20220114805,2022.04.14,,,AUTONOMOUS VEHICLE PERCEPTION MULTIMODAL SENSOR DATA MANAGEMENT,"G06V10/774,G06N3/08,G06V10/80,G06V10/32","Julio Fernando Jarquin Arroyo,Ignacio J. Alvarez,Cornelius Buerkle,Fabian Oboril","The automated driving perception systems described herein provide technical solutions for technical problems facing navigation sensors for autonomous vehicle navigation. These systems may be used to combine inputs from multiple navigation sensors to provide a multimodal perception system. These multimodal perception systems may augment raw data within a development framework to improve performance of object detection, classification, tracking, and sensor fusion under varying external conditions, such as adverse weather and light, as well as possible sensor errors or malfunctions like miss-calibration, noise, and dirty or faulty sensors. This augmentation may include injection of noise, occlusions, and misalignments from raw sensor data, and may include ground-truth labeling to match the augmented data. This augmentation provides improved robustness of the trained perception algorithms against calibration, noise, occlusion, and faults that may exist in real-world scenarios."
274,17547340,2021.12.10,20220101600,2022.03.31,20220101600,2022.03.31,,,System and Method for Identifying Travel Way Features for Autonomous Vehicle Motion Control,"G06T17/00,G06T7/10,G06T17/10,G06T7/70","UATC, LLC","Systems and methods for identifying travel way features in real time are provided. A method can include receiving two-dimensional and three-dimensional data associated with the surrounding environment of a vehicle. The method can include providing the two-dimensional data as one or more input into a machine-learned segmentation model to output a two-dimensional segmentation. The method can include fusing the two-dimensional segmentation with the three-dimensional data to generate a three-dimensional segmentation. The method can include storing the three-dimensional segmentation in a classification database with data indicative of one or more previously generated three-dimensional segmentations. The method can include providing one or more datapoint sets from the classification database as one or more inputs into a machine-learned enhancing model to obtain an enhanced three-dimensional segmentation. And, the method can include identifying one or more travel way features based at least in part on the enhanced three-dimensional segmentation."
275,17079434,2020.10.24,20220128367,2022.04.28,20220128367,2022.04.28,,,SUBSTITUTE AUTONOMOUS VEHICLE DATA,"G01C21/34,G05D1/00,G05D1/02",International Business Machines Corporation,"A navigation request is detected. The navigation request includes a destination for an autonomous vehicle from a starting location. A route is identified from the starting location to destination based on the navigation request. A regulator lookup is performed related to the route based on the navigation request. The regulator lookup is related to an owner of privacy data for one or more regulators. In response to the regulator lookup, a conditional allowance related to the route is received. The conditional allowance indicates that one or more autonomous vehicle sensors of the autonomous vehicle may not capture data related to a first property of a first regulator. the first property is located proximate to the route. The one or more autonomous vehicles sensors of the autonomous vehicle are restricted in response to the conditional allowance."
276,16433026,2019.06.06,,,11242051,2022.02.08,11242051,2022.02.08,Autonomous vehicle action communications,"B60W30/095,B60W10/20,B60W30/16,B60W30/12,B60W10/18,G08G1/16,B60W30/18,G05D1/02,G05D1/00,B60W10/04",State Farm Mutual Automobile Insurance Company,"Methods and systems for communicating between autonomous vehicles are described herein. Such communication may be performed for signaling, collision avoidance, path coordination, and/or autonomous control. A first autonomous vehicle may receive a communication from a second autonomous vehicle travelling on the same road as the first autonomous vehicle, where the communication includes an indication of a maneuver which will be performed by the second autonomous vehicle. The first autonomous vehicle may then analyze the communication to identify a first maneuver for the first autonomous vehicle in response to the second maneuver performed by the second autonomous vehicle. Thus, the first autonomous vehicle may move in accordance with the first maneuver."
277,17515172,2021.10.29,20220051490,2022.02.17,20220051490,2022.02.17,,,REAL-TIME SELECTION OF DATA TO COLLECT IN AUTONOMOUS VEHICLE,"G07C5/08,G05D1/00,H04W4/38,H04W4/40,G07C5/00","Micron Technology, Inc.","A method for an autonomous vehicle includes: controlling at least one system of the vehicle by a host system; monitoring, by a memory device, data associated with operation of the vehicle; determining, by the memory device based on the monitoring, first data to collect from the vehicle; collecting, by the memory device independently of the host system, the first data; and storing, by the memory device, the collected first data in a non-volatile memory."
278,16684689,2019.11.15,,,11217012,2022.01.04,11217012,2022.01.04,System and method for identifying travel way features for autonomous vehicle motion control,"G06T17/10,G06T7/10,G06T17/00,G06T7/70","UATC, LLC","Systems and methods for identifying travel way features in real time are provided. A method can include receiving two-dimensional and three-dimensional data associated with the surrounding environment of a vehicle. The method can include providing the two-dimensional data as one or more input into a machine-learned segmentation model to output a two-dimensional segmentation. The method can include fusing the two-dimensional segmentation with the three-dimensional data to generate a three-dimensional segmentation. The method can include storing the three-dimensional segmentation in a classification database with data indicative of one or more previously generated three-dimensional segmentations. The method can include providing one or more datapoint sets from the classification database as one or more inputs into a machine-learned enhancing model to obtain an enhanced three-dimensional segmentation. And, the method can include identifying one or more travel way features based at least in part on the enhanced three-dimensional segmentation."
279,17002650,2020.08.25,20210398014,2021.12.23,20210398014,2021.12.23,,,REINFORCEMENT LEARNING BASED CONTROL OF IMITATIVE POLICIES FOR AUTONOMOUS DRIVING,"G06N20/00,G06N7/00,G05D1/02","TOYOTA RESEARCH INSTITUTE, INC.,THE BOARD OF TRUSTEES OF THE LELAND STANFORD JUNIOR UNIVERSITY,TOYOTA RESEARCH INSTITUTE, INC.,THE BOARD OF TRUSTEES OF THE LELAND STANFORD JUNIOR UNIVERSITY","A method for controlling an ego agent includes periodically receiving policy information comprising a spatial environment observation and a current state of the ego agent. The method also includes selecting, for each received policy information, a low-level policy from a number of low-level policies. The low-level policy may be selected based on a high-level policy. The method further includes controlling an action of the ego agent based on the selected low-level policy."
280,16887837,2020.05.29,20210369516,2021.12.02,20210369516,2021.12.02,,,PERCEPTION SUPPORTING HARDWARE FEATURES FOR A WHEELCHAIR ACCESSIBLE AUTONOMOUS VEHICLE,"A61G3/08,A61G3/06,B60P1/43,G05D1/00,G06K9/00",GM Cruise Holdings LLC,"The subject disclosure relates to features for improving wheelchair accessibility in autonomous vehicles (AVs) and in particular, for enabling automatic ingress/egress of a wheelchair ramp to facilitate the loading and unloading of a passenger wheelchair. In some aspects, a process of the disclosed technology includes steps for identifying one or more visual reference features on at least one surface of an autonomous vehicle (AV), automatically deploying a ramp to facilitate ingress of a wheelchair, and tracking ingress of the wheelchair based on the one or more visual reference features. Systems and machine-readable media are also provided."
281,17340881,2021.06.07,20210365042,2021.11.25,20210365042,2021.11.25,,,Systems and Methods for Controlling Autonomous Vehicles that Provide a Vehicle Service to Users,"G05D1/02,G05D1/00,G01C21/34,G01C21/36,G08G1/01,G08G1/0962,G08G1/0967,G08G1/14,G08G1/00,G08G1/005,G08G1/0968,B60R16/037,B60R25/24,G08G1/09,G08G1/123,H04W4/46","Uber Technologies, Inc.","Systems and methods for determining autonomous vehicle user boarding times are provided. In one example embodiment, a computer implemented method includes obtaining location data associated with a user device associated with a user. The method includes determining an estimated time until the user starts boarding the autonomous vehicle based at least in part on the location data associated with the user device. The method includes obtaining data associated with the user. The method includes determining an estimated time of boarding duration for the user based at least in part on the data associated with the user. The method includes determining an estimated time until the user completes boarding of the autonomous vehicle based at least in part on the estimated time until the user starts boarding the autonomous vehicle and the estimated time of boarding duration for the user."
282,16266556,2019.02.04,,,11189112,2021.11.30,11189112,2021.11.30,Autonomous vehicle sensor malfunction detection,"G07C5/08,G05D1/00",State Farm Mutual Automobile Insurance Company,"Methods and systems for assessing, detecting, and responding to malfunctions involving components of autonomous vehicles and/or smart homes are described herein. Malfunctions may be detected by receiving sensor data from a plurality of sensors. One of these sensors may be selected for assessment. An electronic device may obtain from the selected sensor a set of signals. When the set of signals includes signals that are outside of a determined range of signals associated with proper functioning for the selected sensor, it may be determined that the selected sensor is malfunctioning. In response, an action may be performed to resolve the malfunction and/or mitigate consequences of the malfunction."
283,17366409,2021.07.02,20210365037,2021.11.25,20210365037,2021.11.25,,,"AUTOMATIC DRIVING SYSTEM FOR GRAIN PROCESSING, AUTOMATIC DRIVING METHOD, AND AUTOMATIC IDENTIFICATION METHOD","G05D1/02,G06T7/00,G06T7/11,G06K9/46,G06K9/00,A01D41/127","FJ Dynamics Technology Co., Ltd","An automatic driving system for grain processing, an automatic driving method, and an automatic identification method is illustrated. The automatic driving system includes a grain processing host, an image acquiring device, and an image processing system. The image acquiring device is provided in the grain processing host. The image acquiring device acquires at least one image around the grain processing host. The image processing system identifies areas in the image by utilizing an image segmentation and identification technique on the basis of the image acquired by the image acquiring device. The grain processing host automatedly controls driving based on the areas identified by the image processing system."
284,17366404,2021.07.02,20210360850,2021.11.25,20210360850,2021.11.25,,,"AUTOMATIC DRIVING SYSTEM FOR GRAIN PROCESSING, AUTOMATIC DRIVING METHOD, AND PATH PLANNING METHOD","A01D34/00,G05D1/02,G06T7/70,G06T7/11","FJ Dynamics Technology Co., Ltd","An automatic driving system for grain processing, and an automatic driving method and a path planning method is illustrated. The automatic driving system for grain processing comprises a grain processing host, an image processing system, a path planning system, and an image acquisition device. The image processing system is arranged on the grain processing host and acquires at least one image of farmland surrounding the grain processing host. The image processing system identifies, based on an image segmentation and identification method, an area in the image; and the path planning system plans, based on the area identified by the image processing system, at least one driving planning path. The grain processing host automatically controls driving according to the driving planning path planned by the path planning system."
285,16370696,2019.03.29,,,11181922,2021.11.23,11181922,2021.11.23,Extension of autonomous driving functionality to new regions,"G05D1/02,G05D1/00,G06F16/29","Zoox, Inc.","Autonomous vehicles use accurate and detailed maps for navigation. Expanding functionality of an autonomous vehicle to a new, e.g., unmapped, region can include determining drivable surface segments of the new region and comparing the segments to segments or classes of segments from an already-mapped region. Segments of the new region that are similar to segments from the mapped region can be identified as potentially navigable. An autonomous vehicle can travel through the new region via those segments indicated as navigable. In addition, during travel through the new region, data may be collected using sensors on the autonomous vehicle to map additional portions of the region and/or confirm a driving ability in the new region. Functionality of an autonomous vehicle may be limited based on how similar the segments are to one another."
286,17278018,2019.09.26,20210350145,2021.11.11,20210350145,2021.11.11,,,"OBJECT RECOGNITION METHOD OF AUTONOMOUS DRIVING DEVICE, AND AUTONOMOUS DRIVING DEVICE","G06K9/00,G06T7/246,G06K9/46,G06K9/20,G06T7/70,H04N5/235,H04N9/04,B60W60/00,G05D1/02,G06N20/00","SAMSUNG ELECTRONICS CO., LTD.,SAMSUNG ELECTRONICS CO., LTD.","Disclosed is an object recognition method including: obtaining a first RGB image by using a camera; predicting at least one first region, in which an object is unrecognizable, in the first RGB image based on brightness information of the first RGB image; determining at least one second region, in which an object exists, from among the at least one first region, based on object information obtained through a dynamic vision sensor; obtaining an enhanced second RGB image by controlling photographic configuration information of the camera in relation to the at least one second region; and recognizing the object in the second RGB image."
287,16861803,2020.04.29,20210339736,2021.11.04,20210339736,2021.11.04,,,SYSTEM FOR PARKING AN AUTONOMOUS VEHICLE,"B60W30/06,B60W40/06,B60W60/00,G05D1/00",GM Cruise Holdings LLC,"The subject disclosure relates to features that improve safety for autonomous vehicle (AV) maneuvers and in particular, that improve safety for parallel parking. A process of the disclosed technology includes steps for initiating a parking maneuver, navigating the AV into a parking location, and detecting a roadway grade with respect to a direction of the AV. In some aspects, the process can further include steps for automatically adjusting a wheel angle of the AV based on the roadway grade with respect to the direction of the AV. Systems and machine-readable media are also provided."
288,16548705,2019.08.22,,,11155209,2021.10.26,11155209,2021.10.26,Virtual mirror with automatic zoom based on vehicle sensors,"B60R1/00,G06T7/70,G06T7/50,G06T7/20,H04N5/225,H04N5/247,H04N5/232,B60R11/04,G06K9/00,B60R11/00,B60R1/12","Micron Technology, Inc.","In one approach, a method includes: displaying, to a user of a first vehicle, image data obtained using a first field of view of a camera of the first vehicle, where the camera collects the image data for objects located outside of the first vehicle; detecting, by at least one processing device of the first vehicle, a second vehicle; determining, by the one processing device, whether the second vehicle is within a predetermined region relative to the first vehicle; and in response to determining that the second vehicle is within the predetermined region, displaying image data obtained using a second field of view of the camera."
289,17243677,2021.04.29,20210316751,2021.10.14,20210316751,2021.10.14,,,SYSTEMS AND METHODS FOR AUTONOMOUS VEHICLE NAVIGATION,"B60W60/00,G01C21/00,B60W10/18,B60W10/20,B60W30/18,G01C21/34,G01C21/36,G08G1/14,G08G1/00,B60T7/12,B62D6/00,G05D1/02,G01C21/30,G06K9/00,B60W30/12,G05D1/00,G08G1/01,G08G1/07","MOBILEYE VISION TECHNOLOGIES LTD.,MOBILEYE VISION TECHNOLOGIES LTD.","Systems and methods are provided for autonomous vehicle navigation. The systems and methods may map a lane mark, may map a directional arrow, selectively harvest road information based on data quality, map road segment free spaces, map traffic lights and determine traffic light relevancy, and map traffic lights and associated traffic light cycle times."
290,17349124,2021.06.16,20210311490,2021.10.07,20210311490,2021.10.07,,,CROWDSOURCING A SPARSE MAP FOR AUTONOMOUS VEHICLE NAVIGATION,"G05D1/02,G06K9/00,H04N7/18,G06T7/12,H04N13/239,G01C21/28,G01C21/00,G06T7/70,G01C21/32,G08G1/0967,H04N5/247,G06T11/60,G06T7/73,G06T7/11,G06T7/33,G06T7/37","Mobileye Vision Technologies Ltd.,Mobileye Vision Technologies Ltd.","Systems and methods are provided for crowdsourcing a sparse map for autonomous vehicle navigation. In one implementation, a non-transitory computer-readable medium may include a sparse map for autonomous vehicle navigation along a road segment. The sparse map may include at least one line representation of a road surface feature extending along the road segment, each line representation representing a path along the road segment substantially corresponding with the road surface feature, and wherein the road surface feature is identified through image analysis of a plurality of images acquired as one or more vehicles traverse the road segment and a plurality of landmarks associated with the road segment."
291,16363320,2019.03.25,,,11124186,2021.09.21,11124186,2021.09.21,Autonomous vehicle control signal,"B60W30/095,G08G1/16,G06Q40/08,B60W40/04,G05D1/02,G05D1/00",State Farm Mutual Automobile Insurance Company,"Methods and systems for communicating between autonomous vehicles are described herein. Such communication may be performed for signaling, collision avoidance, path coordination, and/or autonomous control. An autonomous vehicle may determine an upcoming maneuver for the autonomous vehicle and identify a vehicle signal which is indicative of the upcoming maneuver. Then the autonomous vehicle may present the vehicle signal. After presenting the vehicle signal, the autonomous vehicle may perform the maneuver."
292,16804968,2020.02.28,20210269061,2021.09.02,20210269061,2021.09.02,,,AUTONOMOUS DRIVING EVALUATION USING DATA ANALYSIS,"B60W60/00,G08G1/01,G08G1/16",INTERNATIONAL BUSINESS MACHINES CORPORATION,"A computer implemented method for evaluating autonomous vehicle safety that includes defining criteria for safety of autonomous vehicles in a test space, and dividing the test space into an intended test space and a un-intended test space for the criteria for safety of autonomous vehicles. The intended test space includes characterizations for the autonomous vehicle that can be quantified, and the un-intended test space includes characterizations that are not quantifiable. The method further includes measuring the safety of the autonomous vehicles in the intended test space. The applying the un-intended test space is applied to the intended test space as feedback into the intended test space; and evaluating the intended test space including the feedback from the unintended test space using a combined simulation of peripheral vehicles and autonomous vehicles to provide the evaluation of autonomous vehicle safety."
293,17181733,2021.02.22,20210271242,2021.09.02,20210271242,2021.09.02,,,Autonomous Vehicle Safe Stop,"G05D1/00,B60T7/22,B60W30/09,B60W30/095","UATC, LLC","Systems, methods, tangible non-transitory computer-readable media, and devices for operating an autonomous vehicle are provided. For example, the disclosed technology can include receiving state data that includes information associated with states of an autonomous vehicle and an environment external to the autonomous vehicle. Responsive to the state data satisfying vehicle stoppage criteria, vehicle stoppage conditions can be determined to have occurred. A severity level of the vehicle stoppage conditions can be selected from a plurality of available severity levels respectively associated with a plurality of different sets of constraints. A motion plan can be generated based on the state data. The motion plan can include information associated with locations for the autonomous vehicle to traverse at time intervals corresponding to the locations. Further, the locations can include a current location of the autonomous vehicle and a destination location at which the autonomous vehicle stops traveling."
294,16778626,2020.01.31,20210237714,2021.08.05,20210237714,2021.08.05,,,Autonomous Vehicle Behavior Synchronization,"B60W30/02,G06N5/02,G05D1/00,B60W50/00",International Business Machines Corporation,"A method, system and computer-usable medium are disclosed for autonomous vehicle (AV) behavior synchronization. The AV driving pattern is adjusted to facilitate an occupant's satisfaction by receiving information as to person to form a driving history. The driving history is analyzed to identify preferences and patterns. Based on the driving history a driving preference model is formed for the person. AV driving algorithm(s) are adjusted based on the driving preference model for the person when the person is an occupant of the AV."
295,16376836,2019.04.05,,,11048261,2021.06.29,11048261,2021.06.29,Systems and methods for evaluating autonomous vehicle software interactions for proposed trips,"G05D1/02,B60W50/04,G01C21/34,G07C5/00",State Farm Mutual Automobile Insurance Company,"An autonomous vehicle (AV) computing device including at least one processor may be provided. The at least processor may be programmed to (i) receive a proposed trip including a destination location and a departure time, (ii) determine environmental conditions data based on the destination location and the departure time, (iii) retrieve current software ecosystem data for the AV, (iv) retrieve aggregated data for a plurality of AVs, the aggregated data including a plurality of correlations, each correlation including a) an interaction between at least one software application and at least one environmental condition and b) an adverse performance outcome associated with the interaction, (v) compare the environmental conditions data for the proposed trip and the current software ecosystem data for the AV to the plurality of correlations to identify an adverse performance outcome, and (vi) execute a remedial action to avoid the adverse performance outcome."
296,16863311,2020.04.30,20210192874,2021.06.24,20210192874,2021.06.24,,,Predictive Mobile Test Device Control for Autonomous Vehicle Testing,"G07C5/08,B60W60/00","UATC, LLC","Example aspects of the present disclosure are directed to improved systems and methods for testing autonomous vehicle operation through the use of mobile test devices that are controlled at least in part in response to predictive motion planning associated with autonomous vehicles. More particularly, the motion of a mobile test device can be controlled based on the motion plan of an autonomous vehicle to cause desired interactions between the mobile test device and the autonomous vehicle. Motion planning data associated with the autonomous vehicle can be obtained by an autonomous vehicle (AV) test system prior to the autonomous vehicle implementing or completely implementing a motion plan. In this manner, the AV test system can proactively control the mobile test device based on predictive motion planning data to facilitate interactions between the mobile test device and the autonomous vehicle that may not otherwise be achievable."
297,16504034,2019.07.05,,,11029703,2021.06.08,11029703,2021.06.08,Systems and methods for controlling autonomous vehicles that provide a vehicle service to users,"E05F15/00,G06N5/00,G05D1/02,G05D1/00,G01C21/34,G01C21/36,G08G1/01,G08G1/0962,G08G1/0967,G08G1/14,G08G1/00,G08G1/005,G08G1/0968,B60R16/037,B60R25/24,G08G1/09,G08G1/123,H04W4/46,H04W4/40","Uber Technologies, Inc.","Systems and methods for determining autonomous vehicle user boarding times are provided. In one example embodiment, a computer implemented method includes obtaining location data associated with a user device associated with a user. The method includes determining an estimated time until the user starts boarding the autonomous vehicle based at least in part on the location data associated with the user device. The method includes obtaining data associated with the user. The method includes determining an estimated time of boarding duration for the user based at least in part on the data associated with the user. The method includes determining an estimated time until the user completes boarding of the autonomous vehicle based at least in part on the estimated time until the user starts boarding the autonomous vehicle and the estimated time of boarding duration for the user."
298,17082393,2020.10.28,20210116256,2021.04.22,20210116256,2021.04.22,,,AUTONOMOUS VEHICLE COMPONENT DAMAGE AND SALVAGE ASSESSMENT,"G01C21/34,G05D1/00,B60W10/04,B60W10/18,B60W10/20,B60W30/12,B60W30/16,B60W30/18,G08G1/16,G01S19/13,G05D1/02,G08G1/14,B60L53/36,G05B15/02,G08B25/01,H04L12/28,G06F16/2455,B60R25/04,B60R25/10,B60R25/102,B60R25/25,G06F21/32,B60R21/0136,B60R21/34,G01C21/36,G08G1/017,B60P3/12,G05B23/02,G01B21/00,G06F17/00,G08B21/00,G08B21/18,G06Q10/10,G06Q10/00,B60L58/12,G06Q40/08,B60R16/023,G07C5/00,G07C5/08,G08G1/0965,G08G1/00,B60W30/095,B60W40/04",State Farm Mutual Automobile Insurance Company,"Methods and systems for assessing, detecting, and responding to malfunctions involving components of autonomous vehicle and/or smart homes are described herein. Autonomous operation features and related components can be assessed using direct or indirect data regarding operation. Such assessment may be performed to determine the condition of components for salvage following a collision or other loss-event. To this end, the information regarding a plurality of components may be received. A component of the plurality of components may be identified for assessment. Assessment may including causing test signals to be sent to the identified component. In response to the test signal, one or more responses may be received. The received response may be compared to an expected response to determine whether the identified component is salvageable."
299,16262076,2019.01.30,20190369634,2019.12.05,10928829,2021.02.23,10928829,2021.02.23,Detection of traffic dynamics and road changes in autonomous driving,"G05D1/02,B60W30/08",Intel Corporation,"In some embodiments, the disclosed subject matter involves a system and method for dynamic object identification and environmental changes for use with autonomous vehicles. For efficient detection of changes for autonomous, or partially autonomous vehicles, embodiments may use a technique based on background removal and image subtraction which use motion detection rather than full object identification for all objects in an image. Road side units proximate to a road segment or virtual road side units in the cloud, other vehicles or mobile device (e.g., drones) are used to retrieve and store background images for a road segment, to be used by the autonomous vehicle. Other embodiments are described and claimed."
300,16885385,2020.05.28,20200379108,2020.12.03,20200379108,2020.12.03,,,AUTONOMOUS VEHICLE OPERATION USING ACOUSTIC MODALITIES,"G01S15/931,G05D1/02,G06K9/62",Hyundai-Aptiv AD LLC,Techniques for autonomous vehicle operation using acoustic modalities include using one or more acoustic sensors of a vehicle to receive acoustic waves from one or more objects. The acoustic waves have multiple wavelengths. The acoustic waves are clustered into one or more acoustic clusters based on the plurality of wavelengths. A particular acoustic cluster of the one or more acoustic clusters is selected based on signal processing of the one or more acoustic clusters. A particular object is associated with the particular acoustic cluster. An acoustic fingerprint of the particular object is generated based on the particular acoustic cluster. Characteristics of the particular object are determined based on the acoustic fingerprint of the particular object. A control circuit of the vehicle is used to operate the vehicle to avoid a collision with the particular object based on the characteristics of the particular object.
301,16913908,2020.06.26,20200326707,2020.10.15,20200326707,2020.10.15,,,CROWD SOURCING DATA FOR AUTONOMOUS VEHICLE NAVIGATION,"G05D1/00,G06F16/29,G06F16/23,G01C21/32,G06K9/32,B60W30/18,G01C21/14,G05D1/02,G08G1/0967,B62D15/02,G08G1/0962,G08G1/16,G01C21/34,G01C21/36,G06K9/00,G01C21/16,G08G1/01,B60W30/14,G08G1/0968","MOBILEYE VISION TECHNOLOGIES LTD.,Mobileye Vision Technologies Ltd.","Systems and methods are provided for constructing, using, and updating the sparse map for autonomous vehicle navigation. In one implementation, a non-transitory computer-readable medium includes a sparse map for autonomous vehicle navigation along a road segment. The sparse map includes a polynomial representation of a target trajectory for the autonomous vehicle along the road segment and a plurality of predetermined landmarks associated with the road segment, wherein the plurality of predetermined landmarks are spaced apart by at least 50 meters. The sparse map has a data density of no more than 1 megabyte per kilometer."
302,16370696,2019.03.29,20200310450,2020.10.01,20200310450,2020.10.01,,,EXTENSION OF AUTONOMOUS DRIVING FUNCTIONALITY TO NEW REGIONS,"G05D1/02,G05D1/00,G06F16/29","Zoox, Inc.,Zoox, Inc.","Autonomous vehicles use accurate and detailed maps for navigation. Expanding functionality of an autonomous vehicle to a new, e.g., unmapped, region can include determining drivable surface segments of the new region and comparing the segments to segments or classes of segments from an already-mapped region. Segments of the new region that are similar to segments from the mapped region can be identified as potentially navigable. An autonomous vehicle can travel through the new region via those segments indicated as navigable. In addition, during travel through the new region, data may be collected using sensors on the autonomous vehicle to map additional portions of the region and/or confirm a driving ability in the new region. Functionality of an autonomous vehicle may be limited based on how similar the segments are to one another."
303,16892853,2020.06.04,20200301435,2020.09.24,20200301435,2020.09.24,,,Gridlock Solver for Motion Planning System of an Autonomous Vehicle,"G05D1/02,G01C21/34,G05D1/00,G01C21/20","UATC, LLC","The present disclosure provides autonomous vehicle systems and methods that include or otherwise leverage a motion planning system that solves gridlock as part of determining a motion plan for an autonomous vehicle (AV). In particular, a scenario generator within a motion planning system can determine one or more keep clear areas associated with the lane sequence, each keep clear area indicative of a region along the nominal path in which gridlock prevention is desired. A gridlock constraint can be generated for each of the one or more keep clear areas, each constraint being defined as a constraint area in a multi-dimensional space. A low-cost trajectory path can be determined through a portion of the multi-dimensional space that minimizes exposure to the constraint areas and that is consistent with all constraints generated for the one or more objects of interest and the one or more keep clear areas."
304,16598128,2019.10.10,20200285242,2020.09.10,20200285242,2020.09.10,,,COMPOSITION METHOD OF AUTOMATIC DRIVING MACHINE CONSCIOUSNESS MODEL,"G05D1/02,G06N7/02","APOLLO JAPAN CO., LTD.","The invention proposes an automatic driving “machine consciousness” model, which is composed by the human's safety driving rules. Establish the dynamic fuzzy event probability measure relation, or fuzzy relation, or probability relation of the automatic driving vehicle and the surrounding passing vehicle. The decision result of “machine consciousness” of automatic driving vehicle is realized by complicated logic operation and using the antagonistic result of logic operation in both positive and negative directions. The implementation result is that it can make the decision-making result of automatic driving vehicle close to the result of human's biological consciousness, which can improve the safety of automatic driving vehicle, reduce the development cost and reduce the distance of road test."
305,16825886,2020.03.20,20200216094,2020.07.09,20200216094,2020.07.09,,,PERSONAL DRIVING STYLE LEARNING FOR AUTONOMOUS DRIVING,"B60W60/00,G05D1/00,G06N20/00","Futurewei Technologies, Inc.","Operation of an autonomous vehicle is modified based on the driving style preferences of a passenger. A machine learning module for a motion planner of the autonomous vehicle accepts input relating to driving style of the autonomous vehicle including data representing autonomous vehicle speed, acceleration, braking, or steering during operation. The passenger also provides feedback relating to the vehicle's driving style during operation, and the passenger feedback is used to train the machine learning module to create a personal driving style decision-making model for the passenger that controls operation of the autonomous vehicle. A personal driving style preference profile for the passenger also may be obtained by collecting motion sensor data relating to driving habits of the passenger when the passenger is a driver. The driving style preference profile is used by the motion planner to modify operation of the autonomous vehicle in accordance with the driving style preference profile."
306,16392205,2019.04.23,20200209875,2020.07.02,20200209875,2020.07.02,,,SYSTEM AND METHOD FOR TRAINING AND OPERATING AN AUTONOMOUS VEHICLE,"G05D1/02,G05D1/00,G06K9/00,G06N20/00","Samsung Electronics Co., Ltd.","A method for training and operating an autonomous vehicle. The method includes operating the autonomous vehicle with a control module. The control module includes a series of sensors configured to detect objects or situations in a path of the autonomous vehicle, and a machine learning algorithm trained to classify the objects or interpret the situations detected by the sensors. The method also includes prompting a safety driver of the autonomous vehicle to provide a response when the machine learning algorithm is unable to classify one of the objects or is unable to interpret one of the situations. The method further includes receiving, at the control module, the response from the safety driver, and providing the response from the safety driver as additional training data to the machine learning algorithm."
307,16386530,2019.04.17,,,10699580,2020.06.30,10699580,2020.06.30,Methods and systems for emergency handoff of an autonomous vehicle,"G05D1/00,G08G1/00,G07C5/00,G08G1/01,H04W4/90,H04W4/40,G05D1/02,B60W10/04",Guident Ltd.,"An improved distributed information sharing system (DISS) and methods for an autonomous vehicle, the DISS programmed and configured to receive information from a plurality of distributed sensors; determine the existence of an incident, vehicles, passengers, pedestrians, animals and objects involved in the incident, a nature of the injuries and damages from the incident; determine if the autonomous vehicle can be safely moved autonomously from a location where the incident occurred to a second location; contact an emergency responder when the vehicle cannot be safely moved autonomously; receive a request to transfer control of the vehicle from an emergency responder user device; and in response, transfer control of the automated vehicle to a trusted emergency responder without requiring approval from an owner of the vehicle using encryption and handshake techniques; and notify an owner or interested party of the vehicle of the incident."
308,16710966,2019.12.11,20200192359,2020.06.18,20200192359,2020.06.18,,,Safe Hand-Off Between Human Driver and Autonomous Driving System,"G05D1/00,G06N3/08,G06N3/04,G05D1/02","Allstate Insurance Company,Allstate Insurance Company","Methods, computer-readable media, software, and apparatuses may determine whether a human driver, or an autonomous driving system, should be in control of a vehicle in response to a detection of an unexpected event. A decision may be made to pass control from the autonomous driving system to the human driver, if it is determined that the human driver can handle the unexpected event more safely than the autonomous vehicle."
309,16684689,2019.11.15,20200160532,2020.05.21,20200160532,2020.05.21,,,System and Method for Identifying Travel Way Features for Autonomous Vehicle Motion Control,"G06T7/149,G06T17/05,G06T7/73,G01S17/89","UATC, LLC","Systems and methods for identifying travel way features in real time are provided. A method can include receiving two-dimensional and three-dimensional data associated with the surrounding environment of a vehicle. The method can include providing the two-dimensional data as one or more input into a machine-learned segmentation model to output a two-dimensional segmentation. The method can include fusing the two-dimensional segmentation with the three-dimensional data to generate a three-dimensional segmentation. The method can include storing the three-dimensional segmentation in a classification database with data indicative of one or more previously generated three-dimensional segmentations. The method can include providing one or more datapoint sets from the classification database as one or more inputs into a machine-learned enhancing model to obtain an enhanced three-dimensional segmentation. And, the method can include identifying one or more travel way features based at least in part on the enhanced three-dimensional segmentation."
310,16734947,2020.01.06,20200150682,2020.05.14,20200150682,2020.05.14,,,Systems and Methods for Controlling Autonomous Vehicles that Provide a Vehicle Service to Users,"G05D1/02,H04W4/46,G08G1/123,G08G1/09,B60R25/24,B60R16/037,G08G1/00,G08G1/14,G08G1/0968,G08G1/0967,G08G1/0962,G08G1/01,G08G1/005,G01C21/34,G01C21/36,G05D1/00","UATC, LLC","Systems and methods for controlling autonomous vehicles are provided. In one example embodiment, a computer implemented method includes obtaining data indicative of a location associated with a user to which an autonomous vehicle is to travel. The autonomous vehicle is to travel along a first vehicle route that leads to the location. The method includes obtaining traffic data associated with a geographic area that includes the location. The method includes determining an estimated traffic impact of the autonomous vehicle on the geographic area based at least in part on the traffic data. The method includes determining vehicle action(s) based at least in part on the estimated traffic impact and causing the autonomous vehicle to perform the vehicle action(s) that include at least one of stopping the autonomous vehicle at least partially in a travel way within a vicinity of the location or travelling along a second vehicle route."
311,16734945,2020.01.06,20200142428,2020.05.07,20200142428,2020.05.07,,,Systems and Methods for Controlling Autonomous Vehicles that Provide a Vehicle Service to Users,"G05D1/02,H04W4/46,G08G1/123,G08G1/09,B60R25/24,B60R16/037,G08G1/00,G08G1/14,G08G1/0968,G08G1/0967,G08G1/0962,G08G1/01,G08G1/005,G01C21/34,G01C21/36,G05D1/00","UATC, LLC","Systems and methods for controlling autonomous vehicles are provided. In one example embodiment, a computer implemented method includes obtaining data indicative of a location associated with a user to which an autonomous vehicle is to travel. The autonomous vehicle is to travel along a first vehicle route that leads to the location. The method includes obtaining traffic data associated with a geographic area that includes the location. The method includes determining an estimated traffic impact of the autonomous vehicle on the geographic area based at least in part on the traffic data. The method includes determining vehicle action(s) based at least in part on the estimated traffic impact and causing the autonomous vehicle to perform the vehicle action(s) that include at least one of stopping the autonomous vehicle at least partially in a travel way within a vicinity of the location or travelling along a second vehicle route."
312,16516137,2019.07.18,20200082187,2020.03.12,20200082187,2020.03.12,,,"Method, Apparatus and Device for Identifying Passenger State in Unmanned Vehicle, and Storage Medium","G06K9/00,G07C5/08,G10L25/51,G06K9/62,A61B5/0205,A61B5/11,A61B5/00,G10L25/03","Baidu Online Network Technology (Beijing) Co., Ltd.,Baidu Online Network Technology (Beijing) Co., Ltd.","Embodiments of the present application provide a method, an apparatus, and a device for identifying a passenger state in an unmanned vehicle, and a storage medium. The method comprises: obtaining monitoring data of different dimensions in a process where the passenger takes the unmanned vehicle; performing feature extraction on the monitoring data of the different dimensions and forming feature data of different dimensions; and identifying the passenger state according to the feature data of the different dimensions. By obtaining the monitoring data of various dimensions in the process where the passenger takes the unmanned vehicle to identify the passenger state, it is possible to omnidirectionally monitor the personal is safety and property safety of the passengers, and effectively protect the passenger taking the unmanned vehicle."
313,16672277,2019.11.01,20200064843,2020.02.27,20200064843,2020.02.27,,,CROWD SOURCING DATA FOR AUTONOMOUS VEHICLE NAVIGATION,"G05D1/00,G06K9/00,G05D1/02,G01C21/36,G01C21/34,G08G1/0968,B60W30/14,G08G1/01,G01C21/16,G08G1/16,G08G1/0962,B62D15/02,G08G1/0967,G01C21/14,B60W30/18,G06K9/32,G01C21/32,G06F16/23,G06F16/29",MOBILEYE VISION TECHNOLOGIES LTD.,"Systems and methods are provided for constructing, using, and updating the sparse map for autonomous vehicle navigation. A method may comprise processing, by a mapping server, collected navigation information from a plurality of vehicles obtained by sensors coupled to the plurality of vehicles, wherein the navigation information describes road lanes of a road segment; collecting data about landmarks identified proximate to the road segment, the landmarking including a traffic sign; generating, by the mapping server, an autonomous vehicle map for the road segment, wherein the autonomous vehicle map includes a spline corresponding to a lane in the road segment and the landmarks identified proximate to the road segment; and distributing, by the mapping server, the autonomous vehicle map to an autonomous vehicle for use in autonomous navigation over the road segment."
314,16554437,2019.08.28,20190384294,2019.12.19,20190384294,2019.12.19,,,CROWD SOURCING DATA FOR AUTONOMOUS VEHICLE NAVIGATION,"G05D1/00,G06K9/00,G05D1/02,G01C21/36,G01C21/34,G08G1/0968,B60W30/14,G08G1/01,G01C21/16,G08G1/16,G08G1/0962,B62D15/02,G08G1/0967,G01C21/14,B60W30/18,G06K9/32,G01C21/32,G06F16/23,G06F16/29","Mobileye Vision Technologies Ltd.,Mobileye Vision Technologies Ltd.","Systems and methods of processing crowdsourced navigation information for use in autonomous vehicle navigation are disclosed. A method may include processing, by a mapping server, crowdsourced navigation information from a plurality of vehicles obtained by sensors coupled to the plurality of vehicles, wherein the navigation information describes road lanes of a road segment; collecting data about landmarks identified proximate to the road segment, the landmarking including a traffic sign; generating, by the mapping server, an autonomous vehicle map for the road segment, wherein the autonomous vehicle map includes a spline corresponding to a lane in the road segment and the landmarks identified proximate to the road segment; and distributing, by the mapping server, the autonomous vehicle map to an autonomous vehicle for use in autonomous navigation over the road segment."
315,16401615,2019.05.02,20190340927,2019.11.07,20190340927,2019.11.07,,,Reducing Autonomous Vehicle Downtime and Idle Data Usage,"G08G1/00,G08G1/01,G08G1/09","Uber Technologies, Inc.","Systems and methods for controlling an autonomous vehicle to reduce idle data usage and vehicle downtime are provided. In one example embodiment, a computing system can obtain data associated with autonomous vehicle(s) that are online with a service entity. The computing system can obtain data indicative of the geographic area with an imbalance in a number of vehicles associated with the geographic area. The computing system can determine a first autonomous vehicle for re-positioning with respect to the geographic area based at least in part on the data associated with the one or more autonomous vehicles and the data indicative of the geographic. The computing system can communicating data indicative of a first re-positioning assignment associated with the first autonomous vehicle. In some implementations, the computing system can generate vehicle service incentive to entice a vehicle provider to re-position its autonomous vehicles with respect to the geographic area."
316,16401629,2019.05.02,20190340928,2019.11.07,20190340928,2019.11.07,,,Reducing Autonomous Vehicle Downtime and Idle Data Usage,"G08G1/00,G08G1/065,G06Q10/02,G06Q50/30","Uber Technologies, Inc.","Systems and methods for controlling an autonomous vehicle to reduce idle data usage and vehicle downtime are provided. In one example embodiment, a computing system can obtain data associated with autonomous vehicle(s) that are online with a service entity. The computing system can obtain data indicative of the geographic area with an imbalance in a number of vehicles associated with the geographic area. The computing system can determine a first autonomous vehicle for re-positioning with respect to the geographic area based at least in part on the data associated with the one or more autonomous vehicles and the data indicative of the geographic. The computing system can communicating data indicative of a first re-positioning assignment associated with the first autonomous vehicle. In some implementations, the computing system can generate vehicle service incentive to entice a vehicle provider to re-position its autonomous vehicles with respect to the geographic area."
317,16504034,2019.07.05,20190332123,2019.10.31,20190332123,2019.10.31,,,Systems and Methods for Controlling Autonomous Vehicles that Provide a Vehicle Service to Users,"G05D1/02,G08G1/01,B60R16/037,G01C21/36,G01C21/34,G05D1/00,G08G1/00,G08G1/14,G08G1/0968,G08G1/0967,G08G1/0962,G08G1/005,G08G1/123,G08G1/09,B60R25/24","Uber Technologies, Inc.","Systems and methods for determining autonomous vehicle user boarding times are provided. In one example embodiment, a computer implemented method includes obtaining location data associated with a user device associated with a user. The method includes determining an estimated time until the user starts boarding the autonomous vehicle based at least in part on the location data associated with the user device. The method includes obtaining data associated with the user. The method includes determining an estimated time of boarding duration for the user based at least in part on the data associated with the user. The method includes determining an estimated time until the user completes boarding of the autonomous vehicle based at least in part on the estimated time until the user starts boarding the autonomous vehicle and the estimated time of boarding duration for the user."
318,17807012,2022.06.15,20220348225,2022.11.03,20220348225,2022.11.03,,,AUTONOMOUS DRIVING APPARATUS AND RULE DETERMINATION APPARATUS,"B60W60/00,B60W30/16,B60W40/04,B60W50/02,H04W4/40",DENSO CORPORATION,"An autonomous driving apparatus, which is used in a subject vehicle capable of performing an autonomous driving, is configured to: determine a deviation value of each of one or more candidate routes, which indicates a possibility of the subject vehicle deviating from a traveling rule when the subject vehicle travels the corresponding candidate route, based on a comparison result between an inter-vehicle distance and a minimum control permission distance; select one candidate route having the deviation value within a control permission range as a target route; output an instruction for controlling the subject vehicle to travel along the selected target route; execute a traveling control of the subject vehicle according to the instruction; and update a determination rule of the deviation value in response to a change in a sensor that detects a behavior of at least one of the subject vehicle or the peripheral vehicle."
319,17243900,2021.04.29,20220348223,2022.11.03,20220348223,2022.11.03,,,AUTONOMOUS VEHICLE TO OVERSIGHT SYSTEM COMMUNICATIONS,"B60W60/00,B60W40/02,B60W50/00,G05D1/02,G07C5/08,H04W4/46","TuSimple, Inc.","A system comprises an autonomous vehicle (AV) and a control device operably coupled with the AV. The control device receives, from an operation server, a command to navigate the AV to avoid an expected road condition. The control device receives, from sensors of the AV, sensor data comprising location coordinates of a plurality of objects ahead of the AV. The control device determines whether at least one object from the plurality of objects impedes performing the command. In response to determining that at least one object impedes performing the command, the control device updates the command, such that the updated command comprises one or more navigation instructions to avoid the at least one object while performing the command. The control device navigates the AV according to the updated command."
320,17243785,2021.04.29,20220348222,2022.11.03,20220348222,2022.11.03,,,OVERSIGHT SYSTEM TO AUTONOMOUS VEHICLE COMMUNICATIONS,"B60W60/00,B60W40/02,B60W50/00,G05D1/02,H04W4/46","TuSimple, Inc.","A system comprises an autonomous vehicle (AV) and an operation server operably coupled with the AV. The operation server accesses environmental data associated with a road traveled by the AV. The environmental data is associated with a time window during which the AV is traveling along the road. The operation server compares the environmental data with map data that comprises expected road conditions ahead of the AV. The operation server determines whether the environmental data comprises an unexpected road condition that is not included in the map data. In response to determining that the environmental data comprises the unexpected road condition that is not included in the map data, the operation server determines a location coordinate of the unexpected road condition, and communicates a command to the AV to maneuver to avoid the unexpected road condition."
321,17243981,2021.04.29,20220348224,2022.11.03,20220348224,2022.11.03,,,DIRECT AUTONOMOUS VEHICLE TO AUTONOMOUS VEHICLE COMMUNICATIONS,"B60W60/00,B60W40/02,B60W50/00,G05D1/02,H04W4/46","TuSimple, Inc.","A system comprises a lead autonomous vehicle (AV), a control device associated with the lead AV, and a following AV. The control device receives a command to navigate the lead AV to avoid an unexpected road condition. The control device receives sensor data from a sensor of the lead AV, comprising location coordinates of objects ahead of the lead AV. The control device accesses environmental data associated with a portion of a road between the lead AV and following AV. The environmental data comprises location coordinates of objects between the lead AV and following AV. The control device determines whether an object in the sensor data or environmental data impedes performing the command by the following AV. The control device updates the command, if the control device determines that an object impedes performing the command by the following AV, and communicates the updated command to the following AV."
322,16929888,2020.07.15,,,11472362,2022.10.18,11472362,2022.10.18,Triggering at least one crash cushion of an unmanned vehicle,"B60R21/0134,B60R21/36,B60R21/01","Uwe Radetzki,Dong-Uck Kong,Boris Trendafilov,Heike Bischoff,Sandra Drees","A method is disclosed in which sensor information is obtained that is captured by at least one environment sensor of an unmanned vehicle. The sensor information represents at least one object parameter of an object that is moving relative to the unmanned vehicle. At least partly based on the at least one object parameter, it is determined whether a collision between the unmanned vehicle and the object is imminent. If it is determined that a collision between the unmanned vehicle and the object is imminent, at least partly based on the at least one object parameter, at least one triggering parameter is determined for triggering at least one crash cushion of the unmanned vehicle. The at least one crash cushion is triggered according to the at least one triggering parameter. The at least one crash cushion is triggered before the imminent collision."
323,16972591,2019.06.08,,,11427213,2022.08.30,11427213,2022.08.30,"Method for operating an autonomous vehicle, and autonomous vehicle","B60W50/038,B60W30/09,B60W50/023,B60W50/04,G07C5/00,B60W50/029",Robert Bosch GmbH,"A method for operating an autonomous vehicle. The method includes the transmission of status data to a processing unit, which is independent of the autonomous vehicle, using a wireless communications link. The method furthermore includes monitoring of the function of the autonomous vehicle by the independent processing unit while taking the status data into account, and when a malfunction of the autonomous vehicle is detected, the independent processing unit determines target data for guiding the autonomous vehicle to a stopping position. The target data are transmitted to the autonomous vehicle, and the autonomous vehicle is guided to the stopping position with the aid of the target data. A position of the autonomous vehicle is determined using signals from the wireless communications link and is taken into account when determining the target data."
324,17021991,2020.09.15,,,11458993,2022.10.04,11458993,2022.10.04,Detecting a road closure by a lead autonomous vehicle (AV) and updating routing plans for following AVs,"B60W60/00,G01C21/34,G01C21/00,B60W30/095,G01C21/30,B60W50/14,B60W30/14,B60W30/16,B60W40/06,G08G1/00","TuSimple, Inc.","A lead autonomous vehicle (AV) includes a sensor configured to observe a field of view in front of the lead AV. Following AVs are on the same road behind the lead AV. A processor of the lead AV is configured to detect a road closure. The processor overrides driving instructions of the lead AV, such that the lead AV is stopped at first location coordinates. The processor sends a first message to an operation server, indicating that the road closure is detected. The operation server update the first portion of the map data, reflecting the road closure. The operation server determines whether re-routing is possible for each AV. If re-routing is possible is possible for that AV, the operation server sends re-routing instructions to the AV. If re-routing is not possible is possible for that AV, the operation server sends pulling over instructions to the AV."
325,17236195,2021.04.21,20220340145,2022.10.27,20220340145,2022.10.27,,,AUTOMATIC RECOMMENDATION OF CONTROL IN A SIMULTANEOUS MIX MODE VEHICLE,"B60W40/09,G06N20/00,B60W60/00,B60W10/20,B60W10/18,B60W10/30,B60Q5/00,B60Q1/34,G01C21/34,B60W50/14,G05D1/00",HERE Global B.V.,"Systems and methods for mix mode driving including the selection of driving operations, generation of recommendations for the assignment of the driving operations, and application of the assignment of driving operations to specific operators based on a number of factors."
326,17809358,2022.06.28,20220327740,2022.10.13,20220327740,2022.10.13,,,REGISTRATION METHOD AND REGISTRATION APPARATUS FOR AUTONOMOUS VEHICLE,"G06T7/80,G06T7/33,G06T7/73,G01C21/16","BEIJING BAIDU NETCOM SCIENCE TECHNOLOGY CO., LTD.,BEIJING BAIDU NETCOM SCIENCE TECHNOLOGY CO., LTD.","A registration method and a registration apparatus for an autonomous vehicle is provided. The method includes: generating a first trajectory curve based on first detection poses of a vehicle-mounted camera at a plurality of first time points, generating a second trajectory curve based on second detection poses of a vehicle-mounted positioning device at a plurality of second time points, aligning the first trajectory curve with the second trajectory curve based on the first detection poses and the second detection poses, and registering the vehicle-mounted camera and the vehicle-mounted positioning device based on the first trajectory curve and the second trajectory curve aligned with each other."
327,17232524,2021.04.16,20220332343,2022.10.20,20220332343,2022.10.20,,,SYSTEMS AND METHODS FOR CONTROLLING AN AUTONOMOUS VEHICLE,"B60W60/00,B60W10/20,B60W50/14,B60W30/09,B60W30/095,B60W30/14,B60W30/10,B60W40/08","Toyota Research Institute, Inc.","Systems and methods for controlling an autonomous vehicle are disclosed herein. One embodiment determines a reference path for the autonomous vehicle along a roadway segment and steers the autonomous vehicle along a path that includes controlled back and forth lateral deviations from the reference path along the roadway segment to provide feedback to an occupant of the autonomous vehicle, the feedback indicating to the occupant that the autonomous vehicle is in an autonomous driving mode and that the autonomous driving mode is operating correctly."
328,17239155,2021.04.23,20220340172,2022.10.27,20220340172,2022.10.27,,,PLANNING WITH DYNAMIC STATE A TRAJECTORY OF AN AUTONOMOUS VEHICLE,"B60W60/00,B60W30/09","MOTIONAL AD LLC,MOTIONAL AD LLC","This disclosure describes an autonomous vehicle configured to obtain sensor data associated with objects proximate a projected route of the autonomous vehicle, determine static constraints that limit a trajectory of the autonomous vehicle along the projected route based on non-temporal risks associated with a first subset of the f objects, predict a position and speed of the autonomous vehicle as a function of time along the projected route based on the static constraints, identify temporal risks associated with a second subset of the objects based on the predicted position and speed of the autonomous vehicle, determine dynamic constraints that further limit the trajectory of the autonomous vehicle along the projected route to help the autonomous vehicle avoid the temporal risks associated with the second subset of the objects, and adjust the trajectory of the autonomous vehicle in accordance with the static constraints and the dynamic constraints."
329,16929954,2020.07.15,,,11435748,2022.09.06,11435748,2022.09.06,System and method for real world autonomous vehicle trajectory simulation,"G05D1/02,G05D1/00,G05B13/04,G06N20/00","TUSIMPLE, INC.","A system and method for real world autonomous vehicle trajectory simulation may include: receiving training data from a data collection system; obtaining ground truth data corresponding to the training data; performing a training phase to train a plurality of trajectory prediction models; and performing a simulation or operational phase to generate a vicinal scenario for each simulated vehicle in an iteration of a simulation. Vicinal scenarios may correspond to different locations, traffic patterns, or environmental conditions being simulated. Vehicle intention data corresponding to a data representation of various types of simulated vehicle or driver intentions."
330,16513682,2019.07.16,,,11456890,2022.09.27,11456890,2022.09.27,Open and safe monitoring system for autonomous driving platform,"H04L12/40,H04L47/62,H04L49/9047,B60R16/023,G05D1/00,G05D1/02,H04L67/12",Baidu USA LLC,"In one embodiment, a system for operating an autonomous driving vehicle (ADV) includes a number of modules. These modules include at least a perception module to perceive a driving environment surrounding the ADV and a planning module to plan a path to drive the ADV to navigate the driving environment. The system further includes a bus coupled to the modules and a sensor processing module communicatively coupled to the modules over the bus. The sensor processing module includes a bus interface coupled to the bus, a sensor interface to be coupled to a first set of one or more sensors mounted on the ADV, a message queue to store messages published by the sensors, and a message handler to manage the messages stored in the message queue. The messages may be subscribed by at least one of the modules to allow the modules to monitor operations of the sensors."
331,16833644,2020.03.29,,,11455668,2022.09.27,11455668,2022.09.27,Method and system of automatic billing of transportation services,"G06Q30/04,G06Q20/10,H04W4/02,H04W4/029",Babu Vinod,"In one aspect, a process for automatic billing of transportation services includes the step of generating a first travel vector for a traveler. The process includes the step of generating a second travel vector for a travel provider. The process includes the step of determining that the traveler's location and movement is synchronized with a travel-service provider within a specified distance threshold. The process includes the step of comparing first travel vector with second travel vector. The process includes the step of determining that the first vector and the second vector are within the specified distance threshold. The process includes the step of measuring the time period that the first vector and the second vector are within the specified distance threshold. The process includes the step of billing the traveler for the time period that the first vector and the second vector are within the specified distance threshold."
332,16692661,2019.11.22,,,11433734,2022.09.06,11433734,2022.09.06,Autonomous operation of vehicle vents,B60H1/00,"Toyota Motor Engineering &#x26; Manufacturing North America, Inc.","A vent control system for a vehicle includes one or more processors and a memory communicably coupled to the one or more processors. The memory may store a vent control module including instructions that when executed by the one or more processors cause the one or more processors to autonomously control operation of a vehicle to open at least one vehicle vent when the vehicle is in a regular vent opening condition. Responsive to manual closure of the at least one vehicle vent within a predetermined time period after the at least one vehicle vent was autonomously opened, the regular opening condition may be updated to an updated regular opening condition. After updating the regular opening condition, operation of the vehicle may be autonomously controlled to open the at least one vehicle vent when the vehicle is subsequently in the updated regular opening condition."
333,17703551,2022.03.24,20220315045,2022.10.06,20220315045,2022.10.06,,,"AUTONOMOUS DRIVING DEVICE, AUTONOMOUS DRIVING METHOD, AND NON-TRANSITORY STORAGE MEDIUM","B60W60/00,G05D1/00,B60W50/00",TOYOTA JIDOSHA KABUSHIKI KAISHA,"An autonomous driving device includes a plurality of driving function ECUs having a function to drive a vehicle in place of an occupant, and a driving function switch ECU is configured to individually change operating states of the driving function ECUs according to a route to a destination and remaining power. The driving function ECUs include an autonomous driving ECU configured to autonomously drive the vehicle, and a remote control ECU configured to operate the vehicle according to remote control from outside."
334,16909987,2020.06.23,,,11461922,2022.10.04,11461922,2022.10.04,Depth estimation in images obtained from an autonomous vehicle camera,"G06T7/70,G06T7/11,B60W60/00,G01C21/30,G06V20/58","TUSIMPLE, INC.","Image processing techniques are described to receive bounding box information that describes a bounding box located around a detected object in an image, determine one or more positions of one or more reference points on the bounding box, determine, for each reference point, 3D world coordinates of a point of intersection of the reference point and the road surface, and assign the 3D world coordinates of the one or more reference points to a location of the detected object."
335,17150581,2021.01.15,,,11447156,2022.09.20,11447156,2022.09.20,Responder oversight system for an autonomous vehicle,"B60W60/00,G05D1/02,G07C5/08,G07C5/00,G05D1/00","TuSimple, Inc.","A system includes an autonomous vehicle (AV) comprising a sensor, a control subsystem, and an operation server. The control subsystem receives sensor data comprising location coordinates of the AV from the sensor. The operation server detects an unexpected event from the sensor data, comprising at least one of an accident, an inspection, and a report request. The operation server receives a message from a user comprising a request to access particular information regarding the AV and location data. The operation server associates the AV with the user if the location coordinates of the AV match location data of the user. The operation server generates a ticket for the unexpected ticket. The operation server communicates the particular information to the user. The operation server provides instructions to be forwarded to the user based on a request from the user. The operation server closes the ticket if the unexpected event is addressed."
336,17279435,2019.09.13,,,11425544,2022.08.23,11425544,2022.08.23,"Backend apparatus for triggering an automatic emergency call for at least one vehicle, vehicle control unit for vehicle-to-environment communication, system for triggering an automatic emergency call, method for triggering an automatic emergency call, and computer program product for a backend apparatus","H04W4/40,G08B25/01,G08G1/16",ZF Friedrichshafen AG,"Backend apparatus for triggering an automatic emergency call for a vehicle is arranged outside the vehicle, comprising a first interface for vehicle-to-environment communication to recurrently obtain a current collision probability from a collision detection device for a collision with an object, a second interface for vehicle-to-environment communication to recurrently obtain a data record updated by the vehicle comprising a time, a location and an identification number of the vehicle. The backend apparatus is designed, if the impact probability is not obtained, and on the basis of the impact probability obtained last, to trigger the automatic emergency call comprising the data record obtained last. A third interface makes the automatic emergency call. The invention also relates to a vehicle control unit for a vehicle-to-environment communication, a system and method for triggering an automatic emergency call, and a computer program product for a backend apparatus."
337,17193132,2021.03.05,,,11461719,2022.10.04,11461719,2022.10.04,Operation management apparatus and operation management method of autonomous travel vehicle,G06Q10/06,"TOYOTA JIDOSHA KABUSHIKI KAISHA,DENSO CORPORATION","A schedule changer executes, as a schedule change process for changing a normal operation schedule, a cut-in change process in which a plurality of operating vehicles are divided into a sequence of an advanced vehicle line group for which a departure target time is advanced from a departure target time determined based on the normal operation schedule, and a sequence of a delayed vehicle line group for which the departure target time is delayed from the departure target time determined based on the normal operation schedule, and an inter-vehicle space between the advanced vehicle line group and the delayed vehicle line group is enlarged for an additional vehicle."
338,16505077,2019.07.08,,,11458974,2022.10.04,11458974,2022.10.04,Fleet-based average lane change and driver-specific behavior modelling for autonomous vehicle lane change operation,"B60W40/09,G08G1/16,B60W30/18,B60W30/095,G05D1/02","TOYOTA MOTOR ENGINEERING &#x26; MANUFACTURING NORTH AMERICA, INC.","Systems and methods are provided for creating more organic lane change models for autonomous or semi-autonomous operation of a vehicle. A plurality of data associated with a plurality of driver-performed lane change maneuvers is collected from a plurality of different vehicle. Driver-performed lane change maneuvers are discarded when determined to fall outside a threshold of safety. A generic model is generated from the non-discarded data for average lane change maneuvers. Specific models can be generated for different drivers, vehicle types, and other metrics by comparison with the generic model."
339,17577219,2022.01.17,,,11427266,2022.08.30,11427266,2022.08.30,Autonomous versatile vehicle system,"B62D33/063,B60W60/00,G05D1/00,G05D1/02","Ali Ebrahimi Afrouzi,Lukas Fath,Shahin Fathi Djalali","A system for robotic collaboration, including: a first robotic chassis and a second robotic chassis, each including wheels; a control system; a power supply; at least one sensor; a processor, and a medium storing instructions that when executed by the respective processor effectuates operations including: capturing data of an environment and data indicative of movement; generating a map of the environment based on at least some of the captured data; inferring a current location of the respective robotic chassis based on at least some of the captured data; and executing a portion of a task, the second robotic chassis executing a second part of the task after the first robotic chassis completes a first part of the task."
340,17625280,2020.07.14,20220316909,2022.10.06,20220316909,2022.10.06,,,Method and Communication System for Supporting at Least Partially Automatic Vehicle Control,"G01C21/00,G01C21/30,B60W50/02,H04L67/12","Volkswagen Aktiengesellschaft,MAN Truck &#x26; Bus SE,Volkswagen Aktiengesellschaft,MAN Truck &#x26; Bus SE",A method for providing an information signal (  8  ) for at least partially automatic vehicle control involves an environment sensor system (  3  ) of a motor vehicle (  1  ) being used to generate measurement data for surroundings of the motor vehicle (  1  ). A computing unit (  2  ) of the motor vehicle (  1  ) is used to identify an object (  7  ) and a landmark (  5  ) on the basis of the measurement data. The computing unit (  4  ) is used to determine a first relative position of the object (  7  ) in relation to the landmark (  5  ) on the basis of the measurement data. A communication interface (  4  ) of the motor vehicle (  1  ) is used to generate the information signal (  8  ) on the basis of the first relative position.
341,16810622,2020.03.05,,,11427237,2022.08.30,11427237,2022.08.30,Autonomous rail or off rail vehicle movement and system among a group of vehicles,"B61L27/04,B61L25/02,G05D1/00,G05D1/02,G01C21/00,B61L15/00,B61L23/34,B61L23/04,B61L27/10,B61L27/40","Glydways, Inc.","In an example, the autonomous vehicle (“AV”) can be configured among the other vehicles and railway to communicate with a rider on a peer to peer basis to pick up the rider on demand from a location on a track, like a railway, tram or other track, rather than the rider being held hostage to a fixed railway schedule. The rider can have an application on his/her cell phone, which tracks each of the AVs, and contact them using the application on the cell phone. In an example, the AV is configured for both on-track and off track operation with different operating parameters for on-track and off track, including speed, degree of autonomy, sensors used etc."
342,17696202,2022.03.16,20220297722,2022.09.22,20220297722,2022.09.22,,,"AUTONOMOUS DRIVING DEVICE, AUTONOMOUS DRIVING METHOD, AND PLURALITY OF NON-TRANSITORY STORAGE MEDIA","B60W60/00,B60W20/20,B60W20/13,G07C5/00",TOYOTA JIDOSHA KABUSHIKI KAISHA,"An autonomous driving device to be mounted on a vehicle includes a first ECU configured to autonomously drive the vehicle, and a second ECU configured to operate the vehicle under remote control from an outside. The first ECU is configured to keep an activated state while the second ECU is operating the vehicle. The second ECU is configured to keep a power saving state while the first ECU is autonomously driving the vehicle."
343,17664399,2022.05.20,20220283594,2022.09.08,20220283594,2022.09.08,,,AUTOMATED VEHICLE FOR AUTONOMOUS LAST-MILE DELIVERIES,"G05D1/02,G06Q10/08,B60R25/01,B60R25/24","DoorDash, Inc.,DoorDash, Inc.","Provided are various systems and processes for improving last-mile delivery of real-time, on-demand orders for perishable goods. In one aspect, an automated vehicle (AV) comprises a body including a storage compartment for storing perishable goods. The storage compartment is accessible by a user upon authentication of the user. The AV further comprises a sensor module for receiving data for navigating the AV. The sensor module is positioned above the body on a support structure at a predetermined height above the ground, such as three to five feet. The data includes one or more of the following: audio data, video data, radio waves, and backscattered light waves. The AV further comprises an onboard computer system configured to process the data to navigate the AV along motor vehicle routes and pedestrian routes. The AV may be configured to interface with an automated locker system to retrieve or deposit the perishable goods."
344,17193886,2021.03.05,20220281459,2022.09.08,20220281459,2022.09.08,,,AUTONOMOUS DRIVING COLLABORATIVE SENSING,"B60W40/04,G06T9/00,G06T7/70","Black Sesame International Holding Limited,Black Sesame International Holding Limited","A method of autonomous driving collaborative sensing, including receiving at least one sensor input, determining a pose based on the at least one sensor input, synchronizing the at least one sensor input to the pose, transforming the at least one sensor input, the pose and the synchronization, determining an intermediate representation based on the transform, determining an object extraction based on the transform, aggregating the at least one sensor input, the intermediate representation and the object extraction and determining a birds eye view of the aggregation."
345,17676825,2022.02.22,20220270165,2022.08.25,20220270165,2022.08.25,,,AUTONOMOUS VEHICLE MANAGEMENT DEVICE,"G06Q30/06,G06Q10/06",TOYOTA JIDOSHA KABUSHIKI KAISHA,"When a rental user schedule management unit (general user schedule management unit) receives, from a general user (rental user) different from the priority user that is a lease contractor, a general usage request for a predetermined autonomous vehicle in which a time zone excluding a priority usage time zone is specified, the rental user schedule management unit set the time zone specified by the general usage request as a general usage time zone."
346,17625538,2020.07.01,20220277246,2022.09.01,20220277246,2022.09.01,,,"Method for Coordinating an Autonomous Vehicle Fleet, and Vehicle Fleet Coordination System","G06Q10/06,G08G1/00,G05D1/02,G01C21/34,G06N3/02",Daimler AG,"A method for coordinating an autonomous vehicle fleet that includes a plurality of autonomous motor vehicles in a predetermined first region by a vehicle fleet coordination system. The method includes coordinating the autonomous vehicle fleet depending on a first regional environment profile of the predetermined first region, where a position in the predetermined first region dependent on the first regional environment profile is autonomously approached by a first autonomous motor vehicle of the plurality of autonomous motor vehicles. The method further includes generating the first regional environment profile on a basis of a second regional environment profile which is stored in an electronic computing device of the vehicle fleet coordination system and which is generated for a second region independent of the predetermined first region."
347,17686192,2022.03.03,20220286277,2022.09.08,20220286277,2022.09.08,,,"UNMANNED DRIVING INFORMATION STORAGE AND PLAYBACK METHOD, DEVICE AND STORAGE MEDIUM","H04L9/08,H04L9/32",Black Sesame Technologies Inc.,"The application relates to a method, a device and a storage medium for storing and playing back unmanned driving information, wherein the unmanned driving information storage method comprises the following steps of: acquiring a plurality of data signals associated with an abnormal event when the abnormal event of an unmanned vehicle is monitored; calculating a first hash value for each data signal; storing each first hash value and the corresponding data signal as a key value pair in a key value database respectively; generating a first Merkel tree based on each first hash value; and storing the first Merkel tree and critical data signals of the plurality of data signals into a blockchain, and generating corresponding electronic money addresses and transaction timestamps. By this method, the correctness, integrity, fairness, and credibility of abnormal field data can be guaranteed, and too much storage space will not be occupied at the same time."
348,17678039,2022.02.23,20220270490,2022.08.25,20220270490,2022.08.25,,,"AUTONOMOUS VEHICLE, AUTONOMOUS VEHICLE DISPATCH SYSTEM, AND MOBILE TERMINAL","G08G1/00,G01C21/36,G01C21/34,B60W60/00,H04W4/029,H04W4/40",TOYOTA JIDOSHA KABUSHIKI KAISHA,"A mobile terminal includes an input unit that is capable of receiving input of a dispatch request and a destination and a position determiner that is capable of obtaining a terminal position which is its own current position. In accordance with the dispatch request, an autonomous vehicle is designated as a vehicle that is to be dispatched. The autonomous vehicle includes an autonomous driving controller that performs driving control so as to track the mobile terminal based on the terminal position while on its way to pick up the user."
349,17629678,2019.09.02,20220242446,2022.08.04,20220242446,2022.08.04,,,AUTOMATIC DRIVING CONTROL DEVICE AND AUTOMATIC DRIVING CONTROL METHOD,"B60W60/00,G06V20/58,B60W50/14","Mitsubishi Electric Corporation,Mitsubishi Electric Corporation","Included are: an information acquisition unit for acquiring a plurality of pieces of vehicle surrounds information output from a plurality of respective sensors; a control amount inferring unit for inferring an automatic driving control amount on the basis of the plurality of pieces of vehicle surrounds information and a machine learning model, and outputting the automatic driving control amount; a monitoring unit for determining whether or not the reliability of any one of the plurality of pieces of vehicle surrounds information has decreased; and a control unit for controlling, when the monitoring unit determines that the reliability of any one of the plurality of pieces of vehicle surrounds information has decreased, the control amount inferring unit in such a way as to output the automatic driving control amount excluding an influence of the one of the plurality of pieces of vehicle surrounds information whose reliability is determined to be decreased."
350,16997981,2020.08.20,,,11414087,2022.08.16,11414087,2022.08.16,Method and system for providing personalized interactive assistance in an autonomous vehicle,"B60W40/08,G06N3/04,G06F9/451,B60W50/12",Wipro Limited,"Disclosed herein is method and interactive assistance system for providing personalized assistance to a driver or person in an autonomous vehicle. Parameters related to the user and the vehicle are monitored and compared with historical data to determine a deviation in the parameters. An abnormal condition is detected when the deviation is more than an optimal threshold. Further, a personalized interaction is initiated with the user through a selected one of the interactive assistance engine and one or more assistive activities are performed for handling the abnormal condition. In an embodiment, the method of present disclosure enhances both safety and user experience of the user of the autonomous vehicle."
351,17171390,2021.02.09,20220252409,2022.08.11,20220252409,2022.08.11,,,UPDATING A PICK-UP OR DROP-OFF LOCATION FOR A PASSENGER OF AN AUTONOMOUS VEHICLE,G01C21/34,GM Cruise Holdings LLC,"An autonomous vehicle (AV) described herein is configured to receive a pull over location specified by a passenger, and is further configured to refine the pull over location based upon one or more factors, where the factors include computer-readable content from a profile of the passenger, sensor data output by sensor systems of the AV, observed or predicted weather conditions, observed or predicted traffic, and/or observations recently generated by other AVs that belong to the same fleet as the AV."
352,17522256,2021.11.09,20220250644,2022.08.11,20220250644,2022.08.11,,,Trajectory Validation for Autonomous Driving,B60W60/00,Aptiv Technologies Limited,"A method of determining whether a planned trajectory of a first vehicle over a road along which the first vehicle and a second vehicle are traveling, is invalid, comprising: obtaining the planned trajectory, comprising a first state of the first vehicle for each of a plurality of time instants; obtaining a second state of the second vehicle for each time instant; determining, for each time instant, a respective lateral range extending from the second vehicle; and determining that the planned trajectory is invalid where, for the first and second states at one or more of the time instants: the first vehicle is within the lateral range and within a lane boundary region of the road; and a direction of a lateral velocity of the first vehicle is towards the second vehicle and a lateral acceleration of the first vehicle away from the second vehicle is smaller than a predetermined threshold."
353,16917118,2020.06.30,,,11409303,2022.08.09,11409303,2022.08.09,Image processing method for autonomous driving and apparatus thereof,"G05D1/02,H04N5/235,G06T5/00,G01C21/16,G01S19/47,G01C21/34,G01C21/26,H04N5/232,G06V10/25,G06V10/141,G06V20/56,G06V20/58,G06T7/73,G05D1/00,G06T5/50","SAMSUNG ELECTRONICS CO., LTD.",A processor implemented image processing method includes recognizing a target object in a first frame of an input image; adjusting an exposure of a second frame of the input image based on a brightness of the target object; and generating a synthesized image by synthesizing the first frame and the second frame.
354,17623794,2020.10.16,20220253748,2022.08.11,20220253748,2022.08.11,,,Techniques for Training Systems for Autonomous Vehicle Navigation,G06N20/00,Mobileye Vision Technologies Ltd.,"Techniques are disclosed for the implementation of machine learning model training utilities to generate models for advanced driving assistance system (ADAS), driving assistance, and/or automated vehicle (AV) systems. The techniques described herein may be implemented in conjunction with the utilization of open source and cloud-based machine learning training utilities to generate machine learning trained models. One example of such an open source solution includes TensorFlow, which is a free and open-source software library for dataflow and differentiable programming across a range of tasks. TensorFlow may be used in conjunction with many different types of machine learning utilities, such as Amazon's cloud-based SageMaker utility for instance, which is a fully-managed service that enables developers and data scientists to quickly and easily build, train, and deploy machine learning models at any scale."
355,16500308,2019.07.04,,,11414097,2022.08.16,11414097,2022.08.16,"Apparatus for generating position data, autonomous vehicle and method for generating position data","B60W60/00,G06T7/70,B60W40/08,B60W40/12,B60W50/10",LG Electronics Inc.,"Disclosed is an apparatus for generating position data including a processor which acquires position information of an antenna installed in a vehicle, generates position data of the vehicle based on the position information of the antenna, acquires information about change in an external appearance of the vehicle, and corrects the position data of the vehicle based on the information about the change in the external appearance of the vehicle."
356,16834459,2020.03.30,,,11415997,2022.08.16,11415997,2022.08.16,Autonomous driving simulations based on virtual simulation log data,"G05D1/02,G01C21/34","Zoox, Inc.","A driving simulation system may perform simulations using one or more of a virtual driving simulator or a log-based driving simulator. A log-based simulator may replay data from logs to test whether a control algorithm is successfully capable of navigating a scenario. However, when such log-based simulations are invalid (e.g., based on the results of the simulations or evaluations of conditions of the simulation), a virtual simulation may be generated for the vehicle control system during which new log data may be captured. Such a virtual simulation may comprise sensor simulations and more sophisticated object control for ensuring convergence to a scenario to be tested. The new log data may be used for additional log-based simulations, thereby improving the durability and flexibility for testing and/or validation, while reducing the computational overhead of driving simulation scenarios."
357,17400341,2021.08.12,20220063716,2022.03.03,20220063716,2022.03.03,,,APPARATUS AND METHOD FOR CONTROLLING STEERING OF AUTONOMOUS VEHICLE,"B62D6/00,B60W60/00,B62D15/02","HYUNDAI MOBIS CO., LTD,HYUNDAI MOBIS CO., LTD","Disclosed are apparatuses and methods for controlling the steering of an autonomous vehicle. The apparatus including an electric power steering device to generate an assist torque for a steering wheel, an autonomous driving position controller to control a steering position according to a command steering angle input from an autonomous driving module, a driver steering intervention judger to judge whether a driver intervenes in steering based on a column torque and a vehicle speed, a weight detector to detect a weight for integrating output of an electric power steering device and output of an autonomous driving position controller based on judging whether the driver intervenes in steering, and an output controller to apply the weight to the output of the electric power steering device and the output of the autonomous driving position controller to integrate the output of the electric power steering device and the output of the autonomous driving position controller, wherein the autonomous driving position controller is further configured to adjust a gain value for controlling the steering position by applying the weight."
358,17013996,2020.09.08,20220073097,2022.03.10,20220073097,2022.03.10,,,Methods and Systems for using Remote Assistance to Maneuver an Autonomous Vehicle to a Location,"B60W60/00,G05D1/00",Waymo LLC,"Example embodiments relate to using remote assistance to maneuver an autonomous vehicle to a location. A computing device used by a remote operator may receive a request for assistance from a vehicle that indicates the vehicle is stopped at a first location with one or more navigation options for enabling the vehicle to navigate from the first location to a second location. At least one navigation option includes a maneuver technique that requires operator approval prior to execution. The computing device may then display a graphical user interface (GUI) that conveys the one or more navigation options. Based on detecting a selection of a particular navigation option, the computing device may transmit instructions to the vehicle to perform the particular navigation option. The vehicle may configured to navigate from the first location to the second location by performing the particular navigation option while monitoring for changes in the environment."
359,17341788,2021.06.08,20220073055,2022.03.10,20220073055,2022.03.10,,,SYSTEM AND METHOD FOR CONTROLLING AUTONOMOUS PARKING OF VEHICLE,"B60W30/06,G06K9/00,G06K9/46,G06K9/62,G06K9/40","HYUNDAI MOTOR COMPANY,KIA CORPORATION,Hyundai Mobis Co., Ltd.","A system for performing autonomous parking of a vehicle includes: a camera configured to acquire a surrounding image of the vehicle including a parking line; and a controller configured to derive spatial recognition data based on the surrounding vehicle image as an input, derive a feature point corresponding to the parking line based on the surrounding image and the spatial recognition data, determine a candidate parking line based on clustering of the feature point, and control the vehicle to perform parking in a parking area having the candidate parking line."
360,16516068,2019.07.18,,,11390212,2022.07.19,11390212,2022.07.19,"Method and apparatus for unmanned vehicle passing through intersection, device and storage medium","B60Q5/00,G05D1/00,G05D1/02,B60R11/02,B60Q1/50","Baidu Online Network Technology (Beijing) Co., Ltd.","Embodiments of the present application provide a method and an apparatus for an unmanned vehicle passing through an intersection, a device and a storage medium. The method includes: detecting whether the unmanned vehicle is at an intersection without a traffic light sign; identifying a moving direction and a distance of outside personnel and/or identifying voice and limb reaction of the outside personnel when determining that the unmanned vehicle is at the intersection without the traffic light sign; determining whether to pass according to the moving direction and the distance of the outside personnel, and/or the voice and limb reaction of the outside personnel; and making a corresponding voice prompt and/or a corresponding visual prompt to the outside personnel according to a result of the determination on whether to pass."
361,16580076,2019.09.24,,,11348182,2022.05.31,11348182,2022.05.31,Autonomous vehicle operation feature monitoring and evaluation of effectiveness,"G06Q40/00,G06Q40/08,H04L67/12,H04W4/90,H04W4/44,G07C5/00,B60W40/09,G08G1/005,G08G1/16,G08G1/0967,G08G1/14,G08B21/06,B60W30/16,G08G1/00,G06K9/00,G08B25/08,G07C5/08,G06F30/20,G06Q10/06,B60Q9/00,G06Q20/08,B60R21/00,G05B15/02,H04W4/46,B60W40/08,G01S19/13,G06Q50/30",State Farm Mutual Automobile Insurance Company,"Methods and systems for monitoring use and determining risks associated with operation of a vehicle having one or more autonomous operation features are provided. According to certain aspects, a virtual log of data regarding performance of the features in a virtual test environment may be recorded during operation of the vehicle. This may include information regarding the vehicle, the vehicle environment, use of the autonomous operation features, and/or control decisions made by the features. The control decisions may include evasive maneuvers performed by the vehicle under the control of the features. The performance data in the virtual log may be used to determine risk levels associated with vehicle operation by the autonomous operation features. The risk levels may further be used to adjust an insurance policy associated with the vehicle."
362,16536231,2019.08.08,,,11249480,2022.02.15,11249480,2022.02.15,Autonomous vehicle positioning system,"G05D1/00,G08G1/01,G05D1/02,G08G1/09","TOYOTA MOTOR NORTH AMERICA, INC.","Systems and methods are provided to determine traffic configuration parameters, such as location and speed, that are correlated with optimal traffic flow specific to particular road regions. In a specific embodiment, the disclosure is directed to a vehicle positioning system which utilizes a multi-client server application model configured to perform predictive analysis based upon data collected from a plurality of data streams, infrastructure elements, and vehicles. In a particular implementation, roadways may be partitioned into road regions which may be associated with vehicle configuration templates. Vehicle configuration templates may define instructions for automated vehicle driving parameters within a particular road region. In a specific embodiment, the vehicle positioning system may invoke transition sequences based upon real-time traffic data to modify a given traffic configuration."
363,16380002,2019.04.10,,,11400925,2022.08.02,11400925,2022.08.02,Planning for unknown objects by an autonomous vehicle,"B60W30/09,G08G1/16,G06V10/26,G06V20/56,G06V20/58,B60W10/20,B60W10/184,G05D1/00,G05D1/02",Motional AD LLC,"Among other things, a model is maintained of an environment of a vehicle. A hypothetical object in the environment that cannot be perceived by sensors of the vehicle is included in the model."
364,16676563,2019.11.07,,,11238538,2022.02.01,11238538,2022.02.01,Accident risk model determination using autonomous vehicle operating data,"G06Q40/00,G06Q40/08,G08G1/16,G08G1/0967,G08G1/14,G08B21/06,B60W30/16,G08G1/00,G06K9/00,G08B25/08,G07C5/08,H04L29/08,H04W4/90,H04W4/44,G07C5/00,B60W40/09,G06Q10/06,B60Q9/00,G06Q20/08,B60R21/00,G05B15/02,G08G1/005,G06Q50/30,B60W40/08,H04W4/46,G01S19/13",State Farm Mutual Automobile Insurance Company,"Methods and systems for evaluating the effectiveness of autonomous operation features of autonomous vehicles using an accident risk model are provided. According to certain aspects, an accident risk model may be determined using effectiveness information regarding autonomous operation features associated with a vehicle. The effectiveness information may indicate a likelihood of an accident for the vehicle and may include test data or actual loss data. Determining the likelihood of an accident may include determining risk factors for the features related to the ability of the features to make control decisions that successfully avoid accidents. The accident risk model may further include information regarding effectiveness of the features relative to location or operating conditions, as well as types and severity of accidents. The accident risk model may further be used to determine or adjust aspects of an insurance policy associated with an autonomous vehicle."
365,16404208,2019.05.06,,,11235761,2022.02.01,11235761,2022.02.01,Operational risk assessment for autonomous vehicle control,"B60W30/095,B60W30/09,G05D1/00,G06K9/00","Retrospect Technology, LLC","Changes in the controlling of an autonomous vehicle are caused based on an operational risk determined for the autonomous vehicle. An operational risk monitor module of the autonomous vehicle uses information about objects detected within an environment in which the autonomous vehicle is located and predicted behaviors of those objects to assess the operational risk of the autonomous vehicle along a planned path. The operational risk is used to determine whether to cause a change in the controlling of the autonomous vehicle, for example, based on a comparison between the operational risk and a previously estimated operational risk or based on a determination that the operational risk exceeds a threshold. The operational risk monitor module transmits a signal to one or more control system modules of the autonomous vehicle to indicate to change the controlling of the autonomous vehicle based on the operational risk."
366,17649330,2022.01.28,20220234622,2022.07.28,20220234622,2022.07.28,,,Systems and Methods for Autonomous Vehicle Control,"B60W60/00,B60W30/095,G06K9/62","dRISK, Inc.,dRISK, Inc.","Systems and methods for training AV models in accordance with embodiments of the invention are illustrated. One embodiment includes an autonomous vehicle (AV), a vehicle, a processor, and a memory, where the memory contains an AV model capable of driving the vehicle without human input, where the AV model is trained on a plurality of edge case scenarios. In a still further additional embodiment, a method for training AV models, including obtaining a data structure storing a plurality of scenarios that an AV can encounter, and distance metrics indicating the distance between each scenario, generating a list of edge case scenarios within the plurality of scenarios, identifying hazard frames within the edge case scenarios, encoding the hazard frames into one or more records interpretable by an AV model, and training the AV model using the one or more records."
367,16809540,2020.03.04,,,11386674,2022.07.12,11386674,2022.07.12,Class labeling system for autonomous driving,"G06V20/56,G06K9/62,G06T7/12,G06V10/44,G06V10/22,G06V10/24,G06V20/58","HYUNDAI MOBIS Co., Ltd.","A class labeling system for autonomous driving includes a detection module, a segmentation module, and a lane road boundary detection module. The detection module is configured to detect objects for autonomous driving from an image captured by a camera to generate a bounding box for each of the objects and detect property information about the object. The segmentation module is configured to determine classes for each pixel of the bounding box detected by the detection module and process at least one of the classes as don't care. The lane road boundary detection module is configured to detect at least one of lane and road boundaries using the bounding box detected by the detection module."
368,16705071,2019.12.05,,,11372426,2022.06.28,11372426,2022.06.28,Automated vehicle for autonomous last-mile deliveries,"G05D1/02,G06Q10/08,B60R25/24,B60R25/01","DoorDash, Inc.","Provided are various systems and processes for improving last-mile delivery of real-time, on-demand orders for perishable goods. In one aspect, an automated vehicle (AV) comprises a body including a storage compartment for storing perishable goods. The storage compartment is accessible by a user upon authentication of the user. The AV further comprises a sensor module for receiving data for navigating the AV. The sensor module is positioned above the body on a support structure at a predetermined height above the ground, such as three to five feet. The data includes one or more of the following: audio data, video data, radio waves, and backscattered light waves. The AV further comprises an onboard computer system configured to process the data to navigate the AV along motor vehicle routes and pedestrian routes. The AV may be configured to interface with an automated locker system to retrieve or deposit the perishable goods."
369,17126764,2020.12.18,20220192076,2022.06.23,20220192076,2022.06.23,,,MACHINE-LEARNED TILLAGE PLUG DETECTION IN AN AUTONOMOUS FARMING VEHICLE,"A01B79/00,G06N20/00,G05D1/00,G06T7/00,G06T7/70",Blue River Technology Inc.,"A detection system detects malfunctions in an autonomous farming vehicle during an autonomous routine using one or more models and data from sensors coupled to the autonomous farming vehicle. The models may include machine-learned models trained on the sensor data and configured to identify objects indicative of an operational or malfunctioning component within a tilling assembly such as a tilling shank or sweep. Additionally, a machine-learned model may be trained on sensor data to detect whether debris has plugged the tilling assembly of the autonomous farming vehicle. In response to detecting a malfunction or a plug, the detection system may modify the autonomous routine (e.g., pausing operation) or provide information for the malfunction to be addressed (e.g., the likely location of a malfunctioning sweep that has detached from the tilling assembly)."
370,17150581,2021.01.15,20220227389,2022.07.21,20220227389,2022.07.21,,,RESPONDER OVERSIGHT SYSTEM FOR AN AUTONOMOUS VEHICLE,"B60W60/00,G05D1/02,G05D1/00,G07C5/00,G07C5/08","TuSimple, Inc.","A system includes an autonomous vehicle (AV) comprising a sensor, a control subsystem, and an operation server. The control subsystem receives sensor data comprising location coordinates of the AV from the sensor. The operation server detects an unexpected event from the sensor data, comprising at least one of an accident, an inspection, and a report request. The operation server receives a message from a user comprising a request to access particular information regarding the AV and location data. The operation server associates the AV with the user if the location coordinates of the AV match location data of the user. The operation server generates a ticket for the unexpected ticket. The operation server communicates the particular information to the user. The operation server provides instructions to be forwarded to the user based on a request from the user. The operation server closes the ticket if the unexpected event is addressed."
371,16578549,2019.09.23,,,11352071,2022.06.07,11352071,2022.06.07,Autonomous versatile vehicle system,"B62D33/063,G05D1/02,B60W60/00,G05D1/00","Ali Ebrahimi Afrouzi,Lukas Fath,Shahin Fathi Djalali","Provided is a first robot including: a machine readable medium storing instructions that when executed by the processor of the first robot effectuates operations including: executing, with the processor of the first robot, a task; and transmitting, with the processor of the first robot, a signal to a processor of a second robot during execution of the task when its power supply level reduces below a predetermined threshold; and the second robot including: a machine readable medium storing instructions that when executed by the processor of the second robot effectuates operations including: executing, with the processor of the second robot, the remainder of the task upon receiving the signal transmitted from the processor of the first robot; and wherein the first robot navigates to a charging station when its power supply level reduces below the predetermined threshold and wherein the first robot and second robot provide the same services."
372,17657878,2022.04.04,20220229435,2022.07.21,20220229435,2022.07.21,,,METHOD AND SYSTEM FOR OPTIMIZING REINFORCEMENT-LEARNING-BASED AUTONOMOUS DRIVING ACCORDING TO USER PREFERENCES,"G05D1/00,G05D1/02,G05B13/02","NAVER CORPORATION,NAVER LABS CORPORATION","A method for optimizing autonomous driving includes applying different autonomous driving parameters to a plurality of robot agents in a simulation through an automatic setting by means of the system or a direct setting by means of a manager, so that the robot agents learn robot autonomous driving; and optimizing the autonomous driving parameters by using preference data for the autonomous driving parameters."
373,16909962,2020.06.23,,,11373389,2022.06.28,11373389,2022.06.28,Partitioning images obtained from an autonomous vehicle camera,"G06K9/00,G06V10/25,G06T7/11,G06T7/70,B60W60/00,G01C21/36,G06V20/58,G06V20/56","TUSIMPLE, INC.","Image processing techniques are described to select and crop a region of interest from an image obtained from a camera located on or in a vehicle, such as an autonomous semi-trailer truck. The region of interest can be identified by selecting one or more reference points and determining one or more positions of the one or more reference points on the image obtained from the camera. As an example, a location of two reference points may be 500 meters and 1000 meters in front of a location of autonomous vehicle, where the front of the autonomous vehicle is an area towards which the autonomous vehicle is being driven."
374,17694385,2022.03.14,20220197120,2022.06.23,20220197120,2022.06.23,,,Control of Display Device for Autonomous Vehicle,"G03B21/14,G06F3/038,G02B27/01,G03B21/00,G06V40/16","Micron Technology, Inc.","A display device of an autonomous vehicle is controlled based on data collected from sensors located in or on the vehicle. The display device is used to present one or more images to a driver and/or passengers of the autonomous vehicle. The display device can be, for example, a windshield and/or other window of the vehicle. Image data can be, for example, transformed to improve visual perception by passengers in the vehicle when the images are displayed on a curved shape of the windshield."
375,16682546,2019.11.13,,,11370419,2022.06.28,11370419,2022.06.28,Use of driver assistance collision mitigation systems with autonomous driving systems,"B60W30/09,B60W10/18,B60W10/20,B60W50/00,H04L67/12,H04L12/40",Robert Bosch GmbH,"Systems and methods for controlling a vehicle. The system includes one or more sensors positioned on the vehicle and configured to sense an environment surrounding the vehicle, a collision mitigation subsystem configured to control a braking system of the vehicle, and an autonomous driving subsystem communicatively coupled to the one or more sensors and the collision mitigation subsystem. The autonomous driving subsystem is configured to receive sensor information from the one or more sensors and generate, based on the sensor information, a model of the environment surrounding the vehicle. The autonomous driving subsystem is configured to determine, based on the model of the environment surrounding the vehicle, a plurality of possible trajectories for the vehicle and to select, from the plurality of possible trajectories, a travel path for the vehicle. The autonomous driving subsystem is configured to transmit the travel path to the collision mitigation subsystem."
376,16988160,2020.08.07,,,11325613,2022.05.10,11325613,2022.05.10,Automatic driving system,"B60W60/00,B60W50/06,B60R1/12,B60W40/02,G06K9/00,G06V20/56",SUBARU CORPORATION,An automatic driving system allows a vehicle to travel by automatic driving. The system includes first and second detectors and first and second determiners. The first detector is disposed on a movable part of the vehicle and detects an object located around the vehicle. The second detector is disposed on the vehicle and has an object detection region that partially overlaps a detection region of the first detector. The first determiner determines whether a detection state of the first detector based on a position of the object detected by the second detector and behavior of the object estimated from a detection position of the first detector and a traveling state of the vehicle. The automatic driving availability determiner determines availability of the automatic driving according to the detection state of the first detector and disables the automatic driving when the first detector is not in a regular detection state.
377,17126793,2020.12.18,20220198642,2022.06.23,20220198642,2022.06.23,,,MACHINE-LEARNED TILLAGE SWEEP MALFUNCTION IN AN AUTONOMOUS FARMING VEHICLE,"G06T7/00,G06N20/00,G06K9/00,G06K9/62",Blue River Technology Inc.,"A detection system detects malfunctions in an autonomous farming vehicle during an autonomous routine using one or more models and data from sensors coupled to the autonomous farming vehicle. The models may include machine-learned models trained on the sensor data and configured to identify objects indicative of an operational or malfunctioning component within a tilling assembly such as a tilling shank or sweep. Additionally, a machine-learned model may be trained on sensor data to detect whether debris has plugged the tilling assembly of the autonomous farming vehicle. In response to detecting a malfunction or a plug, the detection system may modify the autonomous routine (e.g., pausing operation) or provide information for the malfunction to be addressed (e.g., the likely location of a malfunctioning sweep that has detached from the tilling assembly)."
378,17600092,2020.10.08,20220183645,2022.06.16,20220183645,2022.06.16,,,ARTIFICIAL INTELLIGENCE-BASED ORAL CT AUTOMATIC COLOR CONVERSION DEVICE AND METHOD FOR DRIVING SAME,"A61B6/00,A61B6/03,A61B6/14,A61B34/10","MEGAGEN IMPLANT CO., LTD.,KYUNGPOOK NATIONAL UNIVERSITY HOSPITAL,Kyungpook National University Industry-Academic Cooperation Foundation","The present disclosure relates to an artificial intelligence-based oral CT automatic color conversion device and a method for driving same. The artificial intelligence-based oral CT automatic color conversion device according to an embodiment of the present invention comprises: a storage unit which stores a color conversion image related to the bone density of an alveolar bone, which is previously prepared by a user; and a control unit which, when an oral CT input image of a patient is received, converts color of the received oral CT input image on the basis of a predetermined parameter value, and adjusts the predetermined parameter value by using an error value resulting from the converted oral CT input image and the (pre)stored color conversion image to automatically convert the color of an oral CT input image to be input later."
379,16917403,2020.06.30,,,11338827,2022.05.24,11338827,2022.05.24,Autonomous vehicle and system for autonomous vehicle,"B60W60/00,H04W4/40,B60W50/029,G07C5/08,G06F21/60,H04W88/16","Apollo Intelligent Driving Technology (Beijing) Co., Ltd.","Embodiments of the present disclosure relate to an autonomous vehicle and a system for the autonomous vehicle. The system may include a master computing unit configured to control operations of the autonomous vehicle; a slave computing unit communicatively coupled to the master computing unit and configured to control the operations of the autonomous vehicle in response to detecting a failure of the master computing unit; at least one lidar configured to acquire environmental information around the autonomous vehicle; and a switch communicatively coupled to the at least one lidar, the master computing unit and the slave computing unit, and configured to provide the environmental information to the master computing unit and the slave computing unit for controlling the autonomous vehicle."
380,16869438,2020.05.07,,,11358601,2022.06.14,11358601,2022.06.14,"Training machine learning model based on training instances with: training instance input based on autonomous vehicle sensor data, and training instance output based on additional vehicle sensor data","B60W40/00,B60W40/04,B60W30/095,G05D1/02,G05D1/00,G06N20/00,G06K9/62,G01S17/931,G01S17/89","Aurora Innovation, Inc.","Various implementations described herein generate training instances that each include corresponding training instance input that is based on corresponding sensor data of a corresponding autonomous vehicle, and that include corresponding training instance output that is based on corresponding sensor data of a corresponding additional vehicle, where the corresponding additional vehicle is captured at least in part by the corresponding sensor data of the corresponding autonomous vehicle. Various implementations train a machine learning model based on such training instances. Once trained, the machine learning model can enable processing, using the machine learning model, of sensor data from a given autonomous vehicle to predict one or more properties of a given additional vehicle that is captured at least in part by the sensor data."
381,17126800,2020.12.18,20220198643,2022.06.23,20220198643,2022.06.23,,,MACHINE-LEARNED TILLAGE SHANK MALFUNCTION IN AN AUTONOMOUS FARMING VEHICLE,"G06T7/00,G06K9/62,H04N13/204,G06T7/593,A01B79/00,A01B3/26,G06N20/00,G06K7/10,G06K19/07",Blue River Technology Inc.,"A detection system detects malfunctions in an autonomous farming vehicle during an autonomous routine using one or more models and data from sensors coupled to the autonomous farming vehicle. The models may include machine-learned models trained on the sensor data and configured to identify objects indicative of an operational or malfunctioning component within a tilling assembly such as a tilling shank or sweep. Additionally, a machine-learned model may be trained on sensor data to detect whether debris has plugged the tilling assembly of the autonomous farming vehicle. In response to detecting a malfunction or a plug, the detection system may modify the autonomous routine (e.g., pausing operation) or provide information for the malfunction to be addressed (e.g., the likely location of a malfunctioning sweep that has detached from the tilling assembly)."
382,16288701,2019.02.28,,,11341854,2022.05.24,11341854,2022.05.24,Autonomous vehicle fleet management system,"G08G1/00,G05D1/00,G06Q10/02","UIPCO, LLC","A vehicle dispatch system including a device processor and a non-transitory computer readable medium including instructions executable by the device processor to perform the following steps: receiving a user request for one or more services; dispatching, to a location designated by the user, a vehicle configured to provide one or more services to the user."
383,16397965,2019.04.29,,,11294265,2022.04.05,11294265,2022.04.05,Control of display device for autonomous vehicle,"G02B27/01,G03B21/00,G03B21/14,G06F3/038,G06K9/00","Micron Technology, Inc.","A display device of an autonomous vehicle is controlled based on data collected from sensors located in or on the vehicle. The display device is used to present one or more images to a driver and/or passengers of the autonomous vehicle. The display device can be, for example, a windshield and/or other window of the vehicle. Image data can be, for example, transformed to improve visual perception by passengers in the vehicle when the images are displayed on a curved shape of the windshield."
384,17679452,2022.02.24,20220180448,2022.06.09,20220180448,2022.06.09,,,AUTONOMOUS VEHICLE OPERATION FEATURE MONITORING AND EVALUATION OF EFFECTIVENESS,G06Q40/08,"STATE FARM MUTUAL AUTOMOBILE INSURANCE COMPANY,STATE FARM MUTUAL AUTOMOBILE INSURANCE COMPANY","Methods and systems for monitoring use and determining risks associated with operation of a vehicle having one or more autonomous operation features are provided. According to certain aspects, operating data may be recorded during operation of the vehicle. This may include information regarding the vehicle, the vehicle environment, use of the autonomous operation features, and/or control decisions made by the features. The control decisions may include actions the feature would have taken to control the vehicle, but which were not taken because a vehicle operator was controlling the relevant aspect of vehicle operation at the time. The operating data may be recorded in a log, which may then be used to determine risk levels associated with vehicle operation based upon risk levels associated with the autonomous operation features. The risk levels may further be used to adjust an insurance policy associated with the vehicle."
385,17670871,2022.02.14,20220164896,2022.05.26,20220164896,2022.05.26,,,FULLY AUTONOMOUS VEHICLE INSURANCE PRICING,"G06Q40/08,G06Q40/00","STATE FARM MUTUAL AUTOMOBILE INSURANCE COMPANY,STATE FARM MUTUAL AUTOMOBILE INSURANCE COMPANY","Methods and systems for determining risk associated with operation of fully autonomous vehicles are provided. According to certain aspects, autonomous operation features associated with a vehicle may be determined, including types and version of sensors, control systems, and software. This information may be used to determine a risk profile reflecting risk levels for a plurality of features, which may be based upon test data regarding the features or actual loss data. Expected use levels may further be determined and used with the risk profile to determine a total risk level associated with operation of the vehicle by the autonomous operation features. The expected use levels may indicate expected vehicle use, as well as traffic, weather, or other conditions in which the vehicle is likely to operate. The total risk level may be used to determine or adjust aspects of an insurance policy associated with the vehicle."
386,16953774,2020.11.20,20220163974,2022.05.26,20220163974,2022.05.26,,,OFF-ROAD MACHINE-LEARNED OBSTACLE NAVIGATION IN AN AUTONOMOUS VEHICLE ENVIRONMENT,"G05D1/02,G06K9/00,G06K9/62,G06N3/02",Deere &#x26; Company,"An autonomous off-road vehicle, upon encountering an obstruction while navigating a route, can apply a first machine-learned model to identify the obstruction. In the event that the first machine-learned model cannot identify the obstruction, the autonomous off-road vehicle can apply a second machine-learned model configured to determine whether or not the obstruction can be ignored, for instance based on dimensions of the obstruction. If the obstruction can be ignored, the autonomous off-road vehicle can continue navigating the route. If the obstruction cannot be ignored, the autonomous off-road vehicle can modify the route, can stop, can flag the obstruction to a remote human operator, can modify an interface of a human operator to display a notification or a video feed from the vehicle, and the like."
387,16516137,2019.07.18,,,11315349,2022.04.26,11315349,2022.04.26,"Method, apparatus and device for identifying passenger state in unmanned vehicle, and storage medium","G06K9/00,G06V20/59,G07C5/08,G10L25/51,G10L25/03,A61B5/0205,A61B5/11,A61B5/00,G06K9/62,G06V40/20,G06V40/16","Apollo Intelligent Driving Technology (Beijing) Co., Ltd.","Embodiments of the present application provide a method, an apparatus, and a device for identifying a passenger state in an unmanned vehicle, and a storage medium. The method comprises: obtaining monitoring data of different dimensions in a process where the passenger takes the unmanned vehicle; performing feature extraction on the monitoring data of the different dimensions and forming feature data of different dimensions; and identifying the passenger state according to the feature data of the different dimensions. By obtaining the monitoring data of various dimensions in the process where the passenger takes the unmanned vehicle to identify the passenger state, it is possible to omnidirectionally monitor the personal is safety and property safety of the passengers, and effectively protect the passenger taking the unmanned vehicle."
388,17532846,2021.11.22,20220163346,2022.05.26,20220163346,2022.05.26,,,METHOD AND APPARATUS FOR GENERATING A MAP FOR AUTONOMOUS DRIVING AND RECOGNIZING LOCATION,"G01C21/00,G06T7/10",ELECTRONICS AND TELECOMMUNICATIONS RESEARCH INSTITUTE,"Disclosed are a method and an apparatus for generating a map for autonomous driving and recognizing a location based on the generated map. When generating a map, a spherical range image is obtained by projecting 3D coordinate information corresponding to a 3D space onto a 2D plane, and semantic segmentation is performed on the spherical range image to generate a semantic segmented image. Then, map data including a spherical range image, a semantic segmented image, and lane attribute information are generated."
389,17652818,2022.02.28,20220179418,2022.06.09,20220179418,2022.06.09,,,DEPART CONSTRAINTS IMPLEMENTATION IN AUTONOMOUS VEHICLE ROUTING,"G05D1/00,G05D1/02,G01C21/34","UATC, LLC","A method of controlling navigation of autonomous vehicles includes accessing map data descriptive of the identity and location of different travel ways within a surrounding environment of an autonomous vehicle and accessing constraint data descriptive of one or more geographic areas or geographic identifiers, within the map data, for which associated navigational constraints are defined. The constraint data includes a depart constraint that specifies an area that an autonomous vehicle may not enter but may exit if inside the area when the depart constraint is imposed, thereby preventing the autonomous vehicle from being trapped in a forbidden area even though the autonomous vehicle may safely complete its route. A travel route is determined for the autonomous vehicle based at least in part on the map data evaluated relative to the constraint data including the depart constraint, and motion of the autonomous vehicle is controlled based on the determined travel route."
390,17117007,2020.12.09,20220176957,2022.06.09,20220176957,2022.06.09,,,Indirect Verification of Speed Limits Based on Contextual Information For Autonomous and Semi-Autonomous Driving Systems,"B60W30/14,B60W60/00,G05D1/02,G06K9/00,G01C21/36",Aptiv Technologies Limited,"This document describes techniques and systems to indirectly verify speed limits based on contextual information for autonomous and semi-autonomous driving systems. In addition to camera systems, the described techniques and systems use other sensors and secondary factors to improve the accuracy and confidence in detecting posted speed limits. For example, a camera system captures an image or other data directly indicative of a speed limit. Contextual information for the road or vehicles nearby is also obtained and used to determine at least one indirect indication of the speed limit. A composite speed limit is identified by applying a respective weight to the direct and indirect indications of the speed limit. The described systems and techniques thereby enable controlling the vehicle based on the composite speed limit. In this way, the described systems and techniques can verify a speed limit to make autonomous and semi-autonomous driving systems safer."
391,17678334,2022.02.23,20220176912,2022.06.09,20220176912,2022.06.09,,,Automatic Vehicle Window Cleaning Method and Apparatus,"B60S1/02,G06V10/56,G06V20/56","Huawei Technologies Co., Ltd.","This application provides an automatic vehicle window cleaning method and apparatus, used to detect a foreign object on a vehicle window based on a value of a pixel in a vehicle window image, and perform automatic cleaning. The method includes: obtaining a vehicle window image; determining a dark channel image corresponding to a single frame of vehicle window image; further determining, based on a quantity of pixels whose gray values exceed a preset gray threshold in the dark channel image and/or definition of the dark channel image, that a first-type foreign object exists on a vehicle window; and/or determining, based on RGB values of pixels in i consecutive frames of vehicle window images, that a second-type foreign object exists on the vehicle window; and controlling a cleaning tool to remove a foreign object. The foreign object includes the first-type foreign object and/or the second-type foreign object."
392,17556446,2021.12.20,20220114627,2022.04.14,20220114627,2022.04.14,,,METHODS AND SYSTEMS FOR AUTOMATIC PROCESSING OF IMAGES OF A DAMAGED VEHICLE AND ESTIMATING A REPAIR COST,"G06Q30/02,G06Q10/00,G06V30/194,G06T7/00,G06Q10/08,G06N20/00","STATE FARM MUTUAL AUTOMOBILE INSURANCE COMPANY,STATE FARM MUTUAL AUTOMOBILE INSURANCE COMPANY","A system and computer-implemented method for processing images of a damaged vehicle and estimating a repair cost of the damaged vehicle includes receiving image data of a vehicle from a user mobile device. The image data is processed to determine whether one or more parts of the damaged vehicle are damaged. In addition, one or more parts of the damaged vehicle are identified for repair and one or more parts of the damaged vehicle are identified for replacement. A cost associated for the repair of each of the one or more parts of the damaged vehicle for repair is estimated based on estimated repair cost data contained in a parts repair database. Moreover, a cost associated with the replacement of each of the one or more parts of the damaged vehicle for replacement is determined based on replacement cost data contained in a parts replacement database."
393,17110750,2020.12.03,20220176993,2022.06.09,20220176993,2022.06.09,,,SYSTEM AND METHOD FOR AUTONOMOUS VEHICLE PERFORMANCE GRADING BASED ON HUMAN REASONING,"B60W60/00,B60W50/06,G06N3/00",GM GLOBAL TECHNOLOGY OPERATIONS LLC,"An autonomous vehicle and a system and method for operating the autonomous vehicle. The system includes a control system and a cognitive system. The control system performs a driving action at the autonomous vehicle. The cognitive system generates the driving action using an evaluation model. The evaluation model is generated by operating the cognitive system in response to a training set of data to generate a planned action for operating the autonomous vehicle by the cognitive system, evaluating the planned action to obtain a system performance grade, and updating the cognitive system based on a comparison of the system performance grade to a human-based performance grade."
394,17438168,2019.12.25,20220143823,2022.05.12,20220143823,2022.05.12,,,Learning System And Learning Method For Operation Inference Learning Model For Controlling Automatic Driving Robot,"B25J9/16,G05B13/02","Meidensha Corporation,Meidensha Corporation","Provided is a learning system  10  for an operation inference learning model  70  for controlling an automatic driving robot  4  , the learning system  10  training the operation inference learning model  70  by reinforcement learning, and comprising the operation inference learning model  70  , which infers operations of a vehicle  2  for making the vehicle  2  run in accordance with a defined command vehicle speed based on a running state of the vehicle  2  including a vehicle speed, and the automatic driving robot  4  , which is installed in the vehicle  2  and which makes the vehicle  2  run based on the operations. In the learning system  10  for an operation inference learning model  70  for controlling an automatic driving robot  4  , the operation inference learning model  70  is pre-trained by reinforcement learning by applying the simulated running state output by the vehicle learning model  60  to the operation inference learning model  70  , and after the pre-training by reinforcement learning has ended, the operation inference learning model  70  is further trained by reinforcement learning by applying, to the operation inference learning model  70  , the running state acquired by the vehicle  2  being run based on the operations inferred by the operation inference learning model  70."
395,17433319,2020.03.02,20220153301,2022.05.19,20220153301,2022.05.19,,,"Control Unit and Method for Detecting, Classifying and Predicting an Interaction Requirement of an Automatically Driven Vehicle","B60W60/00,B60W50/00",Bayerische Motoren Werke Aktiengesellschaft,An electronic control unit for operating an automatically driven vehicle is designed to detect a present driving situation of the vehicle in which an interaction requirement of the vehicle with a server exists. The electronic control unit is further designed to assign an interaction class from a plurality of different interaction classes to the interaction requirement of the present driving situation. An interaction can be carried out with a server with respect to the present driving situation based on the assigned interaction class. The electronic control unit is additionally designed to predict that the automatically driven vehicle can enter a possible driving situation in a future time period in which an interaction requirement of the vehicle with a server exists. One or more measures can then be initiated in order to prevent the possible driving situation and/or in order to change the interaction requirement of the possible driving situation.
396,17569409,2022.01.05,20220128994,2022.04.28,20220128994,2022.04.28,,,AUTONOMOUS VEHICLE POSITIONING SYSTEM,"G05D1/00,G08G1/01,G05D1/02,G08G1/09","TOYOTA MOTOR NORTH AMERICA, INC.","Systems and methods are provided to implementing a set of instructions related to a vehicle configuration template at a vehicle. Vehicle configuration templates may define instructions for automated vehicle driving parameters within a particular road region. The set of instructions within the first road region may correspond with a vehicle transition sequence based on the vehicle configuration template, where the vehicle transition sequence adjusts at least one of a vehicle position and dynamics to achieve a desired traffic flow."
397,17587280,2022.01.28,20220153264,2022.05.19,20220153264,2022.05.19,,,Operational Risk Assessment for Autonomous Vehicle Control,"B60W30/095,B60W30/09,G05D1/00,G06V20/58","Retrospect Technology, LLC","Changes in the controlling of an autonomous vehicle are caused based on an operational risk determined for the autonomous vehicle. An operational risk monitor module of the autonomous vehicle uses information about objects detected within an environment in which the autonomous vehicle is located and predicted behaviors of those objects to assess the operational risk of the autonomous vehicle along a planned path. The operational risk is used to determine whether to cause a change in the controlling of the autonomous vehicle, for example, based on a comparison between the operational risk and a previously estimated operational risk or based on a determination that the operational risk exceeds a threshold. The operational risk monitor module transmits a signal to one or more control system modules of the autonomous vehicle to indicate to change the controlling of the autonomous vehicle based on the operational risk."
398,17463501,2021.08.31,20220126860,2022.04.28,20220126860,2022.04.28,,,"METHOD AND APPARATUS FOR PROCESSING AUTONOMOUS DRIVING SIMULATION DATA, AND ELECTRONIC DEVICE","B60W60/00,H04L65/61,G07C5/04,B60W50/00","BAIDU.COM TIMES TECHNOLOGY (BEIJING) CO., LTD.,BAIDU.COM TIMES TECHNOLOGY (BEIJING) CO., LTD.",A method for processing autonomous driving simulation data. The method includes: determining a type of a message transmitted between a simulation system and an auto driving system (ADS); determining a data acquisition mode based on the type of the message; obtaining a data stream transmitted between the simulation system and the ADS based on the data acquisition mode; and determining performance of the ADS based on the data stream.
399,17073657,2020.10.19,20220119012,2022.04.21,20220119012,2022.04.21,,,SYSTEMS AND METHODS FOR CONFIGURING AUTONOMOUS VEHICLE OPERATION,"B60W60/00,G06V20/56,B60W30/09,B60W30/095","Lyft, Inc.,Lyft, Inc.","Systems, methods, and non-transitory computer-readable media can detect an occurrence of a condition in an environment based on sensor data captured by a vehicle. A determination is made whether the occurrence of the condition satisfies a threshold associated with a likelihood that a behavior associated with an object in the environment will occur based on an interaction between the condition and the object, wherein the likelihood is based on prior observations of one or more objects. Subsequent to determining that the threshold is satisfied, a vehicle operation that is associated with the likelihood that the behavior associated with the object will occur is performed."
400,16949657,2020.11.09,20220146676,2022.05.12,20220146676,2022.05.12,,,DOPPLER-ASSISTED OBJECT MAPPING FOR AUTONOMOUS VEHICLE APPLICATIONS,"G01S17/89,G01S17/58,G01S17/26,B60W40/02",Waymo LLC,"Aspects and implementations of the present disclosure address shortcomings of the existing technology by enabling efficient object identification and tracking in autonomous vehicle (AV) applications by using velocity data-assisted mapping of first set of points obtained for a first sensing data frame by a sensing system of the AV to a second set of points obtained for a second sensing data frame by the sensing system of the AV, the first set of points and the second set of points corresponding to an object in an environment of the AV, and causing a driving path of the AV to be determined in view of the performed mapping."
401,17470576,2021.09.09,20220126874,2022.04.28,20220126874,2022.04.28,,,Autonomous Driving Control Apparatus and Method,B60W60/00,"Hyundai Motor Company Seoul,Kia Corporation","An autonomous driving control method includes collecting travel information on a host vehicle traveling autonomously and on at least one other vehicle, determining a driving intention of the other vehicle based on the travel information on the other vehicle, predicting a driving route of the other vehicle based on the driving intention of the other vehicle, and determining a driving route of the host vehicle based on the predicted driving route of the other vehicle."
402,16664195,2019.10.25,,,11269324,2022.03.08,11269324,2022.03.08,Method and apparatus for controlling autonomous vehicle,"G05D1/00,B60W30/09","Baidu Online Network Technology (Beijing) Co., Ltd.","A method and an apparatus for controlling an autonomous vehicle are provided according to the embodiments of the disclosure. The method includes: sending, in response to determining that a pedestrian is in a first target area, behavior prompt information representing prompting the pedestrian to make a corresponding behavior; determining whether a deceleration condition matching the behavior prompt information is satisfied based on acquired behavior information of the pedestrian; and sending control information for reducing a moving speed of the autonomous vehicle, in response to determining that the deceleration condition is satisfied and determining that a speed of the autonomous vehicle is greater than a preset deceleration threshold. According to the embodiments, deceleration control of the autonomous vehicle is achieved based on the response of the pedestrian to the behavior prompt information."
403,16431991,2019.06.05,,,11282143,2022.03.22,11282143,2022.03.22,Fully autonomous vehicle insurance pricing,"G06Q40/08,G06Q40/00",State Farm Mutual Automobile Insurance Company,"Methods and systems for determining risk associated with operation of fully autonomous vehicles are provided. According to certain aspects, autonomous operation features associated with a vehicle may be determined, including types and version of sensors, control systems, and software. This information may be used to determine a risk profile reflecting risk levels for a plurality of features, which may be based upon test data regarding the features or actual loss data. Expected use levels may further be determined and used with the risk profile to determine a total risk level associated with operation of the vehicle by the autonomous operation features. The expected use levels may indicate expected vehicle use, as well as traffic, weather, or other conditions in which the vehicle is likely to operate. The total risk level may be used to determine or adjust aspects of an insurance policy associated with the vehicle."
404,16851842,2020.04.17,,,11288963,2022.03.29,11288963,2022.03.29,Autonomous vehicles featuring vehicle intention system,"G08G1/16,G08G1/0967,G01C21/26,G06Q50/30,G05D1/00,B60W30/09,B60W40/04,B60W50/14,B60W30/095,B60W50/00,G06N20/00","UATC, LLC","The present disclosure provides autonomous vehicles that include a vehicle intention system that provides intention signals indicative of an intention of the autonomous vehicle. In particular, in one example, the vehicle intention system can obtain one or more operational messages from various systems or components of an autonomous vehicle that operate to control the autonomous vehicle. The operational messages can include operational data regarding the control or operation of the autonomous vehicle. The vehicle intention system can determine an intention of the autonomous vehicle based at least in part on the one or more operational messages. The vehicle intention system can output one or more intention signals that indicate the determined intention of the autonomous vehicle. For example, the vehicle intention system can publish intention messages that indicate the determined intention to one or more components or systems that consume the intention messages."
405,16685319,2019.11.15,,,11288751,2022.03.29,11288751,2022.03.29,Autonomous vehicle operation feature monitoring and evaluation of effectiveness,"G06Q50/22,G06Q40/08",State Farm Mutual Automobile Insurance Company,"Methods and systems for monitoring use and determining risks associated with operation of a vehicle having one or more autonomous operation features are provided. According to certain aspects, operating data may be recorded during operation of the vehicle. This may include information regarding the vehicle, the vehicle environment, use of the autonomous operation features, and/or control decisions made by the features. The control decisions may include actions the feature would have taken to control the vehicle, but which were not taken because a vehicle operator was controlling the relevant aspect of vehicle operation at the time. The operating data may be recorded in a log, which may then be used to determine risk levels associated with vehicle operation based upon risk levels associated with the autonomous operation features. The risk levels may further be used to adjust an insurance policy associated with the vehicle."
406,17480711,2021.09.21,20220089187,2022.03.24,20220089187,2022.03.24,,,MULTI-LAYER AUTONOMOUS VEHICLE CONTROL ARCHITECTURE,"B60W60/00,B60W50/029","Coast Autonomous, Inc.","A system for controlling an autonomous vehicle is provided. The system may include a first sensor system including a first sensor and a first data box. The first sensor system may be configured to determine a first vehicle control decision. The system may further include a second sensor system including a second sensor and a second data box. The second sensor system may be configured to determine a second vehicle control decision. The system further includes a controller configured to receive the first vehicle control decision and the second vehicle control decision from the first sensor system and the second sensor system; determine a priority ranking for the first vehicle control decision and the second vehicle control decision; select, based on the priority ranking, a vehicle control decision from the first vehicle control decision and the second vehicle control decision; and implement, responsive to the determining, the selected vehicle control decision."
407,17021981,2020.09.15,20220081004,2022.03.17,20220081004,2022.03.17,,,DETECTING AN UNKNOWN OBJECT BY A LEAD AUTONOMOUS VEHICLE (AV) AND UPDATING ROUTING PLANS FOR FOLLOWING AVs,"B60W60/00,G08G1/00,G01C21/34,G01C21/00,G01C21/32,B60W30/095,B60W30/09,B60W30/16,B60W30/14","TuSimple, Inc.","A lead autonomous vehicle (AV) includes a sensor configured to observe a field of view in front of the lead AV. Following AVs are on the same road behind the lead AV. A processor of the lead AV is configured to detect an unknown object within the field of view by comparing sensor data received from the sensor and a map data. The processor determines a lane occupied by the unknown object. The processor sends a first message to the following AVs comprising location coordinates of the unknown object and instructions to divert the lane. The processor instructs the lead AV to navigate around the unknown object. While navigating around the unknown object, the processor sends a plurality of second messages to an operation server, comprising sensor data related to the unknown object. The operation server updates the map data, indicating the unknown object at the location coordinates."
408,16538275,2019.08.12,,,11287818,2022.03.29,11287818,2022.03.29,Depart constraints implementation in autonomous vehicle routing,"G05D1/00,G05D1/02,G01C21/34","UATC, LLC","A method of controlling navigation of autonomous vehicles includes accessing map data descriptive of the identity and location of different travel ways within a surrounding environment of an autonomous vehicle and accessing constraint data descriptive of one or more geographic areas or geographic identifiers, within the map data, for which associated navigational constraints are defined. The constraint data includes a depart constraint that specifies an area that an autonomous vehicle may not enter but may exit if inside the area when the depart constraint is imposed, thereby preventing the autonomous vehicle from being trapped in a forbidden area even though the autonomous vehicle may safely complete its route. A travel route is determined for the autonomous vehicle based at least in part on the map data evaluated relative to the constraint data including the depart constraint, and motion of the autonomous vehicle is controlled based on the determined travel route."
409,17021934,2020.09.15,20220081003,2022.03.17,20220081003,2022.03.17,,,DETECTING A CONSTRUCTION ZONE BY A LEAD AUTONOMOUS VEHICLE (AV) AND UPDATING ROUTING PLANS FOR FOLLOWING AVs,"B60W60/00,G08G1/00,G01C21/34,G01C21/00,B60W30/14,B60W30/16,B60W30/095","TuSimple, Inc.","A lead autonomous vehicle (AV) includes a sensor configured to observe a field of view in front of the lead AV. Following AVs are on the same road behind the lead AV. A processor of the lead AV is configured to detect a construction zone. The processor sends a first message to an operation server, indicating that the construction zone is detected. The processor updates driving instructions of the lead AV to navigate around the construction zone. While navigating around the construction zone, the processor sends sensor data associated with the construction zone to the operation server. The operation server determines an extent of the construction zone. If the operation server determines that the construction zone is extensive, it sends re-routing instructions to the AVs. If the operation server determines that the construction zone is not extensive, it sends instructions to navigate around the construction zone to the AVs."
410,17021963,2020.09.15,20220080996,2022.03.17,20220080996,2022.03.17,,,DETECTING A ROAD STRUCTURE CHANGE BY A LEAD AUTONOMOUS VEHICLE (AV) AND UPDATING ROUTING PLANS FOR THE LEAD AV AND FOLLOWING AVs,"B60W60/00,G08G1/00,G01C21/00,G01C21/34,G01C21/32,B60W30/14,B60W30/16","TuSimple, Inc.","A lead autonomous vehicle (AV) includes a sensor configured to observe a field of view in front of the lead AV. Following AVs are on the same road behind the lead AV. A processor of the lead AV is configured to detect a road structural change on the particular road. The processor updates driving instructions of the lead AV to navigate through the structural change using driving instructions related to the structural change. The processor sends a first message to the operation server indicating that the structural change is detected. The operation server updates the first portion of the map data, reflecting the structural change. The operation server sends the updated map data to the one or more following AVs."
411,17477906,2021.09.17,20220089151,2022.03.24,20220089151,2022.03.24,,,PATH PLANNING IN AUTONOMOUS DRIVING ENVIRONMENTS,"B60W30/09,G08G1/16,B60W60/00",ZENUITY AB,"A path planning method and system for a vehicle. The method includes obtaining risk map of a surrounding environment of vehicle. Risk map is formed based on an actuation capability of the vehicle and location of free-space areas in the surrounding environment, actuation capability including uncertainty estimation for actuation capability and the location of free-space areas comprising an uncertainty estimation for the estimated location of free-space areas. Risk map includes risk parameter for each of a plurality of area segments included in the surrounding environment of the vehicle. Obtaining at least one candidate path for vehicle, determining total risk value for each candidate path based on risk parameters of a set of area segments intersected by the at least one path, selecting a candidate path, of at least one candidate path, fulfilling a risk value criterion, and generating, at an output, a first signal indicative of selected candidate path."
412,17021991,2020.09.15,20220081005,2022.03.17,20220081005,2022.03.17,,,DETECTING A ROAD CLOSURE BY A LEAD AUTONOMOUS VEHICLE (AV) AND UPDATING ROUTING PLANS FOR FOLLOWING AVs,"B60W60/00,G08G1/00,G01C21/34,G01C21/00,B60W30/095,G01C21/30,B60W50/14,B60W30/14,B60W30/16,B60W40/06","TuSimple, Inc.","A lead autonomous vehicle (AV) includes a sensor configured to observe a field of view in front of the lead AV. Following AVs are on the same road behind the lead AV. A processor of the lead AV is configured to detect a road closure. The processor overrides driving instructions of the lead AV, such that the lead AV is stopped at first location coordinates. The processor sends a first message to an operation server, indicating that the road closure is detected. The operation server update the first portion of the map data, reflecting the road closure. The operation server determines whether re-routing is possible for each AV. If re-routing is possible is possible for that AV, the operation server sends re-routing instructions to the AV. If re-routing is not possible is possible for that AV, the operation server sends pulling over instructions to the AV."
413,17024267,2020.09.17,,,11264082,2022.03.01,11264082,2022.03.01,"Memory device, memory system and autonomous driving apparatus","G11C11/40,G11C11/4091,G11C11/4093,G11C5/02,G11C5/06,G11C11/408","Samsung Electronics Co., Ltd.","A memory device comprises a first memory area including a first memory cell array having a plurality of first memory cells each for storing N-bit data, where N is a natural number, and a first peripheral circuit for controlling the first memory cells according to an N-bit data access scheme and disposed below the first memory cell array, a second memory area including a second memory cell array having a plurality of second memory cells each for storing M-bit data, where M is a natural number greater than N, and a second peripheral circuit for controlling the second memory cells according to an M-bit data access scheme and disposed below the second memory cell array, wherein the first memory area and the second memory area are included in a single semiconductor chip and share an input and output interface, and a controller configured to generate calculation data by applying a weight stored in the first memory area to sensing data in response to receiving the sensing data obtained by an external sensor, and store the calculation data in one of the first memory area or the second memory area according to the weight, wherein the plurality of first memory cells and the plurality of second memory cells are included in a first chip having a first metal pad, the first peripheral circuit and the second peripheral circuit are included in a second chip having a second metal pad, and the first chip and the second chip are vertically connected to each other by the first metal pad and the second metal pad."
414,17017877,2020.09.11,20220080991,2022.03.17,20220080991,2022.03.17,,,SYSTEM AND METHOD FOR REDUCING UNCERTAINTY IN ESTIMATING AUTONOMOUS VEHICLE DYNAMICS,"B60W50/04,B60W50/02,B60W50/00","Beijing Wodong Tianjun Information Technology Co., Ltd.,JD.com American Technologies Corporation","A system and a method for controlling an autonomous driving vehicle. The system includes vehicle sensors and a controller. The controller has a processor and a storage device storing computer executable code. The computer executable code, when executed at the processor, is configured to: receive vehicle parameters from the vehicle sensors; obtain a vehicle dynamic model by adding a dynamics error bound to a state space model, wherein the dynamics error bound is estimated using linear least square; minimize a linear quadratic regulator cost function based on the vehicle dynamic model; and control the vehicle using control input obtained from the minimized cost function."
415,17311462,2019.12.19,20220024486,2022.01.27,20220024486,2022.01.27,,,COLLABORATIVE AUTONOMOUS GROUND VEHICLE,"B60W60/00,B60K37/06","AUGEAN ROBOTICS, INC.","A collaborative autonomous ground vehicle or robot for traversing a ground surface is disclosed. The robot is a wheeled vehicle includes two camera groups and other sensors to sense the environment in which the robot will operate. The robot includes a control system configured to operate in a teach mode to learn a route by either following a person or preceding a person and to store the learned route as a taught route. The control system is configured for identifying persons and objects, such as obstacles, within the fields of view of the camera groups. When the robot is in its repeat mode it will take the taught route over the ground surface and take appropriate action if an obstacle is identified in the field of view."
416,17501401,2021.10.14,20220035733,2022.02.03,20220035733,2022.02.03,,,"METHOD AND APPARATUS FOR CHECKING AUTOMATIC DRIVING ALGORITHM, RELATED DEVICE AND STORAGE MEDIUM","G06F11/36,B60W60/00,G06K9/62","APOLLO INTELLIGENT CONNECTIVITY (BEIJING) TECHNOLOGY CO., LTD.,APOLLO INTELLIGENT CONNECTIVITY (BEIJING) TECHNOLOGY CO., LTD.","The disclosure provides a method and an apparatus for checking an automatic driving algorithm, a related device and a storage medium. The travelling data during a travelling process of the vehicle is obtained. The travelling data includes the environmental parameter and/or the state parameter of the vehicle. The travelling data is processed using an automatic driving algorithm to be checked to generate the prediction result. The reference result corresponding to the travelling data is obtained. The reliability of the automatic driving algorithm to be checked is determined based on the difference between the prediction result and the reference result."
417,17315554,2021.05.10,20220036100,2022.02.03,20220036100,2022.02.03,,,"METHOD FOR OBJECT RECOGNITION USING QUEUE-BASED MODEL SELECTION AND OPTICAL FLOW IN AUTONOMOUS DRIVING ENVIRONMENT, RECORDING MEDIUM AND DEVICE FOR PERFORMING THE METHOD","G06K9/00,B60W60/00,G06N3/08","Korea University Research and Business Foundation,Korea University Research and Business Foundation","An object recognition method using queue-based model selection and optical flow in an autonomous driving environment includes preprocessing data through a dense flow in a matrix form by calculating an optical flow of images captured consecutively in time by a sensor for an autonomous vehicle, generating a confidence mask by generating a vectorized confidence threshold representing a probability that there is a moving object for each cell of the preprocessed matrix, determining whether there is a moving object on the images by mapping the images captured consecutively in time to the confidence mask, and selecting an object recognition model using a tradeoff constant between object recognition accuracy and queue stability in each time unit. Accordingly, it is possible to improve the performance of object recognition in an autonomous driving environment by applying the optical flow to the confidence threshold of the object recognition system."
418,17491289,2021.09.30,20220017013,2022.01.20,20220017013,2022.01.20,,,Virtual Mirror with Automatic Zoom Based on Vehicle Sensors,"B60R1/00,G06T7/70,G06T7/50,G06T7/20,H04N5/225,H04N5/247,H04N5/232,B60R11/04,G06K9/00","Micron Technology, Inc.","In one approach, a method includes: displaying, to a user of a first vehicle, image data obtained using a first field of view of a camera of the first vehicle, where the camera collects the image data for objects located outside of the first vehicle; detecting, by at least one processing device of the first vehicle, a second vehicle; determining, by the one processing device, whether the second vehicle is within a predetermined region relative to the first vehicle; and in response to determining that the second vehicle is within the predetermined region, displaying image data obtained using a second field of view of the camera."
419,16925501,2020.07.10,20220009520,2022.01.13,20220009520,2022.01.13,,,"AUTONOMOUS VEHICLE, SYSTEM, AND METHOD OF OPERATING AN AUTONOMOUS VEHICLE","B60W60/00,B60W30/18,B60W30/095","Toyota Motor Engineering and Manufacturing North America, Inc.,Toyota Motor Engineering and Manufacturing North America, Inc.","Systems, methods, and computer program products to enhance the situational competency of a vehicle, when operating at least partially in an autonomous mode, and/or the safe operation of a vehicle, when operating at least partially in an autonomous mode. Such systems, methods, and computer program products are to facilitate operation of a vehicle, when operating at least partially in an autonomous mode, in a multi-lane roadway environment to coordinate a change of lane of the autonomous vehicle from a first lane in which the autonomous vehicle is currently operating and a target lane change area of a second lane. Such coordination is to dynamically take into consideration several operational safety factors within the driving environment, including the presence of one or more vehicles in a third lane adjacent to the target lane area of the second lane and the geometric roadway design."
420,17359007,2021.06.25,20210403050,2021.12.30,20210403050,2021.12.30,,,AUTONOMOUS DRIVING CRASH PREVENTION,"B60W60/00,G08G1/16,G06K9/00,G06T7/73,G06T7/62,G06T3/40","TUSIMPLE, INC.","Autonomous vehicles must accommodate various road configurations such as straight roads, curved roads, controlled intersections, uncontrolled intersections, and many others. Autonomous driving systems must make decisions about the speed and distance of traffic and about obstacles including obstacles that obstruct the view of the autonomous vehicle's sensors. For example, at intersections, the autonomous driving system must identify vehicles in the path of the autonomous vehicle or potentially in the path based on a planned path, estimate the distance to those vehicles, and estimate the speeds of those vehicles. Then, based on those and the road configuration and environmental conditions, the autonomous driving system must decide whether it is safe to proceed along the planned path or not, and when it is safe to proceed."
421,17279435,2019.09.13,20210409916,2021.12.30,20210409916,2021.12.30,,,"BACKEND APPARATUS FOR TRIGGERING AN AUTOMATIC EMERGENCY CALL FOR AT LEAST ONE VEHICLE, VEHICLE CONTROL UNIT FOR VEHICLE-TO-ENVIRONMENT COMMUNICATION, SYSTEM FOR TRIGGERING AN AUTOMATIC EMERGENCY CALL, METHOD FOR TRIGGERING AN AUTOMATIC EMERGENCY CALL, AND COMPUTER PROGRAM PRODUCT FOR A BACKEND APPARATUS","H04W4/40,G08G1/16,G08B25/01","ZF Friedrichshafen AG,ZF Friedrichshafen AG","Backend apparatus for triggering an automatic emergency call for a vehicle is arranged outside the vehicle, comprising a first interface for vehicle-to-environment communication to recurrently obtain a current collision probability from a collision detection device for a collision with an object, a second interface for vehicle-to-environment communication to recurrently obtain a data record updated by the vehicle comprising a time, a location and an identification number of the vehicle. The backend apparatus is designed, if the impact probability is not obtained, and on the basis of the impact probability obtained last, to trigger the automatic emergency call comprising the data record obtained last. A third interface makes the automatic emergency call. The invention also relates to a vehicle control unit for a vehicle-to-environment communication, a system and method for triggering an automatic emergency call, and a computer program product for a backend apparatus."
422,16833644,2020.03.29,20210406968,2021.12.30,20210406968,2021.12.30,,,METHOD AND SYSTEM OF AUTOMATIC BILLING OF TRANSPORTATION SERVICES,"G06Q30/04,G06Q20/10,H04W4/02,H04W4/029",BABU VINOD,"In one aspect, a process for automatic billing of transportation services includes the step of generating a first travel vector for a traveler. The process includes the step of generating a second travel vector for a travel provider. The process includes the step of determining that the traveler's location and movement is synchronized with a travel-service provider within a specified distance threshold. The process includes the step of comparing first travel vector with second travel vector. The process includes the step of determining that the first vector and the second vector are within the specified distance threshold. The process includes the step of measuring the time period that the first vector and the second vector are within the specified distance threshold. The process includes the step of billing the traveler for the time period that the first vector and the second vector are within the specified distance threshold."
423,16917245,2020.06.30,20210403035,2021.12.30,20210403035,2021.12.30,,,SYSTEMS AND METHODS FOR AUTONOMOUS VEHICLE PERFORMANCE EVALUATION,"B60W60/00,G01S19/42,B60W30/095","Woven Planet North America, Inc.,Woven Planet North America, Inc.","Systems, methods, and non-transitory computer-readable media can determine mission data associated with a scenario encountered during operation of a vehicle. A first evaluation of the scenario can be determined by evaluating the mission data using a simulation behavior model based on simulated driving data. A second evaluation of the scenario can be determined by evaluating the mission data using an observed behavior model based on observed driving data. Vehicle performance of an autonomy system of the vehicle can be evaluated based on the first evaluation and the second evaluation."
424,16539312,2019.08.13,,,11208115,2021.12.28,11208115,2021.12.28,"Method of assisting autonomous vehicle, and apparatus therefor","B60W50/08,G05D1/00,B60W50/00","SAMSUNG ELECTRONICS CO., LTD.","A method of assisting an autonomous vehicle includes obtaining first surrounding area information of the vehicle when the vehicle is located at a first distance from a monitored area disposed ahead of the vehicle, providing a first control command for controlling the vehicle to operate in a first operating mode, by using the first surrounding area information, obtaining second surrounding area information of the vehicle when the vehicle has driven toward the monitored area and is located at a second distance less than the first distance from the monitored area, and providing a second control command for controlling the vehicle to operate in a second operating mode, by using the second surrounding area information."
425,16909962,2020.06.23,20210397867,2021.12.23,20210397867,2021.12.23,,,PARTITIONING IMAGES OBTAINED FROM AN AUTONOMOUS VEHICLE CAMERA,"G06K9/32,G06K9/00,G06T7/11,G06T7/70,G01C21/36,B60W60/00","TUSIMPLE, INC.","Image processing techniques are described to select and crop a region of interest from an image obtained from a camera located on or in a vehicle, such as an autonomous semi-trailer truck. The region of interest can be identified by selecting one or more reference points and determining one or more positions of the one or more reference points on the image obtained from the camera. As an example, a location of two reference points may be 500 meters and 1000 meters in front of a location of autonomous vehicle, where the front of the autonomous vehicle is an area towards which the autonomous vehicle is being driven."
426,17462472,2021.08.31,20210397858,2021.12.23,20210397858,2021.12.23,,,DETECTION AND MITIGATION OF INAPPROPRIATE BEHAVIORS OF AUTONOMOUS VEHICLE PASSENGERS,"G06K9/00,G10L15/18,B60W60/00","Cornelius Buerkle,Fabian Oboril,Frederik Pasch,Yin Wei Liew,Say Chuan Tan,Chien Chern Yew,Ralf Graefe,Florian Geissler,Ignacio J. Alvarez","Disclosed herein are systems and methods for detecting and mitigating inappropriate behavior. The systems and methods may include receiving data. Using the data a harassment score and/or classification for a behavior may be determined. Using the harassment score and/or classification, a determination may be made as to when the harassment score and/or classification for the behavior exceeds a threshold. When the threshold is exceeded, a protection system and/or action engine may be activated to mitigate the inappropriate behavior."
427,16909987,2020.06.23,20210398310,2021.12.23,20210398310,2021.12.23,,,DEPTH ESTIMATION IN IMAGES OBTAINED FROM AN AUTONOMOUS VEHICLE CAMERA,"G06T7/70,G06K9/00,G06T7/11,B60W60/00,G01C21/30","TUSIMPLE, INC.","Image processing techniques are described to receive bounding box information that describes a bounding box located around a detected obj ect in an image, determine one or more positions of one or more reference points on the bounding box, determine, for each reference point, 3D world coordinates of a point of intersection of the reference point and the road surface, and assign the 3D world coordinates of the one or more reference points to a location of the detected object."
428,16897263,2020.06.09,20210382814,2021.12.09,20210382814,2021.12.09,,,"COMPUTING HARDWARE AND SOFTWARE DESIGN TESTING AUDITABILITY, INCLUDING FOR CRITICAL CONTROL SYSTEMS, FUNCTIONAL SAFETY, AND AUTONOMOUS VEHICLE COMPONENT CERTIFICATION","G06F11/36,G06F21/57,G06F8/41,G06F9/50,H04L9/06","Methodics, Inc.,Methodics, Inc.","Disclosed is a method, a device, a system and/or a manufacture of computing hardware and software design testing auditability, including for critical control systems, functional safety, and autonomous vehicle component certification. In one embodiment, a system includes a test recording routine that defines a database relation associating a design version within a design dependency graph and a test version. The system includes a design audit interface that generates a first validation request to validate an isolation testing. An isolation validation engine determines that the design version has completed the isolation testing where each design script of the design fileset was executed in a discrete environment. In addition, a reproduction validation engine may also retrieve the design fileset and the runtime environment data, reassemble a workspace data, execute the test script, and compare the result data to a previous result data to validate reproducibility of the testing."
429,16898528,2020.06.11,20210387628,2021.12.16,20210387628,2021.12.16,,,EXTRACTING AGENT INTENT FROM LOG DATA FOR RUNNING LOG-BASED SIMULATIONS FOR EVALUATING AUTONOMOUS VEHICLE SOFTWARE,"B60W40/09,G06F11/34,G06F30/20,B60W60/00",WAYMO LLC,"The disclosure relates to running simulations in order to test software used to control a vehicle in an autonomous driving mode. For instance, logged data may be identified for a simulation. The logged data may have been collected by a first vehicle and may identifying an agent that is a road user. The logged data may be analyzed to identify one or more signals of intent of the agent including a logged path of the agent. One or more characteristics may be identified based on the one or more signals. The simulation may be run using the logged data by replacing the agent with an interactive agent having the one or more characteristics. The interactive agent may be capable of responding to actions performed by a simulated vehicle in the simulation using software for controlling a vehicle in an autonomous driving mode."
430,16399901,2019.04.30,,,11198431,2021.12.14,11198431,2021.12.14,Operational risk assessment for autonomous vehicle control,"B60W30/09,G06K9/00,G05D1/00,B60W30/00,B60W30/095","Retrospect Technology, LLC","Changes in the controlling of an autonomous vehicle are caused based on an operational risk determined for the autonomous vehicle. An operational risk monitor module of the autonomous vehicle uses information about objects detected within an environment in which the autonomous vehicle is located and predicted behaviors of those objects to assess the operational risk of the autonomous vehicle along a planned path. The operational risk is used to determine whether to cause a change in the controlling of the autonomous vehicle, for example, based on a comparison between the operational risk and a previously estimated operational risk or based on a determination that the operational risk exceeds a threshold. The operational risk monitor module transmits a signal to one or more control system modules of the autonomous vehicle to indicate to change the controlling of the autonomous vehicle based on the operational risk."
431,16997981,2020.08.20,20210370950,2021.12.02,20210370950,2021.12.02,,,METHOD AND SYSTEM FOR PROVIDING PERSONALIZED INTERACTIVE ASSISTANCE IN AN AUTONOMOUS VEHICLE,"B60W40/08,G06N3/04,B60W50/12,G06F9/451",Wipro Limited,"Disclosed herein is method and interactive assistance system for providing personalized assistance to a driver or person in an autonomous vehicle. Parameters related to the user and the vehicle are monitored and compared with historical data to determine a deviation in the parameters. An abnormal condition is detected when the deviation is more than an optimal threshold. Further, a personalized interaction is initiated with the user through a selected one of the interactive assistance engine and one or more assistive activities are performed for handling the abnormal condition. In an embodiment, the method of present disclosure enhances both safety and user experience of the user of the autonomous vehicle."
432,16284487,2019.02.25,,,11192430,2021.12.07,11192430,2021.12.07,Controlling sunshades in an autonomous vehicle,"B60R22/00,E05F15/00,G05D1/00,G05D3/00,G06F7/00,G06F17/00,B60J1/20,G05D1/02,G01C22/00","TOYOTA RESEARCH INSTITUTE, INC.",A method for controlling a sunshade of an autonomous vehicle is presented. The method includes determining that current conditions satisfy an activation condition. The method also includes predicting whether a driver will enable a manual mode during the current conditions. The method further includes activating a first sunshade in response to the satisfied activation condition regardless of whether the driver will enable the manual mode. The method still further includes activating a second sunshade in response to the satisfied activation condition when the driver will not enable the manual mode.
433,17402312,2021.08.13,20210374997,2021.12.02,20210374997,2021.12.02,,,METHODS AND SYSTEMS FOR OBTAINING IMAGE DATA OF A VEHICLE FOR AUTOMATIC DAMAGE ASSESSMENT,"G06T7/73,G06Q30/02,G06Q10/10,G06Q40/08","STATE FARM MUTUAL AUTOMOBILE INSURANCE COMPANY,STATE FARM MUTUAL AUTOMOBILE INSURANCE COMPANY","A system and computer-implemented method for facilitating a user of a mobile device obtaining image data of damage to a vehicle for damage assessment includes capturing image data of a vehicle with the mobile device. The mobile device may include an orientation model for capturing the image data. The captured image data is analyzed, and a determination is made of the orientations of the images of the captured image data. In addition, a determination is made as to whether the captured image data can be used for the damage assessment. The captured image data may then be transmitted to a damage estimator computing device for estimating an amount of damage to the vehicle."
434,17183198,2021.02.23,20210365024,2021.11.25,20210365024,2021.11.25,,,METHOD AND DEVICE FOR POSITIONING UNMANNED VEHICLE,"G05D1/00,G01C21/36,G05D1/02,B60W60/00","BEIJING BAIDU NETCOM SCIENCE TECHNOLOGY CO., LTD.","The embodiments of the present application provide a method and device for positioning unmanned vehicle. The method includes: sending a positioning request to a user terminal, when an abnormal positioning for an unmanned vehicle is detected; receiving auxiliary positioning information returned by the user terminal according to the positioning request, the positioning request including auxiliary positioning information, determining whether a position corresponding to the auxiliary positioning information exceeds a setting range corresponding to an actual position of the unmanned vehicle or not; acquiring environmental information of the unmanned vehicle, when the position corresponding to the auxiliary positioning information does not exceed the setting range corresponding to the actual position of the unmanned vehicle; and adjusting the position corresponding to the auxiliary positioning information according to the environmental information and a pre-stored electronic map."
435,16500308,2019.07.04,20210362739,2021.11.25,20210362739,2021.11.25,,,"APPARATUS FOR GENERATING POSITION DATA, AUTONOMOUS VEHICLE AND METHOD FOR GENERATING POSITION DATA","B60W60/00,G06T7/70,B60W40/12,B60W40/08,B60W50/10",LG Electronics Inc.,"Disclosed is an apparatus for generating position data including a processor which acquires position information of an antenna installed in a vehicle, generates position data of the vehicle based on the position information of the antenna, acquires information about change in an external appearance of the vehicle, and corrects the position data of the vehicle based on the information about the change in the external appearance of the vehicle."
436,17393365,2021.08.03,20210362759,2021.11.25,20210362759,2021.11.25,,,AUTONOMOUS RAIL OR OFF RAIL VEHICLE MOVEMENT AND SYSTEM AMONG A GROUP OF VEHICLES,"B61L27/04,B61L27/00,G01C21/20","Glydways, Inc.","In an example, the autonomous vehicle (“AV”) can be configured among the other vehicles and railway to communicate with a rider on a peer to peer basis to pick up the rider on demand from a location on a track, like a railway, tram or other track, rather than the rider being held hostage to -a fixed, railway schedule. The rider can have an application on his/her cell phone, which tracks each of the AVs. and contact them using the application on the cell phone. In an example, the AV is configured for both on-track and off track operation with different operating parameters for on-track and off track, including speed, degree of autonomy, sensors used etc."
437,17368719,2021.07.06,20210333117,2021.10.28,20210333117,2021.10.28,,,AUTONOMOUS VEHICLE ROUTE PLANNING,"G01C21/34,G05D1/00,G06Q10/02,G06Q50/30","TOYOTA RESEARCH INSTITUTE, INC.,TOYOTA RESEARCH INSTITUTE, INC.","A method for route planning for an autonomous vehicle includes receiving a request to autonomously navigate to a destination. The method also includes identifying a stall factor on a route to the destination prior to departing to the destination, the stall factor delaying a time for arriving at the destination. The method further includes determining whether an occupant of the autonomous vehicle is capable of manually operating the autonomous vehicle in a manual operating mode or a semi-manual operating mode. The method still further includes identifying an alternate route to the destination based on identifying the stall factor and the occupant being incapable of manually operating the autonomous vehicle. The method also includes controlling the autonomous vehicle to drive on the alternate route instead of the route."
438,17364761,2021.06.30,20210325883,2021.10.21,20210325883,2021.10.21,,,IDENTIFYING A ROUTE FOR AN AUTONOMOUS VEHICLE BETWEEN AN ORIGIN AND DESTINATION LOCATION,"G05D1/00,G05D1/02",GM Cruise Holdings LLC,"Described herein are technologies relating to computing a likelihood of an operation-influencing event with respect to an autonomous vehicle at a geographic location. The likelihood of the operation-influencing event is computed based upon a prediction of a value that indicates whether, through a causal process, the operation-influencing event is expected to occur. The causal process is identified by means of a model, which relates spatiotemporal factors and the operation-influencing events."
439,16847634,2020.04.13,20210318685,2021.10.14,20210318685,2021.10.14,,,"AUTONOMOUS ELECTRIC VEHICLE CHARGING OPTIMIZATION BASED ON LOCATION, COST AND SAFETY USING EDGE COMPUTING","G05D1/02,G06F16/29,G06Q10/04,G06Q30/00,G06Q10/06,B60L53/66,G01C21/34,B60L58/12",International Business Machines Corporation,"A method is provided to find an optimal charging station for an electric vehicle travelling along an intended route. Optimality can be based on various factors including relative cost savings, the distance required to detour to a charging station, a station charging level indicating how fast charging takes place, and a safety rating for a charging station. The detour charging station might be a mobile facility. The charging station information is downloaded to the vehicle's navigation system on a regular basis, e.g., daily. Relative cost savings is considered as a percentage of the cost of a reference charging station that is on the route, i.e., that would incur no detour deviation. The detour distance is considered as a percentage of the overall trip distance. An operator of the electric vehicle can set threshold constraints for these factors, and the factors can have different priorities for determining optimality."
440,17195078,2021.03.08,20210312813,2021.10.07,20210312813,2021.10.07,,,OPERATION MANAGEMENT APPARATUS AND OPERATION MANAGEMENT METHOD OF AUTONOMOUS TRAVEL VEHICLE,"G08G1/00,G06Q10/06,G05D1/02,G08G1/127","TOYOTA JIDOSHA KABUSHIKI KAISHA,DENSO CORPORATION,TOYOTA JIDOSHA KABUSHIKI KAISHA,DENSO CORPORATION","An introduction necessity judgment unit judges necessity of introduction of an additional vehicle to a circuit based on a boarding demand on the circuit, and outputs an introduction request command when judging that the introduction is necessary. Upon reception of the introduction request command, an introduction timing determiner outputs an introduction command to the additional vehicle when a maximum value of actual operation intervals of operating vehicles is greater than or equal to an interval threshold determined according to a target velocity, and outputs a hold command to the additional vehicle for putting introduction to the circuit on-hold when the maximum value is less than the interval threshold Dr_th."
441,17193132,2021.03.05,20210312367,2021.10.07,20210312367,2021.10.07,,,OPERATION MANAGEMENT APPARATUS AND OPERATION MANAGEMENT METHOD OF AUTONOMOUS TRAVEL VEHICLE,G06Q10/06,"TOYOTA JIDOSHA KABUSHIKI KAISHA,DENSO CORPORATION,TOYOTA JIDOSHA KABUSHIKI KAISHA,DENSO CORPORATION","A schedule changer executes, as a schedule change process for changing a normal operation schedule, a cut-in change process in which a plurality of operating vehicles are divided into a sequence of an advanced vehicle line group for which a departure target time is advanced from a departure target time determined based on the normal operation schedule, and a sequence of a delayed vehicle line group for which the departure target time is delayed from the departure target time determined based on the normal operation schedule, and an inter-vehicle space between the advanced vehicle line group and the delayed vehicle line group is enlarged for an additional vehicle."
442,17193760,2021.03.05,20210311495,2021.10.07,20210311495,2021.10.07,,,OPERATION MANAGEMENT APPARATUS AND OPERATION MANAGEMENT METHOD OF AUTONOMOUS TRAVEL VEHICLE,"G05D1/02,G07C5/02,G06Q10/06","TOYOTA JIDOSHA KABUSHIKI KAISHA,DENSO CORPORATION,TOYOTA JIDOSHA KABUSHIKI KAISHA,DENSO CORPORATION","When a non-operable notification is output from any of a plurality of operating vehicles, an operation schedule creator creates a substitute vehicle introduction operation schedule based on planned stopping times and a target velocity determined by a normal operation schedule, as an operation schedule to be provided, to each of operating vehicles other than a non-operable vehicle which has output the non-operable notification, when the operating vehicle passes an operation schedule updating location for a first time after the non-operable notification is output."
443,17196446,2021.03.09,20210312812,2021.10.07,20210312812,2021.10.07,,,OPERATION MANAGEMENT APPARATUS AND OPERATION MANAGEMENT METHOD OF AUTONOMOUS TRAVEL VEHICLE,"G08G1/00,G05D1/02","TOYOTA JIDOSHA KABUSHIKI KAISHA,DENSO CORPORATION,TOYOTA JIDOSHA KABUSHIKI KAISHA,DENSO CORPORATION","An operation schedule changer can execute, as a schedule change process for changing a normal operation schedule, an advancing change process, a delay change process, and a cut-in change process. The schedule changer executes one of the advancing change process, the delay change process, or the cut-in change process based on a boarding demand."
444,17194783,2021.03.08,20210309260,2021.10.07,20210309260,2021.10.07,,,AUTOMATIC RUNNING VEHICLE AND OPERATION MANAGEMENT DEVICE FOR AUTOMATIC RUNNING VEHICLE,"B60W60/00,G08G1/00,G06K9/00","TOYOTA JIDOSHA KABUSHIKI KAISHA,DENSO CORPORATION,TOYOTA JIDOSHA KABUSHIKI KAISHA,DENSO CORPORATION",An automatic running vehicle executes regular operation control based on an operation schedule provided from an operation management device. The automatic running vehicle includes an automatic running control unit. The automatic running control unit executes retreat control to move to a retreat position on the predetermined route and stop there upon receipt of a retreat instruction from the operation management device or an immediately following overtaking vehicle.
445,17194560,2021.03.08,20210312356,2021.10.07,20210312356,2021.10.07,,,AUTONOMOUS TRAVEL VEHICLE AND TRAFFIC SYSTEM,"G06Q10/06,G05D1/02,G05D1/00,B60W60/00","TOYOTA JIDOSHA KABUSHIKI KAISHA,DENSO CORPORATION,TOYOTA JIDOSHA KABUSHIKI KAISHA,DENSO CORPORATION","After an evacuating drive for moving a vehicle to an evacuation destination station is performed subsequent to receipt of an operation interruption command, upon receiving an operation restart command while at the evacuation destination station, an operation schedule modifier executes a schedule modification so that, based on an actual operation delay duration with respect to an operation schedule, a travel duration for traveling from the evacuation destination station to an operation schedule updating site is shortened as compared to a corresponding travel duration according to the operation schedule."
446,16411771,2019.05.14,,,11144057,2021.10.12,11144057,2021.10.12,Autonomous versatile vehicle system,"G05D1/00,G05D1/02,B60P3/20,B60N3/16,G06N3/08,G06N7/00,B60N3/10","Ali Ebrahimi Afrouzi,Lukas Fath,Shahin Fathi Djalali,Chen Zhang","Provided is an autonomous versatile robotic chassis, including: a chassis; a set of wheels coupled to the chassis; one or more motors to drive the set of wheels; one or more mounting elements; at least one food equipment coupled to the robotic chassis using the one or more mounting elements; a processor; one or more sensors; a camera; and a tangible, non-transitory, machine readable medium storing instructions that when executed by the processor effectuates operations including: generating, with the processor, a map of an environment; localizing, with the processor, the robotic chassis; receiving, with the processor, a request for delivery of a food item to a first location; generating, with the processor, a movement path to the first location from a current location; and instructing, with the processor, the robotic chassis to transport the food item to the first location by navigating along the movement path."
447,17194570,2021.03.08,20210309249,2021.10.07,20210309249,2021.10.07,,,OPERATION MANAGEMENT DEVICE FOR AUTOMATIC RUNNING VEHICLE AND AUTOMATIC RUNNING VEHICLE,"B60W60/00,B60W30/18,G08G1/123,G06K9/00","TOYOTA JIDOSHA KABUSHIKI KAISHA,DENSO CORPORATION,TOYOTA JIDOSHA KABUSHIKI KAISHA,DENSO CORPORATION","An operating situation obtaining unit obtains the operating situation information of a plurality of operating vehicles along a predetermined route. A delayed vehicle extraction unit extracts a delayed vehicle that is delayed in actual operation relative to the operation schedule from among the plurality of operating vehicles, based on the operating situation information of the respective operating vehicles. An overtaking instruction unit outputs an overtaking instruction to overtake the delayed vehicle to a following vehicle that immediately follows the delayed vehicle."
448,17235365,2021.04.20,20210302165,2021.09.30,20210302165,2021.09.30,,,IMU DATA OFFSET COMPENSATION FOR AN AUTONOMOUS VEHICLE,"G01C21/16,G05D1/02,G01C21/30,G01C25/00,G01S17/86,G01S17/931","UATC, LLC","A sensor data processing system for an autonomous vehicle receives inertial measurement unit (IMU) data from one or more IMUs of the autonomous vehicle. Based at least in part on the IMU data, the system identifies an IMU data offset from a deficient IMU of the one or more IMUs, and generates an offset compensation transform to compensate for the IMU data offset from the deficient IMU. The system dynamically executes the offset compensation transform on the IMU data from the deficient IMU to dynamically compensate for the IMU data offset."
449,17341992,2021.06.08,20210295461,2021.09.23,20210295461,2021.09.23,,,SHARED VEHICLE SERVICE PROVIDING METHOD PERFORMED BY SERVER COMMUNICATING WITH USER DEVICE OF PASSENGER AND AUTONOMOUS VEHICLE,"G06Q50/30,H04L29/08,G01C21/34,G08G1/00,G06Q30/00,B60W60/00,G08G1/133","SOS Lab Co., Ltd.","According to an aspect of the present disclosure, provided is a shared vehicle service providing method based on a shared vehicle management server communicating with a shared vehicle and a user device. Also provided is a shared vehicle service providing method for managing an article of a shared vehicle user on the basis of a shared vehicle management server. More specifically, provided is a shared vehicle service providing method in which a shared vehicle management server manages dispatch of a shared vehicle and an article of a user on the basis of data acquired from the shared vehicle and a user device."
450,17092845,2020.11.09,20210271250,2021.09.02,20210271250,2021.09.02,,,AUTONOMOUS DRIVING SYSTEM EMERGENCY SIGNALING,"G05D1/02,B60Q9/00","Tesla, Inc.","A vehicular autonomous driving system includes a time division multiplexed (TDM) bus, an autonomous driving (AD) controller coupled to the TDM bus, and a plurality of AD sensors coupled to the TDM bus. The AD sensors are configured to collect AD data and transmit collected AD data to the AD controller on the TDM bus in an assigned time slot at a first power level. A first AD sensor of the plurality of AD sensors is configured to, based upon collected AD data, detect an AD emergency event. In response to the detection, the first AD sensor is configured to transmit an AD emergency message on the TDM bus in a non-assigned time slot and at a second power level that exceeds the first power level. The AD sensor may transmit the AD emergency message in a particular sub-slot of the non-assigned time slot."
451,16522179,2019.07.25,,,11100591,2021.08.24,11100591,2021.08.24,Autonomous vehicle operation feature usage recommendations,"G06Q40/08,G06Q40/04,G06Q40/06,G06Q10/10,H04W4/029",STATE FARM MUTUAL AUTOMOBILE INSURANCE COMPANY,"Methods and systems for monitoring use, determining risk, and recommending usage levels of one or more autonomous (and/or semi-autonomous) operation features of a vehicle are provided. According to certain aspects, operating data from sensors within the vehicle may be used to determine risks associated with use of the features, which may include use at particular levels or with certain settings. The operating data may further be used to determine optimal or suggested use levels for the features. When the actual and suggested use levels differ, an alert may be generated and presented to the vehicle operator indicating suggested changes. The vehicle operator may then change the use levels or select an option to change the usage to the suggested use levels. The response of the vehicle operator may be used to determine or adjust aspects of an insurance policy associated with the vehicle."
452,16299510,2019.03.12,,,11100347,2021.08.24,11100347,2021.08.24,Photometric stereo object detection for articles left in an autonomous vehicle,"G06K9/00,G06K9/46,G06K9/62,H04W4/40,G06T7/586","FORD GLOBAL TECHNOLOGIES, LLC","Abandoned articles left by a user departing from an autonomous vehicle are automatically detected by capturing image data including a plurality of diversely-illuminated images of a target area within a passenger cabin of the vehicle. A plurality of normal vectors are determined for respective pixels representing the target area in a normal extractor based on the images. A normal-driven map is stored in a first array in response to the plurality of normal vectors. A baseline map is stored in a second array compiled from baseline images of the target area in a nominal clean state. Differences between the normal-driven map and the baseline map indicative of an object not present in the clean state are detected in a comparator. Difficult to detect objects can be found using a single, fixed camera."
453,16824258,2020.03.19,20210266295,2021.08.26,20210266295,2021.08.26,,,Deterministic Container-Based Network Configurations for Autonomous Vehicles,H04L29/06,"UATC, LLC","Systems and methods for operating autonomous vehicle devices in a network according to a network configuration are discussed. The network can include a plurality of pods configured to run on the one or more host computing devices. The network can include one or more containers encapsulated by each of the plurality of pods. The network can include one or more communication links configured to provide communications among the plurality of network devices. For instance, the one or more communication links can include one or more intranetwork links configured to provide communication between the plurality of pods. The network can include a firewall comprising one or more firewall rules. The one or more firewall rules can be configured to allow communications along the one or more communication links and block communications along some or all connections other than the one or more communication links."
454,17306449,2021.05.03,20210264794,2021.08.26,20210264794,2021.08.26,,,COOPERATIVE ADAPTIVE CRUISE CONTROL (CACC) SYSTEM FOR CONTROL OF CONNECTED AND AUTONOMOUS VEHICLE (CAV) PLATOONS,"G08G1/00,B60W30/16,B60W30/09","Intel Corporation,Intel Corporation","Techniques are disclosed to increase the safety of vehicles travelling in a vehicle platoon. These techniques include the utilization of a comprehensive safety framework such as a safety driving model (SDM) for the platoon control systems. In contrast to the conventional approaches, the use of the SDM model allows for platoon vehicle control systems to consider the acceleration/deceleration capabilities of the vehicles to calculate minimum safe longitudinal distances between the platoon vehicles. The disclosed techniques may utilize the periodicity of platoon messages as well as other parameters to improve upon platoon vehicle control and safety."
455,16972591,2019.06.08,20210237752,2021.08.05,20210237752,2021.08.05,,,"METHOD FOR OPERATING AN AUTONOMOUS VEHICLE, AND AUTONOMOUS VEHICLE","B60W50/038,G07C5/00,B60W30/09,B60W50/04,B60W50/023","Robert Bosch GmbH,Robert Bosch GmbH","A method for operating an autonomous vehicle. The method includes the transmission of status data to a processing unit, which is independent of the autonomous vehicle, using a wireless communications link. The method furthermore includes monitoring of the function of the autonomous vehicle by the independent processing unit while taking the status data into account, and when a malfunction of the autonomous vehicle is detected, the independent processing unit determines target data for guiding the autonomous vehicle to a stopping position. The target data are transmitted to the autonomous vehicle, and the autonomous vehicle is guided to the stopping position with the aid of the target data. A position of the autonomous vehicle is determined using signals from the wireless communications link and is taken into account when determining the target data."
456,16358206,2019.03.19,,,11086322,2021.08.10,11086322,2021.08.10,Identifying a route for an autonomous vehicle between an origin and destination location,"G05D1/00,G05D1/02",GM Cruise Holdings LLC,"Described herein are technologies relating to computing a likelihood of an operation-influencing event with respect to an autonomous vehicle at a geographic location. The likelihood of the operation-influencing event is computed based upon a prediction of a value that indicates whether, through a causal process, the operation-influencing event is expected to occur. The causal process is identified by means of a model, which relates spatiotemporal factors and the operation-influencing events."
457,16286294,2019.02.26,,,11079765,2021.08.03,11079765,2021.08.03,"Methods for communicating state, intent, and context of an autonomous vehicle","B60Q1/26,G05D1/02,G05D1/00,B60Q1/52,B60Q5/00,B60Q1/50,B60Q1/46",Direct Current Capital LLC,"One variation of a method for communicating state, intent, and context of an autonomous vehicle includes: at a first time, displaying a first icon representing a current state of a vehicle on a rear-facing visual display arranged on the vehicle; navigating toward an intersection; at a second time, detecting a state of the intersection ahead of the vehicle; rendering a second icon representing the state of the intersection at the second time on the rear-facing visual display; detecting a change in the state of the intersection at a third time succeeding the second time; selecting a next navigation action for the vehicle responsive to the change in the state of the intersection at the third time; prior to executing the next navigation action, rendering a third icon representing the next navigation action on the rear-facing visual display; and autonomously executing the next navigation action."
458,16817455,2020.03.12,,,11084512,2021.08.10,11084512,2021.08.10,Autonomous rail or off rail vehicle movement and system among a group of vehicles,"B61L27/04,B61L27/00,G01C21/20",Vinod Khosla,"In an example, the autonomous vehicle (“AV”) can be configured among the other vehicles and railway to communicate with a rider on a peer to peer basis to pick up the rider on demand from a location on a track, like a railway, tram or other track, rather than the rider being held hostage to -a fixed, railway schedule. The rider can have an application on his/her cell phone, which tracks each of the AVs. and contact them using the application on the cell phone. In an example, the AV is configured for both on-track and off track operation with different operating parameters for on-track and off track, including speed, degree of autonomy, sensors used etc."
459,16895373,2020.06.08,,,11080794,2021.08.03,11080794,2021.08.03,Autonomous vehicle technology effectiveness determination for insurance pricing,"G06Q40/08,G07C5/08,H04W4/90,H04W4/44,H04L29/08,B60W40/09,G08G1/005,G08G1/16,G08G1/0967,G08G1/14,G08B21/06,B60W30/16,G08G1/00,G06K9/00,G08B25/08,G06F30/20,G06Q40/04,G06Q10/06,B60Q9/00,G06Q20/08,B60R21/00,G05B15/02,H04W4/46,B60W40/08,G01S19/13,G06Q50/30",State Farm Mutual Automobile Insurance Company,"Methods and systems for determining the effectiveness of one or more autonomous (and/or semi-autonomous) operation features of a vehicle are provided. According to certain aspects, information regarding autonomous operation features of the vehicle may be used to determine an effectiveness metric indicative of the ability of each autonomous operation feature to avoid or mitigate accidents or other losses. The information may include operating data from the vehicle or other vehicles having similar autonomous operation features, test data, or loss data from other vehicles. The determined effectiveness metric may then be used to determine part or all of an insurance policy, which may be reviewed by an insured and updated based upon the effectiveness metric."
460,17214828,2021.03.27,20210216792,2021.07.15,20210216792,2021.07.15,,,SYSTEM AND METHOD FOR INSTANCE-LEVEL LANE DETECTION FOR AUTONOMOUS VEHICLE CONTROL,"G06K9/00,G06K9/46,G06K9/62,G06N20/00,G06N3/04,G06N3/08","TuSimple, Inc.","A system and method for instance-level lane detection for autonomous vehicle control are disclosed. A particular embodiment includes: receiving image data from an image data collection system associated with an autonomous vehicle; performing an operational phase comprising extracting roadway lane marking features from the image data, causing a plurality of trained tasks to execute concurrently to generate instance-level lane detection results based on the image data, the plurality of trained tasks having been individually trained with different features of training image data received from a training image data collection system and corresponding ground truth data, the training image data and the ground truth data comprising data collected from real-world traffic scenarios; causing the plurality of trained tasks to generate task-specific predictions of feature characteristics based on the image data and to generate corresponding instance-level lane detection results; and providing the instance-level lane detection results to an autonomous vehicle subsystem of the autonomous vehicle."
461,16672868,2019.11.04,,,11062399,2021.07.13,11062399,2021.07.13,Accident response using autonomous vehicle monitoring,"G06Q40/00,G08G1/16,H04W4/44,G07C5/08,G06Q40/08,G08G1/0967,G08G1/14,G06K9/00,G08G1/00,B60W30/16,G08B21/06,G08G1/005,G05B15/02,B60R21/00,G06Q20/08,B60Q9/00,G06Q10/06,B60W40/09,G07C5/00,H04W4/90,H04L29/08,G06F30/20,G08B25/08,G01S19/13,B60W40/08,H04W4/46,G06Q50/30",State Farm Mutual Automobile Insurance Company,"Methods and systems are provided for monitoring use of a vehicle having one or more autonomous (and/or semi-autonomous) operation features to determine and respond to incidents, such as collisions, thefts, or breakdowns. According to certain aspects, operating data from sensors within or near the vehicle may be used to determine when an incident has occurred and determine an appropriate response. The responses may include contacting a third party to provide assistance, such as local emergency services. In some embodiments, occurrence of the incident may be verified by automated communication with the vehicle operator."
462,17036402,2020.09.29,,,11062416,2021.07.13,11062416,2021.07.13,Shared vehicle service providing method performed by server communicating with user device of passenger and autonomous vehicle,"G06Q50/30,G06Q30/00,B60W60/00,G08G1/133,H04L29/08,G01C21/34,G08G1/00","SOS Lab Co., Ltd","According to an aspect of the present disclosure, provided is a shared vehicle service providing method based on a shared vehicle management server communicating with a shared vehicle and a user device. Also provided is a shared vehicle service providing method for managing an article of a shared vehicle user on the basis of a shared vehicle management server. More specifically, provided is a shared vehicle service providing method in which a shared vehicle management server manages dispatch of a shared vehicle and an article of a user on the basis of data acquired from the shared vehicle and a user device."
463,16731470,2019.12.31,20210201053,2021.07.01,20210201053,2021.07.01,,,VISUAL ANALYTICS PLATFORM FOR UPDATING OBJECT DETECTION MODELS IN AUTONOMOUS DRIVING APPLICATIONS,"G06K9/00,G06F16/904,G06F3/0484,G05D1/00,G06F16/58,G06N20/00",Robert Bosch GmbH,"Visual analytics tool for updating object detection models in autonomous driving applications. In one embodiment, an object detection model analysis system including a computer and an interface device. The interface device includes a display device. The computer includes an electronic processor that is configured to extract object information from image data with a first object detection model, extract characteristics of objects from metadata associated with image data, generate a summary of the object information and the characteristics, generate coordinated visualizations based on the summary and the characteristics, generate a recommendation graphical user interface element based on the coordinated visualizations and a first one or more user inputs, and update the first object detection model based at least in part on a classification of one or more individual objects as an actual weakness in the first object detection model to generate a second object detection model for autonomous driving."
464,17186285,2021.02.26,20210181755,2021.06.17,20210181755,2021.06.17,,,SYSTEMS AND METHODS FOR AUTONOMOUS DRIVING,"G05D1/02,G05D1/00,B60W30/18,B60W50/00,G06N20/00","BEIJING VOYAGER TECHNOLOGY CO., LTD.,BEIJING VOYAGER TECHNOLOGY CO., LTD.",The present disclosure relates to systems and methods for autonomous driving. The systems may obtain driving information associated with a vehicle; determine a state of the vehicle; determine one or more candidate control signals and one or more evaluation values corresponding to the one or more candidate control signals based on the driving information and the state of the vehicle by using a trained control model; select a target control signal from the one or more candidate control signals based on the one or more evaluation values; and transmit the target control signal to a control component of the vehicle.
465,16435845,2019.06.10,,,11038384,2021.06.15,11038384,2021.06.15,Monitoring of power systems using unmanned vehicle,"H04B5/00,H02J50/80,G05D1/10,G05D1/00,H04W4/029,H04W4/44,H04W4/80,B64C39/02","Schweitzer Engineering Laboratories, Inc.",The present application relates to autonomous and/or real-time monitoring of power transmission devices using an unmanned vehicle. The unmanned vehicle may have a modular payload that controls the unmanned vehicle's positioning and orientation. The modular payload may include processing circuitry that controls data acquisition and perform processing of the collected data. Processing of the collected data may include determinations of the type of power transmission device being monitored and/or determinations of the operational status of the power transmission device being monitored. Communication between the autonomous vehicle and/or payload and the power transmission device may be established using radiofrequency data links.
466,16518195,2019.07.22,,,11034349,2021.06.15,11034349,2021.06.15,Autonomous driving method and apparatus,"B60W30/16,B60W40/06,B60W50/00,B60W30/09","Samsung Electronics Co., Ltd.",An autonomous driving method includes: recognizing a target vehicle; determining a first slope of a host vehicle and a second slope of the target vehicle; correcting a result of the recognizing of the target vehicle based on the first slope and the second slope; and controlling the host vehicle based on the corrected result of the recognizing of the target vehicle.
467,17045924,2019.02.04,20210171046,2021.06.10,20210171046,2021.06.10,,,METHOD AND VEHICLE SYSTEM FOR PASSENGER RECOGNITION BY AUTONOMOUS VEHICLES,"B60W40/08,G05B15/02,G06Q50/30,B60W60/00,G01S19/42,G06T7/73,G06K9/00","ROBERT BOSCH GMBH,Robert Bosch GmbH","A method for passenger recognition by an autonomous vehicle in which a photograph of the person to be transported is transmitted to a central server, an approximate position of the person to be transported is determined, the autonomous vehicle is brought close to the previously determined position, a precise position of the person to be transported is ascertained by sensor equipment internal to the vehicle on the basis of color and texture features and/or on the basis of a way of walking, the identity of the ascertained person to be transported is verified by a facial recognition system, and the autonomous vehicle is positioned in a boarding area of the person to be transported."
468,16692661,2019.11.22,20210155070,2021.05.27,20210155070,2021.05.27,,,AUTONOMOUS OPERATION OF VEHICLE VENTS,B60H1/00,"Toyota Motor Engineering &#x26; Manufacturing North America, Inc.","A vent control system for a vehicle includes one or more processors and a memory communicably coupled to the one or more processors. The memory may store a vent control module including instructions that when executed by the one or more processors cause the one or more processors to autonomously control operation of a vehicle to open at least one vehicle vent when the vehicle is in a regular vent opening condition. Responsive to manual closure of the at least one vehicle vent within a predetermined time period after the at least one vehicle vent was autonomously opened, the regular opening condition may be updated to an updated regular opening condition. After updating the regular opening condition, operation of the vehicle may be autonomously controlled to open the at least one vehicle vent when the vehicle is subsequently in the updated regular opening condition."
469,16682546,2019.11.13,20210139018,2021.05.13,20210139018,2021.05.13,,,USE OF DRIVER ASSISTANCE COLLISION MITIGATION SYSTEMS WITH AUTONOMOUS DRIVING SYSTEMS,"B60W30/09,B60W10/18,B60W10/20,B60W50/00,H04L29/08",Robert Bosch GmbH,"Systems and methods for controlling a vehicle. The system includes one or more sensors positioned on the vehicle and configured to sense an environment surrounding the vehicle, a collision mitigation subsystem configured to control a braking system of the vehicle, and an autonomous driving subsystem communicatively coupled to the one or more sensors and the collision mitigation subsystem. The autonomous driving subsystem is configured to receive sensor information from the one or more sensors and generate, based on the sensor information, a model of the environment surrounding the vehicle. The autonomous driving subsystem is configured to determine, based on the model of the environment surrounding the vehicle, a plurality of possible trajectories for the vehicle and to select, from the plurality of possible trajectories, a travel path for the vehicle. The autonomous driving subsystem is configured to transmit the travel path to the collision mitigation subsystem."
470,16388352,2019.04.18,,,11005649,2021.05.11,11005649,2021.05.11,Autonomous driving controller encrypted communications,"H04L9/08,B60W50/02,B60W50/00","TESLA, INC.","An autonomous driving controller includes a plurality of parallel processors operating on common input data received from the plurality of autonomous driving sensors. Each of the plurality of parallel processors includes communication circuitry, a general processor, a security processor subsystem (SCS), and a safety subsystem (SMS). The communication circuitry supports communications between the plurality of parallel processors, including inter-processor communications between the general processors of the plurality of parallel processors, communications between the SCSs of the plurality of parallel processors using SCS cryptography, and communications between the SMSs of the plurality of parallel processors using SMS cryptography, the SMS cryptography differing from the SCS cryptography. The SCS and/or the SMS may each include dedicated hardware and/or memory to support the communications."
471,16673504,2019.11.04,20210129859,2021.05.06,20210129859,2021.05.06,,,DISPLAYING NEXT ACTION OF AN AUTONOMOUS VEHICLE,"B60W50/14,G05D1/00,G06T19/00",Volvo Car Corporation,"Systems, methods and computer program products that facilitate displaying next action of an autonomous vehicle. A system can include a memory and a processor that executes computer executable components. The computer executable components can include: an analysis component that determines or infers next action of an autonomous vehicle and a display component that generates a graphical user interface that visually conveys the next action, wherein the graphical user interface comprises a shape that dynamically morphs to visually represent the next action."
472,17139270,2020.12.31,20210124363,2021.04.29,20210124363,2021.04.29,,,TRAFFIC LIGHT OCCLUSION DETECTION FOR AUTONOMOUS VEHICLE,"G05D1/02,G05D1/00,G06K9/00,G06K9/32,G06T7/194,G06T7/11",GM GLOBAL TECHNOLOGY OPERATIONS LLC,"An occlusion detection system for an autonomous vehicle is described herein, where a signal conversion system receives a three-dimensional sensor signal from a sensor system and projects the three-dimensional sensor signal into a two-dimensional range image having a plurality of pixel values that include distance information to objects captured in the range image. A localization system detects a first object in the range image, such as a traffic light, having first distance information and a second object in the range image, such as a foreground object, having second distance information. An occlusion polygon is defined around the second object and the range image is provided to an object perception system that excludes information within the occlusion polygon to determine a configuration of the first object. A directive is output by the object perception system to control the autonomous vehicle based upon occlusion detection."
473,16921008,2020.07.06,20210114620,2021.04.22,20210114620,2021.04.22,,,"METHOD FOR CONTROLLING AUTONOMOUS VEHICLE TO PASS THROUGH CURVE, ELECTRONIC DEVICE AND MEDIUM","B60W60/00,B60W40/072,B60W30/10,G01C21/30,B60W30/095,B60W30/09,B60W40/105,B60W30/18","BEIJING BAIDU NETCOM SCIENCE AND TECHNOLOGY CO., LTD.,BEIJING BAIDU NETCOM SCIENCE AND TECHNOLOGY CO., LTD.","Embodiments of the present disclosure disclose a method for controlling an autonomous vehicle to pass through a curve, a device and a medium, and relate to the field of autonomous driving technologies. At least one implementation of the method for controlling an autonomous vehicle to pass through a curve includes: determining a curve boundary within a sensing area in a current driving direction of the autonomous vehicle based on a current position of the autonomous vehicle on the curve; determining a current safe stopping distance of the autonomous vehicle on the curve based on current driving parameters of the autonomous vehicle and the curve boundary; determining a speed threshold of the autonomous vehicle based on the current safe stopping distance, braking parameters of the autonomous vehicle and a curve curvature corresponding to the current position; and controlling a speed of the autonomous vehicle not to exceed the speed threshold."
474,17024267,2020.09.17,20210125659,2021.04.29,20210125659,2021.04.29,,,"MEMORY DEVICE, MEMORY SYSTEM AND AUTONOMOUS DRIVING APPARATUS","G11C11/4091,G11C5/02,G11C5/06,G11C11/4093,G11C11/408","Samsung Electronics Co., Ltd.","A memory device comprises a first memory area including a first memory cell array having a plurality of first memory cells each for storing N-bit data, where N is a natural number, and a first peripheral circuit for controlling the first memory cells according to an N-bit data access scheme and disposed below the first memory cell array, a second memory area including a second memory cell array having a plurality of second memory cells each for storing M-bit data, where M is a natural number greater than N, and a second peripheral circuit for controlling the second memory cells according to an M-bit data access scheme and disposed below the second memory cell array, wherein the first memory area and the second memory area are included in a single semiconductor chip and share an input and output interface, and a controller configured to generate calculation data by applying a weight stored in the first memory area to sensing data in response to receiving the sensing data obtained by an external sensor, and store the calculation data in one of the first memory area or the second memory area according to the weight, wherein the plurality of first memory cells and the plurality of second memory cells are included in a first chip having a first metal pad, the first peripheral circuit and the second peripheral circuit are included in a second chip having a second metal pad, and the first chip and the second chip are vertically connected to each other by the first metal pad and the second metal pad."
475,16892574,2020.06.04,20210124527,2021.04.29,20210124527,2021.04.29,,,"MEMORY DEVICE, MEMORY SYSTEM AND AUTONOMOUS DRIVING APPARATUS","G06F3/06,G06F13/16,G05D1/00","Samsung Electronics Co., Ltd.","A memory device includes a first memory area including a first memory cell array having a plurality of first memory cells each for storing N-bit data according to an M-bit data access scheme, where N is a natural number, and a first peripheral circuit for controlling the first memory cells and disposed below the first memory cell array, a second memory area including a second memory cell array having a plurality of second memory cells each for storing M-bit data according to an M-bit data access scheme, where M is a natural number greater than N, and a second peripheral circuit for controlling the second memory cells and disposed below the second memory cell array, the first memory area and the second memory area are included in a single semiconductor chip and share an input and output interface, and a controller configured to generate calculation data by applying a weight stored in the first memory area to sensing data in response to receiving the sensing data obtained by an external sensor, and store the calculation data in one of the first memory area or the second memory area according to the weight."
476,17131625,2020.12.22,20210108929,2021.04.15,20210108929,2021.04.15,,,DYNAMIC SELECTION OF AUTONOMOUS VEHICLE STOPPING POINTS,"G01C21/34,G01C21/36,G06N20/00","Yi Zhang,Frederik Pasch,Hao Feng,Cornelius Buerkle,Maruti Gupta Hyde,Fabian Oboril,Ravikumar Balakrishnan,Kay-Ulrich Scholl","Disclosed are embodiments for adjusting a vehicle stopping point. The vehicle stopping point is a point between a route of the vehicle and a second route. in some embodiments, an adjustment to the stopping point is determined based on ranking secondary routes that are adjusted based on the adjusted vehicle stopping point. Tanking of the secondary routes is based, in sonic embodiments, on a score of segment(s) included in the secondary routes. In some cases, the ranking of the segments considers safety information associated with each of the segments."
477,16988160,2020.08.07,20210086789,2021.03.25,20210086789,2021.03.25,,,AUTOMATIC DRIVING SYSTEM,"B60W60/00,B60W50/06,B60R1/12,B60W40/02,G06K9/00",SUBARU CORPORATION,An automatic driving system allows a vehicle to travel by automatic driving. The system includes first and second detectors and first and second determiners. The first detector is disposed on a movable part of the vehicle and detects an object located around the vehicle. The second detector is disposed on the vehicle and has an object detection region that partially overlaps a detection region of the first detector. The first determiner determines whether a detection state of the first detector based on a position of the object detected by the second detector and behavior of the object estimated from a detection position of the first detector and a traveling state of the vehicle. The automatic driving availability determiner determines availability of the automatic driving according to the detection state of the first detector and disables the automatic driving when the first detector is not in a regular detection state.
478,17102409,2020.11.23,20210078562,2021.03.18,20210078562,2021.03.18,,,PLANNING FOR UNKNOWN OBJECTS BY AN AUTONOMOUS VEHICLE,"B60W10/184,B60W10/20,B60W10/04,B60W40/04,B60W10/10,G08G1/16",Motional AD LLC,"Among other things, a world model is maintained of an environment of a vehicle. A hypothetical object in the environment that cannot be perceived by sensors of the vehicle is included in the world model."
479,17019135,2020.09.11,20210078600,2021.03.18,20210078600,2021.03.18,,,DISTRIBUTED COMPUTING SYSTEMS FOR AUTONOMOUS VEHICLE OPERATIONS,"B60W60/00,B60W30/095,G08G1/14,G08G1/16,G01C21/00","TUSIMPLE, INC.","Disclosed are distributed computing systems and methods for controlling multiple autonomous control modules and subsystems in an autonomous vehicle. In some aspects of the disclosed technology, a computing architecture for an autonomous vehicle includes distributing the complexity of autonomous vehicle operation, thereby avoiding the use of a single high-performance computing system and enabling off-the-shelf components to be use more readily and reducing system failure rates."
480,16567785,2019.09.11,20210070301,2021.03.11,20210070301,2021.03.11,,,PARTIALLY-AUTONOMOUS ROAD VEHICLE CONTROL VIA A SINGLE-EXTREMITY INTERFACE,"B60W30/18,B60W30/06,B60W50/10,G05D1/00","Toyota Motor Engineering &#x26; Manufacturing North America, Inc.,Toyota Motor Engineering &#x26; Manufacturing North America, Inc.","Methods and systems may provide for technology to control a road vehicle in a partially-autonomous mode along a default path and change a speed of the road vehicle in response to a first actuation event. The technology may also automatically deviate the road vehicle from a current lane on the default path in response to a second actuation event if a distance condition is satisfied with response to one or more of a future lane change or a future turn on the default path, wherein the first actuation event and the second actuation event are associated with a single-extremity user operation."
481,17019911,2020.09.14,20210064058,2021.03.04,20210064058,2021.03.04,,,Autonomous-Vehicle Dispatch Based on Fleet-Level Target Objectives,"G05D1/02,G01C21/34,G06Q30/06,G06Q10/06,G06Q10/00,G06Q50/30,G06Q30/02,G06Q10/02","Lyft, Inc.","In one embodiment, a method includes determining a fleet-level objective for a vehicle associated with instructing the vehicle to travel a route according to route criteria based on the fleet-level objective. The method includes receiving a ride request from a ride requestor associated with ride criteria including a pick-up location and a drop-off location. The method includes determining that the ride requestor is a passenger for the vehicle to satisfy the fleet-level objective contingent on modifications to the ride criteria. The method includes providing incentives to the ride requestor contingent on acceptance of the modifications to the ride criteria. The method includes, after receiving the acceptance of the modifications to the ride criteria, modifying the ride criteria in accordance with the route criteria. The method includes instructing the vehicle to transport the ride requestor based on the modified ride criteria so as to fulfill the fleet-level objective."
482,16548705,2019.08.22,20210053489,2021.02.25,20210053489,2021.02.25,,,VIRTUAL MIRROR WITH AUTOMATIC ZOOM BASED ON VEHICLE SENSORS,"B60R1/00,G06K9/00,G06T7/70,G06T7/50,G06T7/20,H04N5/225,H04N5/247,H04N5/232,B60R11/04","Micron Technology, Inc.","In one approach, a method includes: displaying, to a user of a first vehicle, image data obtained using a first field of view of a camera of the first vehicle, where the camera collects the image data for objects located outside of the first vehicle; detecting, by at least one processing device of the first vehicle, a second vehicle; determining, by the one processing device, whether the second vehicle is within a predetermined region relative to the first vehicle; and in response to determining that the second vehicle is within the predetermined region, displaying image data obtained using a second field of view of the camera."
483,17086364,2020.10.31,20210048830,2021.02.18,20210048830,2021.02.18,,,MULTIMODAL MULTI-TECHNIQUE SIGNAL FUSION SYSTEM FOR AUTONOMOUS VEHICLE,"G05D1/02,G05D1/00,G06K9/00,G06K9/62",GM GLOBAL TECHNOLOGY OPERATIONS LLC,"An autonomous vehicle incorporating a multimodal multi-technique signal fusion system is described herein. The signal fusion system is configured to receive at least one sensor signal that is output by at least one sensor system (multimodal), such as at least one image sensor signal from at least one camera. The at least one sensor signal is provided to a plurality of object detector modules of different types (multi-technique), such as an absolute detector module and a relative activation detector module, that generate independent directives based on the at least one sensor signal. The independent directives are fused by a signal fusion module to output a fused directive for controlling the autonomous vehicle."
484,16917403,2020.06.30,20210046952,2021.02.18,20210046952,2021.02.18,,,AUTONOMOUS VEHICLE AND SYSTEM FOR AUTONOMOUS VEHICLE,"B60W60/00,B60W50/029,G07C5/08,H04W4/40","BEIJING BAIDU NETCOM SCIENCE AND TECHNOLOGY CO., LTD.","Embodiments of the present disclosure relate to an autonomous vehicle and a system for the autonomous vehicle. The system may include a master computing unit configured to control operations of the autonomous vehicle; a slave computing unit communicatively coupled to the master computing unit and configured to control the operations of the autonomous vehicle in response to detecting a failure of the master computing unit; at least one lidar configured to acquire environmental information around the autonomous vehicle; and a switch communicatively coupled to the at least one lidar, the master computing unit and the slave computing unit, and configured to provide the environmental information to the master computing unit and the slave computing unit for controlling the autonomous vehicle."
485,16917147,2020.06.30,20210046945,2021.02.18,20210046945,2021.02.18,,,AUTONOMOUS VEHICLE AND SYSTEM FOR AUTONOMOUS VEHICLE,"B60W50/029,B60W60/00,G07C5/08,H04W4/40","BEIJING BAIDU NETCOM SCIENCE AND TECHNOLOGY CO., LTD.","Embodiments of the present disclosure relate to an autonomous vehicle and a system for the autonomous vehicle. The system may include: a power supply including a first power output and a second power output; a master computing unit arranged to be powered by the first power output, configured to control operations of the autonomous vehicle in response to detecting the second power output, and configured to provide a third power output by adjusting the first power output; and a slave computing unit arranged to be powered by the second power output, and configured to control the operations of the autonomous vehicle in response to detecting a failure of the master computing unit."
486,16536231,2019.08.08,20210041869,2021.02.11,20210041869,2021.02.11,,,AUTONOMOUS VEHICLE POSITIONING SYSTEM,"G05D1/00,G08G1/01,G08G1/09,G05D1/02","TOYOTA MOTOR NORTH AMERICA, INC.","Systems and methods are provided to determine traffic configuration parameters, such as location and speed, that are correlated with optimal traffic flow specific to particular road regions. In a specific embodiment, the disclosure is directed to a vehicle positioning system which utilizes a multi-client server application model configured to perform predictive analysis based upon data collected from a plurality of data streams, infrastructure elements, and vehicles. In a particular implementation, roadways may be partitioned into road regions which may be associated with vehicle configuration templates. Vehicle configuration templates may define instructions for automated vehicle driving parameters within a particular road region. In a specific embodiment, the vehicle positioning system may invoke transition sequences based upon real-time traffic data to modify a given traffic configuration."
487,16522262,2019.07.25,20210023990,2021.01.28,20210023990,2021.01.28,,,VEHICLE DRIVER AND AUTONOMOUS SYSTEM COLLABORATION,"B60Q9/00,G06N5/04,G01C21/34",International Business Machines Corporation,"A state of a driver operating a vehicle based at least on a rest pattern of the driver and a driver safety score and vehicle characteristic associated with the vehicle are determined. A risk of a planned route is received based on environment information. A safety risk for at least one location along the planned route is determined based on the received risk. Based on the safety risk, a use of available driver attention determined based on the state of the driver, possible modification of the planned route and vehicle state may be planned that minimize the safety risk. It may be determined that the driver is approaching a location along the planned route having a safety risk. Responsive to determining that the driver is approaching a location along the planned route having a safety risk, alert may be caused to be sent to the driver."
488,16905809,2020.06.18,,,10906558,2021.02.02,10906558,2021.02.02,Methods and systems for managing interactions of an autonomous vehicle with other objects,"B60W60/00,G06K9/00","IKE ROBOTICS, INC.","A method and a system for managing interactions of an autonomous vehicle with one or more objects are described. In one embodiment, objects that are in the vicinity of the autonomous vehicle are detected based on sensor measurements. An interaction label is determined for each one of the objects. The interaction label is one of a yield label, a no-yield label, a stay-behind label, a stay in-front label, and an irrelevant label and describes an interaction of the autonomous vehicle with the object. A cost function is generated for the object based on the interaction label. A trajectory for an interval of time is determined for the autonomous vehicle based on the cost functions of one or more objects. The trajectory is then used to generate control commands for controlling the motion of the autonomous vehicle during the interval of time."
489,17061855,2020.10.02,20210016771,2021.01.21,20210016771,2021.01.21,,,SADDLE-RIDE VEHICLE WITH AUTONOMOUS BRAKING AND METHOD OF OPERATING SAME,"B60W30/09,B60W10/18,B60W10/04,B60W40/08,B60W50/16,B60W10/02,B60T7/12,B60W50/14,B60W30/095","Harley-Davidson Motor Company Group, LLC","A saddle-ride vehicle includes a forward travel sensor a brake that decelerates the vehicle by actuation of a rider-operable brake control. A controller identifies a trigger for an autonomous braking event for the brake. A rider sensor system is in electrical communication with the controller and includes one or both of: a rider cognition sensor operable to detect parameters of rider cognition and report rider cognition status to the controller, and a rider physical sensor operable to detect parameters of a physical engagement between a rider and the vehicle and report rider physical engagement status to the controller. The controller is programmed to perform one or both of the following in response to the identification of the autonomous braking event trigger: checking for a positive cognitive engagement of the rider with the rider cognition sensor, and checking for a positive physical engagement of the rider with the rider physical sensor."
490,16513682,2019.07.16,20210021442,2021.01.21,20210021442,2021.01.21,,,OPEN AND SAFE MONITORING SYSTEM FOR AUTONOMOUS DRIVING PLATFORM,"H04L12/40,H04L12/863,H04L12/861",Baidu USA LLC,"In one embodiment, a system for operating an autonomous driving vehicle (ADV) includes a number of modules. These modules include at least a perception module to perceive a driving environment surrounding the ADV and a planning module to plan a path to drive the ADV to navigate the driving environment. The system further includes a bus coupled to the modules and a sensor processing module communicatively coupled to the modules over the bus. The sensor processing module includes a bus interface coupled to the bus, a sensor interface to be coupled to a first set of one or more sensors mounted on the ADV, a message queue to store messages published by the sensors, and a message handler to manage the messages stored in the message queue. The messages may be subscribed by at least one of the modules to allow the modules to monitor operations of the sensors."
491,16929888,2020.07.15,20210016735,2021.01.21,20210016735,2021.01.21,,,Triggering at least one Crash Cushion of an Unmanned Vehicle,"B60R21/0134,B60R21/36","Uwe Radetzki,Dong-Uck Kong,Boris Trendafilov,Heike Bischoff,Sandra Drees,Deutsche Post AG","A method is disclosed in which sensor information is obtained that is captured by at least one environment sensor of an unmanned vehicle. The sensor information represents at least one object parameter of an object that is moving relative to the unmanned vehicle. At least partly based on the at least one object parameter, it is determined whether a collision between the unmanned vehicle and the object is imminent. If it is determined that a collision between the unmanned vehicle and the object is imminent, at least partly based on the at least one object parameter, at least one triggering parameter is determined for triggering at least one crash cushion of the unmanned vehicle. The at least one crash cushion is triggered according to the at least one triggering parameter. The at least one crash cushion is triggered before the imminent collision."
492,16505077,2019.07.08,20210009133,2021.01.14,20210009133,2021.01.14,,,FLEET-BASED AVERAGE LANE CHANGE AND DRIVER-SPECIFIC BEHAVIOR MODELLING FOR AUTONOMOUS VEHICLE LANE CHANGE OPERATION,"B60W30/18,B60W40/09,B60W30/095,G08G1/16","TOYOTA MOTOR ENGINEERING &#x26; MANUFACTURING NORTH AMERICA, INC.","Systems and methods are provided for creating more organic lane change models for autonomous or semi-autonomous operation of a vehicle. A plurality of data associated with a plurality of driver-performed lane change maneuvers is collected from a plurality of different vehicle. Driver-performed lane change maneuvers are discarded when determined to fall outside a threshold of safety. A generic model is generated from the non-discarded data for average lane change maneuvers. Specific models can be generated for different drivers, vehicle types, and other metrics by comparison with the generic model."
493,16869438,2020.05.07,20200391736,2020.12.17,20200391736,2020.12.17,,,"Training Machine Learning Model Based On Training Instances With: Training Instance Input Based On Autonomous Vehicle Sensor Data, and Training Instance Output Based On Additional Vehicle Sensor Data","B60W30/095,G05D1/02,G05D1/00,G06N20/00,G06K9/62,G01S17/931","Aurora Innovation, Inc.","Various implementations described herein generate training instances that each include corresponding training instance input that is based on corresponding sensor data of a corresponding autonomous vehicle, and that include corresponding training instance output that is based on corresponding sensor data of a corresponding additional vehicle, where the corresponding additional vehicle is captured at least in part by the corresponding sensor data of the corresponding autonomous vehicle. Various implementations train a machine learning model based on such training instances. Once trained, the machine learning model can enable processing, using the machine learning model, of sensor data from a given autonomous vehicle to predict one or more properties of a given additional vehicle that is captured at least in part by the sensor data."
494,16435845,2019.06.10,20200389059,2020.12.10,20200389059,2020.12.10,,,MONITORING OF POWER SYSTEMS USING UNMANNED VEHICLE,"H02J50/80,G05D1/10,G05D1/00,B64C39/02,H04W4/029,H04W4/44,H04W4/80","Schweitzer Engineering Laboratories, Inc.,Schweitzer Engineering Laboratories, Inc.",The present application relates to autonomous and/or real-time monitoring of power transmission devices using an unmanned vehicle. The unmanned vehicle may have a modular payload that controls the unmanned vehicle's positioning and orientation. The modular payload may include processing circuitry that controls data acquisition and perform processing of the collected data. Processing of the collected data may include determinations of the type of power transmission device being monitored and/or determinations of the operational status of the power transmission device being monitored. Communication between the autonomous vehicle and/or payload and the power transmission device may be established using radiofrequency data links.
495,16899561,2020.06.11,20200393253,2020.12.17,20200393253,2020.12.17,,,METHOD FOR GENERATING ROAD MAP FOR AUTONOMOUS VEHICLE NAVIGATION,"G01C21/32,G01C21/34,G06K9/00",WeRide Corp.,"A method for generating a road map for vehicle navigation comprises: receiving an original road map having a crossroad junction, an inward lane entering the crossroad junction, and an outward lane leaving the crossroad junction; generating a reference path capable of guiding a vehicle driving from the inward lane to the outward lane through the crossroad junction; generating a polygonal hub that encompasses the crossroad junction, wherein the reference path enters and leaves the hub by crossing a first binder and a second binder, respectively; and generating automatically a type of the reference path based on the geometrical relationship between the first binder and the second binder."
496,16423902,2019.05.28,20200377087,2020.12.03,20200377087,2020.12.03,,,LANE KEEP CONTROL OF AUTONOMOUS VEHICLE,"B60W30/12,G06K9/00,G05D1/02,B60W40/072","SF Motors, Inc.,SF Motors, Inc.","An autonomous vehicle (AV) is automatically navigated within a a driving lane. Lane line data is received from one or more sensors, such as one or more cameras. A first parametric curve can be matched to a location of a first lane line detected from the lane line data. A second parametric curve can be matched to a location of a second lane line detected from the lane line data. A center parametric curve can be then generated in the center of the first parametric curve and the second parametric curve. The center parametric curve is then sampled to generate a discrete vector of trajectory points along the center parametric curve. The AV is then navigated along the road based on the trajectory points."
497,16994089,2020.08.14,20200372460,2020.11.26,20200372460,2020.11.26,,,Continuous Integrity Monitoring for Autonomous Transportation Services (MaaS),"G06Q10/08,G08G1/00,H04L9/32,H04L9/08","Intel Corporation,Intel Corporation","Systems, apparatuses, and methods to attest to and verify the integrity of cargo during transport by an autonomous vehicle are provided. An autonomous vehicle can discretize parameters associated with transportation of cargo and can generate a keyed hash digest from the discretized parameters. The keyed hash digest can be sent to a stakeholder in the transportation of the cargo to attest to the integrity of the cargo during transport."
498,16787667,2020.02.11,20200356100,2020.11.12,20200356100,2020.11.12,,,GENERATION OF AUTONOMY MAP FOR AUTONOMOUS VEHICLE,"G05D1/02,G01C21/34","ANI TECHNOLOGIES PRIVATE LIMITED,ANI TECHNOLOGIES PRIVATE LIMITED",Generation of an autonomy map for assisting an autonomous vehicle includes extracting the historical autonomy information associated one or more route segments of one or more routes. An autonomy level for each route segment is determined based on the extracted historical autonomy information. A digital autonomy map is generated including each route segment of at least one route such that each route segment is tagged with the determined autonomy level. The autonomy level of each route segment is dynamically updated in real-time for providing real-time driving assistance to the autonomous vehicle.
499,16929954,2020.07.15,20200348678,2020.11.05,20200348678,2020.11.05,,,SYSTEM AND METHOD FOR REAL WORLD AUTONOMOUS VEHICLE TRAJECTORY SIMULATION,"G05D1/02,G05D1/00,G05B13/04,G06N20/00","TUSIMPLE, INC.","A system and method for real world autonomous vehicle trajectory simulation may include: receiving training data from a data collection system; obtaining ground truth data corresponding to the training data; performing a training phase to train a plurality of trajectory prediction models; and performing a simulation or operational phase to generate a vicinal scenario for each simulated vehicle in an iteration of a simulation. Vicinal scenarios may correspond to different locations, traffic patterns, or environmental conditions being simulated. Vehicle intention data corresponding to a data representation of various types of simulated vehicle or driver intentions."
500,16404208,2019.05.06,20200346643,2020.11.05,20200346643,2020.11.05,,,Operational Risk Assessment for Autonomous Vehicle Control,"B60W30/095,B60W30/09,G06K9/00,G05D1/00","Retrospect Technology, LLC,Retrospect Technology, LLC","Changes in the controlling of an autonomous vehicle are caused based on an operational risk determined for the autonomous vehicle. An operational risk monitor module of the autonomous vehicle uses information about objects detected within an environment in which the autonomous vehicle is located and predicted behaviors of those objects to assess the operational risk of the autonomous vehicle along a planned path. The operational risk is used to determine whether to cause a change in the controlling of the autonomous vehicle, for example, based on a comparison between the operational risk and a previously estimated operational risk or based on a determination that the operational risk exceeds a threshold. The operational risk monitor module transmits a signal to one or more control system modules of the autonomous vehicle to indicate to change the controlling of the autonomous vehicle based on the operational risk."
501,16399901,2019.04.30,20200346641,2020.11.05,20200346641,2020.11.05,,,Operational Risk Assessment for Autonomous Vehicle Control,"B60W30/09,B60W30/095,G06K9/00,G05D1/00","Retrospect Technology, LLC,Retrospect Technology, LLC","Changes in the controlling of an autonomous vehicle are caused based on an operational risk determined for the autonomous vehicle. An operational risk monitor module of the autonomous vehicle uses information about objects detected within an environment in which the autonomous vehicle is located and predicted behaviors of those objects to assess the operational risk of the autonomous vehicle along a planned path. The operational risk is used to determine whether to cause a change in the controlling of the autonomous vehicle, for example, based on a comparison between the operational risk and a previously estimated operational risk or based on a determination that the operational risk exceeds a threshold. The operational risk monitor module transmits a signal to one or more control system modules of the autonomous vehicle to indicate to change the controlling of the autonomous vehicle based on the operational risk."
502,16917118,2020.06.30,20200333796,2020.10.22,20200333796,2020.10.22,,,IMAGE PROCESSING METHOD FOR AUTONOMOUS DRIVING AND APPARATUS THEREOF,"G05D1/02,H04N5/235,G06T5/00,G06K9/20,G06K9/00,G06K9/32,G01C21/16,G01S19/47,G01C21/34,G01C21/26,H04N5/232,G06T7/73,G05D1/00,G06T5/50","Samsung Electronics Co., Ltd.,Samsung Electronics Co., Ltd.",A processor implemented image processing method includes recognizing a target object in a first frame of an input image; adjusting an exposure of a second frame of the input image based on a brightness of the target object; and generating a synthesized image by synthesizing the first frame and the second frame.
503,16378475,2019.04.08,20200317119,2020.10.08,20200317119,2020.10.08,,,AUTONOMOUS VEHICLE ACTIVE INTERACTION WITH SURROUNDING ENVIRONMENT,"B60Q1/50,B60Q1/34,B60Q5/00,B60W30/095","SF Motors, Inc.,SF Motors, Inc.","An automated vehicle (AV) which automatically interacts with objects in a surrounding environment based on the objects determined intention and predicted actions determined based on their intention. Data is collected from an external environment by cameras, sensors, and optionally other devices on an AV. The data is processed to identify objects and a state for each object, and an interaction scenario is identified. For objects within the interaction scenario, an intention for each object is determined, and the action of the object is predicted. The AV generates a decision to perform an action to communicate the AV's action to one or more objects. Commands are generated to execute the decision, and the intention of the AV is implemented by executing the commands using one or more output mechanisms (horn, turn signal, display, and/or other mechanisms) for the  AV."
504,16365461,2019.03.26,20200310449,2020.10.01,20200310449,2020.10.01,,,REASONING SYSTEM FOR SENSEMAKING IN AUTONOMOUS DRIVING,"G05D1/02,G06N5/04",GM Global Technology Operations LLC,"An autonomous vehicle, system and method of operating the autonomous vehicle. The system includes a sensor, a reasoning engine and a navigation system. The sensor receives token data. The reasoning engine performs an abductive inference on a fact determined from the token data to estimate a backward condition, and a deductive inference to the estimated backward condition in to order to predict a forward condition. The navigation system operates the autonomous vehicle based on the predicted forward condition."
505,16365490,2019.03.26,20200310421,2020.10.01,20200310421,2020.10.01,,,ONLINE DRIVING PERFORMANCE EVALUATION USING SPATIAL AND TEMPORAL TRAFFIC INFORMATION FOR AUTONOMOUS DRIVING SYSTEMS,"G05D1/00,G05D1/02",GM GLOBAL TECHNOLOGY OPERATIONS LLC,"An autonomous vehicle, system and method of operating the autonomous vehicle. The system includes a performance evaluator, a decision module and a navigation system. The performance evaluator determines a performance grade for each of a plurality of decisions for operating the autonomous vehicle. The decision module selects a decision have a greatest performance grade. The navigation system operates the autonomous vehicle using the selected decision."
506,16358206,2019.03.19,20200301419,2020.09.24,20200301419,2020.09.24,,,IDENTIFYING A ROUTE FOR AN AUTONOMOUS VEHICLE BETWEEN AN ORIGIN AND DESTINATION LOCATION,"G05D1/00,G05D1/02",GM Cruise Holdings LLC,"Described herein are technologies relating to computing a likelihood of an operation-influencing event with respect to an autonomous vehicle at a geographic location. The likelihood of the operation-influencing event is computed based upon a prediction of a value that indicates whether, through a causal process, the operation-influencing event is expected to occur. The causal process is identified by means of a model, which relates spatiotemporal factors and the operation-influencing events."
507,16895373,2020.06.08,20200302547,2020.09.24,20200302547,2020.09.24,,,AUTONOMOUS VEHICLE TECHNOLOGY EFFECTIVENESS DETERMINATION FOR INSURANCE PRICING,G06Q40/08,State Farm Mutual Automobile Insurance Company,"Methods and systems for determining the effectiveness of one or more autonomous (and/or semi-autonomous) operation features of a vehicle are provided. According to certain aspects, information regarding autonomous operation features of the vehicle may be used to determine an effectiveness metric indicative of the ability of each autonomous operation feature to avoid or mitigate accidents or other losses. The information may include operating data from the vehicle or other vehicles having similar autonomous operation features, test data, or loss data from other vehicles. The determined effectiveness metric may then be used to determine part or all of an insurance policy, which may be reviewed by an insured and updated based upon the effectiveness metric."
508,16809540,2020.03.04,20200285866,2020.09.10,20200285866,2020.09.10,,,CLASS LABELING SYSTEM FOR AUTONOMOUS DRIVING,"G06K9/00,G06K9/46,G06K9/62,G06K9/32,G06K9/20","HYUNDAI MOBIS Co., Ltd.","A class labeling system for autonomous driving includes a detection module, a segmentation module, and a lane road boundary detection module. The detection module is configured to detect objects for autonomous driving from an image captured by a camera to generate a bounding box for each of the objects and detect property information about the object. The segmentation module is configured to determine classes for each pixel of the bounding box detected by the detection module and process at least one of the classes as don't care. The lane road boundary detection module is configured to detect at least one of lane and road boundaries using the bounding box detected by the detection module."
509,16299510,2019.03.12,20200293799,2020.09.17,20200293799,2020.09.17,,,PHOTOMETRIC STEREO OBJECT DETECTION FOR ARTICLES LEFT IN AN AUTONOMOUS VEHICLE,"G06K9/00,G06K9/46,G06K9/62,G06T7/586,H04W4/40","FORD GLOBAL TECHNOLOGIES, LLC","Abandoned articles left by a user departing from an autonomous vehicle are automatically detected by capturing image data including a plurality of diversely-illuminated images of a target area within a passenger cabin of the vehicle. A plurality of normal vectors are determined for respective pixels representing the target area in a normal extractor based on the images. A normal-driven map is stored in a first array in response to the plurality of normal vectors. A baseline map is stored in a second array compiled from baseline images of the target area in a nominal clean state. Differences between the normal-driven map and the baseline map indicative of an object not present in the clean state are detected in a comparator. Difficult to detect objects can be found using a single, fixed camera."
510,16818578,2020.03.13,20200293057,2020.09.17,20200293057,2020.09.17,,,TERRAIN TRAFFICABILITY ASSESSMENT FOR AUTONOMOUS OR SEMI-AUTONOMOUS ROVER OR VEHICLE,"G05D1/02,G06N20/00,G06N3/08,B60W60/00,G05D1/00,G06K9/62,G06K9/00,G06K9/20",Mission Control Space Services Inc.,A rover or semi-autonomous or autonomous vehicle may use an image classifier to determine a terrain class of regions of an image of the terrain ahead of the rover or vehicle. The regions of the images are used to estimate the slope of the terrain for the different regions. The terrain class and slope are used to predict an amount of slip the rover will experience when traversing the terrain of the different regions. A heuristic mapping for the terrain class may be applied to the predicted slip amount to determine a hazard level for the rover or vehicle traversing the terrain.
511,16793645,2020.02.18,20200272163,2020.08.27,20200272163,2020.08.27,,,LOW-COST AUTONOMOUS DRIVING SHUTTLE AND A METHOD OF OPERATING SAME,"G05D1/02,G06K9/00","HYUNDAI MOTOR COMPANY,KIA MOTORS CORPORATION,HYUNDAI MOTOR COMPANY,KIA MOTORS CORPORATION","A method of operating an autonomous driving shuttle includes: receiving, by the autonomous driving shuttle, information on an operation of the autonomous driving shuttle; recognizing a guide line by using at least one camera provided in the autonomous driving shuttle; and driving the autonomous driving shuttle by using the information on the operation and the recognized guide line."
512,16284487,2019.02.25,20200269663,2020.08.27,20200269663,2020.08.27,,,CONTROLLING SUNSHADES IN AN AUTONOMOUS VEHICLE,"B60J1/20,G05D1/02,G05D1/00","TOYOTA RESEARCH INSTITUTE, INC.",A method for controlling a sunshade of an autonomous vehicle is presented. The method includes determining that current conditions satisfy an activation condition. The method also includes predicting whether a driver will enable a manual mode during the current conditions. The method further includes activating a first sunshade in response to the satisfied activation condition regardless of whether the driver will enable the manual mode. The method still further includes activating a second sunshade in response to the satisfied activation condition when the driver will not enable the manual mode.
513,16242592,2019.01.08,20200219333,2020.07.09,10762725,2020.09.01,10762725,2020.09.01,Automatic classification of inactive vehicle tracking unit,"H04W4/42,H04W4/44,G07C5/00,G01S5/00,G08G1/00",Verizon Connect Ireland Limited,"A device can receive message data associated with a vehicle tracking unit (VTU). The device can identify, based on the message data, the VTU as an inactive VTU. The device can compute a feature vector, associated with the VTU, based on the message data and on environmental data associated with the VTU. The feature vector can be computed based on identifying the VTU as an inactive VTU. The device can determine, using an inactivity classification model, an inactivity classification associated with the VTU. The inactivity classification can be determined based on providing the feature vector, associated with the VTU, as an input to the inactivity classification model. The device can cause an inactivity action to be performed based on the inactivity classification."
514,16851842,2020.04.17,20200250981,2020.08.06,20200250981,2020.08.06,,,Autonomous Vehicles Featuring Vehicle Intention System,"G08G1/16,B60W50/00,B60W30/095,B60W50/14,B60W40/04,B60W30/09,G05D1/00,G06Q50/30,G01C21/26,G08G1/0967","UATC, LLC","The present disclosure provides autonomous vehicles that include a vehicle intention system that provides intention signals indicative of an intention of the autonomous vehicle. In particular, in one example, the vehicle intention system can obtain one or more operational messages from various systems or components of an autonomous vehicle that operate to control the autonomous vehicle. The operational messages can include operational data regarding the control or operation of the autonomous vehicle. The vehicle intention system can determine an intention of the autonomous vehicle based at least in part on the one or more operational messages. The vehicle intention system can output one or more intention signals that indicate the determined intention of the autonomous vehicle. For example, the vehicle intention system can publish intention messages that indicate the determined intention to one or more components or systems that consume the intention messages."
515,16259935,2019.01.28,20200241541,2020.07.30,20200241541,2020.07.30,,,SYSTEM AND METHOD OF AN ALGORITHMIC SOLUTION TO GENERATE A SMOOTH VEHICLE VELOCITY TRAJECTORY FOR AN AUTONOMOUS VEHICLE WITH SPATIAL SPEED CONSTRAINTS,"G05D1/02,G05D1/00","GM GLOBAL TECHNOLOGY OPERATIONS LLC,GM GLOBAL TECHNOLOGY OPERATIONS LLC","Methods and systems for piecewise sinusoid trajectory planning including: receiving, by a processing unit disposed in an ego vehicle, point data defining a current path plan for the ego vehicle; fetching, by the processing unit, a current ego position along the current path plan; calculating, by the processing unit, a current velocity and an acceleration for the current ego position which is based in part on a velocity and acceleration derived from a previous planned trajectory, the planned trajectory is calculated by: setting a graph with a grid of nodes in the velocity-time domain of the search space connected by edges; evaluating the graph with a shortest path algorithm wherein the validity and cost with respect to desired constraints of vehicle motion and system limitations of each edge are determined by use of the piecewise sinusoidal path length, velocity, and acceleration profiles which are parameterized to connect pairs of nodes; setting, by the processing unit, the optimal vehicle trajectory equal to the set of connected edges, and thereby piecewise sinusoid velocity profiles, which minimize the objective cost function over some duration planned into the future."
516,16538275,2019.08.12,20200233415,2020.07.23,20200233415,2020.07.23,,,DEPART CONSTRAINTS IMPLEMENTATION IN AUTONOMOUS VEHICLE ROUTING,"G05D1/00,G05D1/02,G01C21/34","Uber Technologies, Inc.","A method of controlling navigation of autonomous vehicles includes accessing map data descriptive of the identity and location of different travel ways within a surrounding environment of an autonomous vehicle and accessing constraint data descriptive of one or more geographic areas or geographic identifiers, within the map data, for which associated navigational constraints are defined. The constraint data includes a depart constraint that specifies an area that an autonomous vehicle may not enter but may exit if inside the area when the depart constraint is imposed, thereby preventing the autonomous vehicle from being trapped in a forbidden area even though the autonomous vehicle may safely complete its route. A travel route is determined for the autonomous vehicle based at least in part on the map data evaluated relative to the constraint data including the depart constraint, and motion of the autonomous vehicle is controlled based on the determined travel route."
517,16817455,2020.03.12,20200207391,2020.07.02,20200207391,2020.07.02,,,AUTONOMOUS RAIL OR OFF RAIL VEHICLE MOVEMENT AND SYSTEM AMONG A GROUP OF VEHICLES,"B61L27/04,B61L27/00,G01C21/20",Vinod Khosla,"In an example, the autonomous vehicle (“AV”) can be configured among the other vehicles and railway to communicate with a rider on a peer to peer basis to pick up the rider on demand from a location on a track, like a railway, tram or other track, rather than the rider being held hostage to -a fixed, railway schedule. The rider can have an application on his/her cell phone, which tracks each of the AVs. and contact them using the application on the cell phone. In an example, the AV is configured for both on-track and off track operation with different operating parameters for on-track and off track, including speed, degree of autonomy, sensors used etc."
518,16810622,2020.03.05,20200198678,2020.06.25,20200198678,2020.06.25,,,AUTONOMOUS RAIL OR OFF RAIL VEHICLE MOVEMENT AND SYSTEM AMONG A GROUP OF VEHICLES,"B61L27/04,B61L25/02,G05D1/02,B61L23/04,B61L23/34,B61L15/00,G01C21/00,G05D1/00,B61L27/00",Vinod KHOSLA,"In an example, the autonomous vehicle (“AV”) can be configured among the other vehicles and railway to communicate with a rider on a peer to peer basis to pick up the rider on demand from a location on a track, like a railway, tram or other track, rather than the rider being held hostage to a fixed railway schedule. The rider can have an application on his/her cell phone, which tracks each of the AVs, and contact them using the application on the cell phone. In an example, the AV is configured for both on-track and off track operation with different operating parameters for on-track and off track, including speed, degree of autonomy, sensors used etc."
519,16708441,2019.12.10,20200189611,2020.06.18,20200189611,2020.06.18,,,AUTONOMOUS DRIVING USING AN ADJUSTABLE AUTONOMOUS DRIVING PATTERN,"B60W50/08,G08G1/01,G05D1/00,B60W30/18,G05D1/02",CARTICA AI LTD,"There may be provided a method for autonomous driving, the method may include: receiving, from a vehicle, and by an I/O module of a computerized system, (a) driving information indicative of a manner in which a driver controls the vehicle while driving over a path, and (b) environmental sensor information indicative of information sensed by the vehicle, the environmental sensor information is indicative of the path and the vicinity of the path; detecting, based on at least the environmental information, multiple events encountered during the driving over the path; determining event types, wherein each of the multiple events belongs to a certain event type; for each event type, determining, based on driving information associated with events of the multiple events that belong to the event type, a tailored autonomous driving pattern information that is indicative of a tailored autonomous driving pattern to be applied by the vehicle during an occurrence of the event type; for each event type, determining, based on environmental sensor information associated with events of the multiple events that belong to the event type, an event type identifier; and storing in at least one data structure (a) event type identifier for each one of the multiple types of events, and (b) tailored autonomous driving pattern information for each one of the multiple types of events."
520,16705071,2019.12.05,20200183414,2020.06.11,20200183414,2020.06.11,,,AUTOMATED VEHICLE FOR AUTONOMOUS LAST-MILE DELIVERIES,"G05D1/02,G06Q10/08,B60R25/24,B60R25/01","DoorDash, Inc.,DoorDash, Inc.","Provided are various systems and processes for improving last-mile delivery of real-time, on-demand orders for perishable goods. In one aspect, an automated vehicle (AV) comprises a body including a storage compartment for storing perishable goods. The storage compartment is accessible by a user upon authentication of the user. The AV further comprises a sensor module for receiving data for navigating the AV. The sensor module is positioned above the body on a support structure at a predetermined height above the ground, such as three to five feet. The data includes one or more of the following: audio data, video data, radio waves, and backscattered light waves. The AV further comprises an onboard computer system configured to process the data to navigate the AV along motor vehicle routes and pedestrian routes. The AV may be configured to interface with an automated locker system to retrieve or deposit the perishable goods."
521,16664195,2019.10.25,20200150651,2020.05.14,20200150651,2020.05.14,,,METHOD AND APPARATUS FOR CONTROLLING AUTONOMOUS VEHICLE,"G05D1/00,B60W30/09","Baidu Online Network Technology (Beijing) Co., Ltd.","A method and an apparatus for controlling an autonomous vehicle are provided according to the embodiments of the disclosure. The method includes: sending, in response to determining that a pedestrian is in a first target area, behavior prompt information representing prompting the pedestrian to make a corresponding behavior; determining whether a deceleration condition matching the behavior prompt information is satisfied based on acquired behavior information of the pedestrian; and sending control information for reducing a moving speed of the autonomous vehicle, in response to determining that the deceleration condition is satisfied and determining that a speed of the autonomous vehicle is greater than a preset deceleration threshold. According to the embodiments, deceleration control of the autonomous vehicle is achieved based on the response of the pedestrian to the behavior prompt information."
522,16726276,2019.12.24,20200130709,2020.04.30,20200130709,2020.04.30,,,METHOD AND DEVICE FOR DETERMINING A CONFIGURATION FOR AN AUTONOMOUS VEHICLE,"B60W60/00,G05B13/04,G05D1/00,B60W50/00","Intel Corporation,Mobileye Vision Technologies Ltd.","According to various embodiments, a method for determining a configuration for an autonomous vehicle is described comprising, for each configuration parameter setting of a plurality of configuration parameter settings and each driving scenario of a plurality of driving scenarios, simulating a behavior of an autonomous vehicle configured in accordance with the configuration parameter setting in the driving scenario and determining a continuous measure of a safety of the autonomous vehicle in the driving scenario configured in accordance with the configuration parameter setting based on the simulated behavior, wherein the measure represents a continuous degree of safety of the vehicle configured in accordance with the configuration parameter setting and selecting one or more configurations for the autonomous vehicle based on the determined measures of a safety that meet a threshold degree of safety."
523,16577735,2019.09.20,20200097004,2020.03.26,20200097004,2020.03.26,,,EVOLUTIONARY ALGORITHMIC STATE MACHINE FOR AUTONOMOUS VEHICLE PLANNING,"G05D1/00,G06N3/08,B60W40/04","CYNGN, INC.,CYNGN, INC.","Artificial intelligence vehicle systems include vehicle guidance systems and adaptive, evolutionary driving training protocols for state machines. A state machine makes decisions based on information supplied by the sensors attached to the vehicle, the current state of the vehicle, the capabilities of the vehicle, and optionally the applicable traffic laws (e.g., if a roadway vehicle) or facility rules (e.g., if a facility vehicle, such as warehouse, construction site, campus, or the like). An autonomous driver of a state machine decides between possible actions given the current environment where those possible actions to existing conditions are represented by action rules, which may be referred to as “genes.” The adaptive systems enable improved vehicle guidance and can improve over time as new circumstances are encountered and processed."
524,16516068,2019.07.18,20200079286,2020.03.12,20200079286,2020.03.12,,,"Method and Apparatus for Unmanned Vehicle Passing Through Intersection, Device and Storage Medium","B60Q5/00,G05D1/00,B60Q1/50,G05D1/02,B60R11/02","Baidu Online Network Technology (Beijing) Co., Ltd.,Baidu Online Network Technology (Beijing) Co., Ltd.","Embodiments of the present application provide a method and an apparatus for an unmanned vehicle passing through an intersection, a device and a storage medium. The method includes: detecting whether the unmanned vehicle is at an intersection without a traffic light sign; identifying a moving direction and a distance of outside personnel and/or identifying voice and limb reaction of the outside personnel when determining that the unmanned vehicle is at the intersection without the traffic light sign; determining whether to pass according to the moving direction and the distance of the outside personnel, and/or the voice and limb reaction of the outside personnel; and making a corresponding voice prompt and/or a corresponding visual prompt to the outside personnel according to a result of the determination on whether to pass."
525,16539312,2019.08.13,20200047771,2020.02.13,20200047771,2020.02.13,,,"METHOD OF ASSISTING AUTONOMOUS VEHICLE, AND APPARATUS THEREFOR","B60W50/08,G05D1/00","Samsung Electronics Co., Ltd.,Samsung Electronics Co., Ltd.","A method of assisting an autonomous vehicle includes obtaining first surrounding area information of the vehicle when the vehicle is located at a first distance from a monitored area disposed ahead of the vehicle, providing a first control command for controlling the vehicle to operate in a first operating mode, by using the first surrounding area information, obtaining second surrounding area information of the vehicle when the vehicle has driven toward the monitored area and is located at a second distance less than the first distance from the monitored area, and providing a second control command for controlling the vehicle to operate in a second operating mode, by using the second surrounding area information."
526,16421423,2019.05.23,20200001779,2020.01.02,20200001779,2020.01.02,,,METHOD FOR COMMUNICATING INTENT OF AN AUTONOMOUS VEHICLE,"B60Q1/50,G05D1/00",drive.ai Inc.,"One variation of a method for communicating intent includes, at an autonomous vehicle: autonomously approaching an intersection; autonomously navigating to a stop proximal the intersection; while stopped proximal the intersection, projecting an intent icon onto pavement at a first distance ahead of the autonomous vehicle; calculating a confidence score for possession of right of way of the autonomous vehicle to enter the intersection based on objects detected in a field around the autonomous vehicle; projecting the intent icon onto pavement at distances ahead of the autonomous vehicle proportional to the confidence score and greater than the first distance; and in response to the confidence score exceeding a threshold score, autonomously entering the intersection."
527,16518195,2019.07.22,20190337515,2019.11.07,20190337515,2019.11.07,,,AUTONOMOUS DRIVING METHOD AND APPARATUS,"B60W30/16,B60W50/00,B60W40/06","Samsung Electronics Co., Ltd.,Samsung Electronics Co., Ltd.",An autonomous driving method includes: recognizing a target vehicle; determining a first slope of a host vehicle and a second slope of the target vehicle; correcting a result of the recognizing of the target vehicle based on the first slope and the second slope; and controlling the host vehicle based on the corrected result of the recognizing of the target vehicle.
528,16388541,2019.04.18,20190332390,2019.10.31,20190332390,2019.10.31,,,AUTONOMOUS DRIVING CONTROLLER PARALLEL PROCESSOR BOOT ORDER,"G06F9/4401,B60R16/023,G05D1/00","TESLA, INC.,TESLA, INC.","An autonomous driving controller includes a plurality of parallel processors operating on common input data. Each of the plurality of parallel processors includes a general processor, a security processor subsystem (SCS), and a safety subsystem (SMS). The general processors, the SCSs, and the SMSs of the plurality of parallel processors are configured to first, boot the plurality of SCSs from ROM second, boot the plurality of SMSs of the plurality of parallel processors from RAM or ROM, and, third, boot the plurality of general processors of the plurality of parallel processors from RAM. Between booting of the SCSs and the SMSs, at least one of the plurality of SCSs may load SMS boot code into the RAM that is dedicated to the plurality of SMSs."
529,16388352,2019.04.18,20190334706,2019.10.31,20190334706,2019.10.31,,,AUTONOMOUS DRIVING CONTROLLER ENCRYPTED COMMUNICATIONS,"H04L9/08,B60W50/02","TESLA, INC.,TESLA, INC.","An autonomous driving controller includes a plurality of parallel processors operating on common input data received from the plurality of autonomous driving sensors. Each of the plurality of parallel processors includes communication circuitry, a general processor, a security processor subsystem (SCS), and a safety subsystem (SMS). The communication circuitry supports communications between the plurality of parallel processors, including inter-processor communications between the general processors of the plurality of parallel processors, communications between the SCSs of the plurality of parallel processors using SCS cryptography, and communications between the SMSs of the plurality of parallel processors using SMS cryptography, the SMS cryptography differing from the SCS cryptography. The SCS and/or the SMS may each include dedicated hardware and/or memory to support the communications."
530,16357129,2019.03.18,20190283531,2019.09.19,20190283531,2019.09.19,,,INTELLIGENT THERMAL CONTROL SYSTEM FOR AUTONOMOUS VEHICLE,"B60H1/00,B60H1/24","Air International Thermal Systems,Air International Thermal Systems","A thermal system for use in autonomous motor vehicles includes an intelligent controller that receives inputs from various sources, interprets the inputs using an algorithm that learns during the process of interpreting the inputs, and generates outputs to control system features. The intelligent controller receives key input data that includes internet data and vehicle data. This data, together with other key inputs, are provided to the input layer which determines an energy balance that identifies the desired power level and the actual power level. Once the desired and actual power levels are identified, the controller generates outputs that regulate conditions within the vehicle's interior. The intelligent controller includes algorithms that enable the thermal system to make power management predictions for maximum system efficiency. The intelligent controller is capable of learning and can make decisions as to optimum interior conditions without the need for additional or repetitive operator or occupant inputs."
531,16397965,2019.04.29,20190258146,2019.08.22,20190258146,2019.08.22,,,Control of Display Device for Autonomous Vehicle,"G03B21/14,G06K9/00,G02B27/01,G06F3/038,G03B21/00","Micron Technology, Inc.","A display device of an autonomous vehicle is controlled based on data collected from sensors located in or on the vehicle. The display device is used to present one or more images to a driver and/or passengers of the autonomous vehicle. The display device can be, for example, a windshield and/or other window of the vehicle. Image data can be, for example, transformed to improve visual perception by passengers in the vehicle when the images are displayed on a curved shape of the windshield."
532,16391032,2019.04.22,20190248380,2019.08.15,20190248380,2019.08.15,,,COMPUTER-ASSISTED DRIVING METHOD AND APPARATUS INCLUDING AUTOMATIC MITIGATION OF POTENTIAL EMERGENCY,"B60W50/12,B60W30/09,B60W30/095,G05D1/00",Intel Corporation,"Apparatuses, storage media and methods associated with computer assisted driving (CAD), are disclosed herein. In some embodiments, an apparatus includes an autopilot engine to automatically pilot the vehicle out of a potential emergency situation, including to automatically pilot the vehicle for a period of time in view of a plurality of operational guardrails determined in real time for each of a plurality of timing windows; and a mitigation unit to conditionally activate the autopilot engine, including to activate the autopilot engine in response to analysis results indicative of the vehicle being potentially operated into the emergency situation manually. Other embodiments are also described and claimed."
533,16264566,2019.01.31,20190232974,2019.08.01,20190232974,2019.08.01,,,METHOD FOR CUSTOMIZING MOTION CHARACTERISTICS OF AN AUTONOMOUS VEHICLE FOR A USER,"B60W50/08,G05D1/02,B60W50/00,G05D1/00,G06K9/00,G06F3/01,A61B5/024,A61B5/16,A61B5/00",drive.ai Inc.,"One variation of a method for customizing motion characteristics of an autonomous vehicle for a user includes: accessing a baseline emotional state of the user following entry of the user into the autonomous vehicle at a first time proximal a start of a trip; during a first segment of the trip, autonomously navigating toward a destination location according to a first motion planning parameter, accessing a second emotional state of the user at a second time, detecting degradation of sentiment of the user based on differences between the baseline and second emotional states; and correlating degradation of sentiment of the user with a navigational characteristic of the autonomous vehicle; modifying the first motion planning parameter of the autonomous vehicle to deviate from the navigational characteristic; and, during a second segment of the trip, autonomously navigating toward the destination location according to the revised motion planning parameter."
534,16380002,2019.04.10,20190232957,2019.08.01,20190232957,2019.08.01,,,PLANNING FOR UNKNOWN OBJECTS BY AN AUTONOMOUS VEHICLE,"B60W30/09,G08G1/16","nuTonomy, Inc.","Among other things, a model is maintained of an environment of a vehicle. A hypothetical object in the environment that cannot be perceived by sensors of the vehicle is included in the model."
535,16250533,2019.01.17,20190225216,2019.07.25,20190225216,2019.07.25,,,TRAVEL REFERENCE LINE DETERMINATION SYSTEM AND AUTOMATIC DRIVING SYSTEM,"B60W30/10,G06F17/10,G05B13/02,G05D1/02","HONDA MOTOR CO., LTD.,HONDA MOTOR CO., LTD.","There is provided a travel reference line determination system and an automatic driving system capable of determining a travel reference line of a vehicle appropriately even under conditions where information representing the track environment of the vehicle is hard to get. An ECU of an automatic driving system calculates a model y coordinate value ymw_i using a map in FIG.  4  (Step  12  ), calculates an estimated y coordinate value y_i using track environment data D_info (Step  11  ), calculates curvature C so that an error between the model y coordinate value ymw_i and the estimated y coordinate value y_i may be minimized (Step  18  ), calculates a travel trajectory Xf using the curvature C (Step  4  ), and executes automatic driving control using the travel trajectory Xf (Steps  31  to  33  )."
536,16286294,2019.02.26,20190196482,2019.06.27,20190196482,2019.06.27,,,"METHODS FOR COMMUNICATING STATE, INTENT, AND CONTEXT OF AN AUTONOMOUS VEHICLE","G05D1/02,B60Q1/26,G05D1/00",drive.ai Inc.,"One variation of a method for communicating state, intent, and context of an autonomous vehicle includes: at a first time, displaying a first icon representing a current state of a vehicle on a rear-facing visual display arranged on the vehicle; navigating toward an intersection; at a second time, detecting a state of the intersection ahead of the vehicle; rendering a second icon representing the state of the intersection at the second time on the rear-facing visual display; detecting a change in the state of the intersection at a third time succeeding the second time; selecting a next navigation action for the vehicle responsive to the change in the state of the intersection at the third time; prior to executing the next navigation action, rendering a third icon representing the next navigation action on the rear-facing visual display; and autonomously executing the next navigation action."
537,15930839,2020.05.13,,,11457558,2022.10.04,11457558,2022.10.04,Autonomous vehicle navigation,"A01D34/00,G05D1/02,G06T7/10,G06K9/62,G06V20/56,A01D101/00,A01D34/64",Hydro-Gear Limited Partnership,"A lawn mower including a vision sensor configured to capture an image, a drive system configured to move the lawn mower at a velocity and configured to change the velocity, a processor connected to the vision sensor and the drive system, the processor comprising processing logic that includes a first movement threshold, the processor configured to divide the image into a plurality of image sections, categorize, for each image section, the image data, into one of mowable image data and unmowable image data, obtain, for each image section, a percentage of unmowable image data, and assign one of a first result value and a second result value to each section based on a comparison between the percentage with the first movement threshold."
538,16734584,2020.01.06,,,11383620,2022.07.12,11383620,2022.07.12,Automatic vehicle configuration based on sensor data,"B60N2/02,B60W40/08,B60R16/037,B60H1/00","Capital One Services, LLC","A vehicle receives sensor data that includes image data of frames that depict one or more individuals outside of the vehicle, and identifies, by analyzing the sensor data using one or more attribute recognition techniques, a set of attributes of an individual of the one or more individuals. The vehicle determines a set of scores indicating a set of likelihoods of a set of vehicle configurations being a preferred vehicle configuration for the individual, based on a data model performing a machine-learning-driven analysis of attribute data identifying the set of attributes, and/or location data identifying a location of the individual relative to the vehicle. The vehicle selects a particular vehicle configuration based on a score that indicates a likelihood of the particular vehicle configuration being the preferred vehicle configuration and provides an instruction to cause a vehicle component to implement the particular vehicle configuration by updating a configurable value."
539,16941162,2020.07.28,,,11373419,2022.06.28,11373419,2022.06.28,Automatically detecting unmapped drivable road surfaces for autonomous vehicles,"G06V20/56,G06K9/62,G05D1/02",Waymo LLC,"Aspects of the disclosure relate to detecting unmapped drivable road surfaces. In one instance, sensor data captured by a sensor of an autonomous vehicle may be projected onto a grid having a plurality of cells. The plurality of cells may be classified by generating a label for each of the plurality of cells. Each label may identifies whether or not a corresponding cell contains a drivable surface. Ones of the plurality of cells may be clustered based on the labels to form a cluster of cells. An area of the cluster of cells may be compared to a map. Whether the area of the cluster of cells is an unmapped drivable road surface may be determined based on the comparison."
540,17156535,2021.01.23,20220126725,2022.04.28,20220126725,2022.04.28,,,METHOD FOR SCHEDULING MULTI AGENT AND UNMANNED ELECTRIC VEHICLE BATTERY SWAP BASED ON INTERNET OF VEHICLES,"B60L53/80,B60L53/63,B60L53/66,H04W4/44,B60L53/67","HARBIN ENGINEERING UNIVERSITY,HARBIN ENGINEERING UNIVERSITY","A method for scheduling EV battery swap based on IoV, in which the roadside units regard battery-swap station clusters with a high degree of potential cooperation as a whole, and gather them into a single battery swap area; taking a service rate of a cluster of swap stations as an assessment target, and mainly examining a service capability, a service quality, and location information of each of swap station nodes themselves, and a current state of those electric vehicles that require to swap battery; providing a solution of the best joint actions for the overall electric vehicles to maintain the overall service balance of every swap station and improve a long-term performance of Internet of Vehicles. According to the invention, a battery of the electric vehicles can be swapped as soon as possible, and every battery swap station can maintain business balance."
541,17029854,2020.09.23,20220088249,2022.03.24,20220088249,2022.03.24,,,AUTONOMOUS SEAT SANITIZING SYSTEM FOR A VEHICLE,"A61L2/24,A61L2/10,B60Q3/233,B60Q1/00","Toyota Motor North America, Inc.","An autonomous seat sanitizing system for a vehicle includes a vehicle seat sanitizing system control module configured to detect a person approaching a vehicle. Responsive to a person approaching the vehicle, a distance of the person from the vehicle is determined. The distance of the person from the vehicle is compared to a predetermined threshold distance. If the distance of the person from the vehicle is less than the predetermined threshold distance, the control module determines if at least one seat in the vehicle occupant compartment is unoccupied. If at least one seat is unoccupied, the module controls operation of the vehicle to direct a sanitizing ultraviolet (UV) light onto the unoccupied seat until a vehicle door is opened from an exterior of the vehicle, or until the distance of the person from the vehicle is no longer less than the predetermined threshold distance."
542,17363644,2021.06.30,20210323445,2021.10.21,20210323445,2021.10.21,,,AUTONOMOUS SEAT ADJUSTMENT IN A VEHICLE,"B60N2/02,G06K9/00,B60N2/00","TOYOTA RESEARCH INSTITUTE, INC.,TOYOTA RESEARCH INSTITUTE, INC.",A method for adjusting a seat in a vehicle includes adjusting the seat from an initial position to a passenger adjusted position based on receiving an input from a passenger. The method further includes determining the passenger exited the vehicle after adjusting the seat and predicting a likelihood of the passenger returning to the vehicle based on determining the passenger exited the vehicle. The method also includes adjusting the seat to the initial position based on the likelihood of the passenger returning is less than a passenger returning threshold. The method still further includes identifying a person approaching the vehicle after the passenger exited the vehicle based on information captured by one or more sensors of the vehicle. The method also includes adjusting the seat to a position associated with the previous passenger based on identifying the person approaching the vehicle as the previous passenger.
543,16941162,2020.07.28,20210049374,2021.02.18,20210049374,2021.02.18,,,Automatically Detecting Unmapped Drivable Road Surfaces For Autonomous Vehicles,"G06K9/00,G06K9/62,G05D1/02",Waymo LLC,"Aspects of the disclosure relate to detecting unmapped drivable road surfaces. In one instance, sensor data captured by a sensor of an autonomous vehicle may be projected onto a grid having a plurality of cells. The plurality of cells may be classified by generating a label for each of the plurality of cells. Each label may identifies whether or not a corresponding cell contains a drivable surface. Ones of the plurality of cells may be clustered based on the labels to form a cluster of cells. An area of the cluster of cells may be compared to a map. Whether the area of the cluster of cells is an unmapped drivable road surface may be determined based on the comparison."
544,16734584,2020.01.06,20210031655,2021.02.04,20210031655,2021.02.04,,,AUTOMATIC VEHICLE CONFIGURATION BASED ON SENSOR DATA,"B60N2/02,B60H1/00,B60R16/037,B60W40/08","Capital One Services, LLC,Capital One Services, LLC","A vehicle receives sensor data that includes image data of frames that depict one or more individuals outside of the vehicle, and identifies, by analyzing the sensor data using one or more attribute recognition techniques, a set of attributes of an individual of the one or more individuals. The vehicle determines a set of scores indicating a set of likelihoods of a set of vehicle configurations being a preferred vehicle configuration for the individual, based on a data model performing a machine-learning-driven analysis of attribute data identifying the set of attributes, and/or location data identifying a location of the individual relative to the vehicle. The vehicle selects a particular vehicle configuration based on a score that indicates a likelihood of the particular vehicle configuration being the preferred vehicle configuration and provides an instruction to cause a vehicle component to implement the particular vehicle configuration by updating a configurable value."
545,16797636,2020.02.21,20200283016,2020.09.10,20200283016,2020.09.10,,,MOVEMENT PREDICTION OF PEDESTRIANS USEFUL FOR AUTONOMOUS DRIVING,"B60W60/00,B60W30/095,G06K9/00,G06N7/00,G06T7/246",Robert Bosch GmbH,A prediction device is described for predicting a location of a pedestrian moving in an environment. The prediction device may have a memory configured to store a probability distribution for multiple latent variables indicating one or more states of the one or more pedestrians. The prediction device may be configured to predict a position of a pedestrian for which no position information is currently available from the probability distribution of the multiple latent variables.
546,16732221,2019.12.31,20200211372,2020.07.02,20200211372,2020.07.02,,,DYNAMIC CO-OPERATIVE ARRAYS OF ELECTROMAGNETIC MARKERS FOR HIGHLY AUTONOMOUS VEHICLE LOCATION AND CRYPTOGRAPHICALLY SECURE TRANSACTIONS,"G08G1/01,H04W4/44,H04L9/06,G08G1/042",Edmund S. Nabrotzky,"A system that uses cooperative arrays of electromagnetic resonating markers in combination with a vehicle mounted resonating transceiver. Markers establish their position placement during a calibration sequence in which cryptographic keys are exchanged, ensuring the markers are placed by authorized personnel and that none can be removed/relocated without detection. Markers can then be reliably polled by passing vehicles to determine relative location in areas of sensor occlusion. The markers can also be securely used for emerging smart city financial transactions such as automated parking, garbage collection, deliveries, tolling or temporary pedestrian markets."
547,16528040,2019.07.31,,,10525850,2020.01.07,10525850,2020.01.07,Automatic vehicle configuration based on sensor data,"B60N2/02,B60W40/08,B60R16/037,B60H1/00","Capital One Services, LLC","A vehicle receives sensor data that includes image data of frames that depict one or more individuals outside of the vehicle, and identifies, by analyzing the sensor data using one or more attribute recognition techniques, a set of attributes of an individual of the one or more individuals. The vehicle determines a set of scores indicating a set of likelihoods of a set of vehicle configurations being a preferred vehicle configuration for the individual, based on a data model performing a machine-learning-driven analysis of attribute data identifying the set of attributes, and/or location data identifying a location of the individual relative to the vehicle. The vehicle selects a particular vehicle configuration based on a score that indicates a likelihood of the particular vehicle configuration being the preferred vehicle configuration and provides an instruction to cause a vehicle component to implement the particular vehicle configuration by updating a configurable value."
548,17483762,2021.09.23,20220101557,2022.03.31,20220101557,2022.03.31,,,CALIBRATION OF AUTONOMOUS FARMING VEHICLE IMAGE ACQUISITION SYSTEM,"G06T7/80,G06T7/70,G06T7/579,G06T17/05,G05D1/02",Blue River Technology Inc.,"A system and a method are disclosed for calibrating an image acquisition system of a farming machine. The farming machine captures images of objects in an environment as the farming machine moves through an environment. Based on the captured images, a represented three-dimensional (3D) model of the environment representing the objects in a three-dimensional space is generated. From the represented 3D model, a represented location of an object (e.g., building, lamppost, tree) is determined. The represented location of the object is compared to a reference location of the object and the comparison is used to calibrate the image acquisition system by modifying positions, orientations, or optical settings of one or more cameras in the image acquisition system."
549,16257713,2019.01.25,,,10402977,2019.09.03,10402977,2019.09.03,Learning method and learning device for improving segmentation performance in road obstacle detection required to satisfy level 4 and level 5 of autonomous vehicles using laplacian pyramid network and testing method and testing device using the same,"G06T7/11,G06K9/62,G06N3/08,G06T7/13,G06N20/00,G06T3/40,G06K9/00","Stradvision, Inc.","A learning method for improving a segmentation performance in detecting edges of road obstacles and traffic signs, etc. required to satisfy level 4 and level 5 of autonomous vehicles using a learning device is provided. The traffic signs, as well as landmarks and road markers may be detected more accurately by reinforcing text parts as edge parts in an image. The method includes steps of: the learning device (a) instructing k convolutional layers to generate k encoded feature maps, including h encoded feature maps corresponding to h mask layers; (b) instructing k deconvolutional layers to generate k decoded feature maps (i) by using h bandpass feature maps and h decoded feature maps corresponding to the h mask layers and (ii) by using feature maps to be inputted respectively to k-h deconvolutional layers; and (c) adjusting parameters of the deconvolutional and convolutional layers."
550,16562225,2019.09.05,,,11435946,2022.09.06,11435946,2022.09.06,Intelligent wear leveling with reduced write-amplification for data storage devices configured on autonomous vehicles,"G06F3/06,G06N3/04,G06N3/08,G06F12/10","Micron Technology, Inc.","Systems, methods and apparatus of intelligent wear-leveling with reduced write-amplification for data storage devices configured on autonomous vehicles. For example, a data storage device of a vehicle includes: storage media components; a controller configured to store data into and retrieve data from the storage media components according to commands received in the data storage device; an address map configured to map between: logical addresses specified in the commands received in the data storage device, and physical addresses of memory cells in the storage media components; and an artificial neural network configured to receive, as input and as a function of time, operating parameters indicative a data access pattern, and generate, based on the input, a prediction to determine an optimized operation for wear leveling among memory cells in the data storage device. The controller is configured to perform the optimized operation for wear leveling based on the prediction."
551,16791900,2020.02.14,20210255637,2021.08.19,20210255637,2021.08.19,,,INTELLIGENT LIDAR SENSORS FOR AUTONOMOUS VEHICLES,"G05D1/02,G06N3/063,G06N3/04,G06F17/16,G05B13/02,G01S7/48,G01S7/4865,G01S17/89","Micron Technology, Inc.","Systems, methods and apparatuses of lidar sensors of autonomous vehicles. A lidar sensor can include: a memory configured to store a lidar image and an Artificial Neural Network (ANN); an inference engine configured to use the (ANN) to analyze the lidar image and generate inference results; and a communication interface coupled to a computer system of a vehicle to implement an advanced driver assistance system to operate the controls according to the inference results and a sensor data stream generated by sensors configured on the vehicle."
552,16719196,2019.12.18,20210190913,2021.06.24,20210190913,2021.06.24,,,Intelligent Radar Electronic Control Units in Autonomous Vehicles,"G01S7/41,G06N5/04,G01S13/931,G01S13/89","Micron Technology, Inc.","Systems, methods and apparatuses of radar Electronic Control Units (ECUs) of autonomous vehicles. A radar ECU can include: a memory configured to store a radar image and an Artificial Neural Network (ANN); an inference engine configured to use the (ANN) to analyze the radar image and generate inference results; and a communication interface coupled to a computer system of a vehicle to implement an advanced driver assistance system to operate the controls according to the inference results and a sensor data stream generated by sensors configured on the vehicle."
553,16562225,2019.09.05,20210072921,2021.03.11,20210072921,2021.03.11,,,Intelligent Wear Leveling with Reduced Write-Amplification for Data Storage Devices Configured on Autonomous Vehicles,"G06F3/06,G06N3/04,G06N3/08,G06F12/10","Micron Technology, Inc.","Systems, methods and apparatus of intelligent wear-leveling with reduced write-amplification for data storage devices configured on autonomous vehicles. For example, a data storage device of a vehicle includes: storage media components; a controller configured to store data into and retrieve data from the storage media components according to commands received in the data storage device; an address map configured to map between: logical addresses specified in the commands received in the data storage device, and physical addresses of memory cells in the storage media components; and an artificial neural network configured to receive, as input and as a function of time, operating parameters indicative a data access pattern, and generate, based on the input, a prediction to determine an optimized operation for wear leveling among memory cells in the data storage device. The controller is configured to perform the optimized operation for wear leveling based on the prediction."
554,16562222,2019.09.05,20210072911,2021.03.11,20210072911,2021.03.11,,,Intelligent Write-Amplification Reduction for Data Storage Devices Configured on Autonomous Vehicles,"G06F3/06,G06F12/02,G06N3/04,G05D1/00,G05D1/02","Micron Technology, Inc.","Systems, methods and apparatus of intelligent write-amplification reduction for data storage devices configured on autonomous vehicles. For example, a data storage device of a vehicle includes: one or more storage media components; a controller configured to store data into and retrieve data from the one or more storage media components according to commands received in the data storage device; an address map configured to map between: logical addresses specified in the commands received in the data storage device, and physical addresses of memory cells in the one or more storage media components; and an artificial neural network configured to receive, as input and as a function of time, operating parameters indicative a data access pattern, and generate, based on the input, a prediction to determine an optimized data placement scheme. The controller is configured to adjust the address map according to the optimized data placement scheme."
555,16932681,2020.07.17,20210024094,2021.01.28,20210024094,2021.01.28,,,FILTERING USER RESPONSES FOR GENERATING TRAINING DATA FOR MACHINE LEARNING BASED MODELS FOR NAVIGATION OF AUTONOMOUS VEHICLES,"B60W60/00,B60W40/02,B60W40/09,G06N3/08","Perceptive Automata, Inc.",An autonomous vehicle uses machine learning based models such as neural networks to predict hidden context attributes associated with traffic entities. The hidden context represents behavior of the traffic entities in the traffic. The machine learning based model is configured to receive a video frame as input and output likelihoods of receiving user responses having particular ordinal values. The system uses a loss function based on cumulative histogram of user responses corresponding to various ordinal values. The system identifies user responses that are unlikely to be valid user responses to generate training data for training the machine learning mode. The system identifies invalid user responses based on response time of the user responses.
556,16253996,2019.01.22,,,10460210,2019.10.29,10460210,2019.10.29,Method and device of neural network operations using a grid generator for converting modes according to classes of areas to satisfy level 4 of autonomous vehicles,"G06K9/00,G06K9/62,G06N3/08,G06T7/70","Stradvision, Inc.","A method of neural network operations by using a grid generator is provided for converting modes according to classes of areas to satisfy level 4 of autonomous vehicles. The method includes steps of: (a) a computing device, if a test image is acquired, instructing a non-object detector to acquire non-object location information for testing and class information of the non-objects for testing by detecting the non-objects for testing on the test image; (b) the computing device instructing the grid generator to generate section information by referring to the non-object location information for testing; (c) the computing device instructing a neural network to determine parameters for testing; (d) the computing device instructing the neural network to apply the neural network operations to the test image by using each of the parameters for testing, to thereby generate one or more neural network outputs."
557,16254500,2019.01.22,,,10339424,2019.07.02,10339424,2019.07.02,Method and device of neural network operations using a grid generator for converting modes according to classes of areas to satisfy level 4 of autonomous vehicles,"G06K9/00,G06K9/62,G06N3/04,G06N7/00,G06T7/70,G06N3/08","Stradvision, Inc.","A method of neural network operations by using a grid generator is provided for converting modes according to classes of areas to satisfy level 4 of autonomous vehicles. The method includes steps of: a computing device (a) instructing a detector to acquire object location information for testing and class information; (b) instructing the grid generator to generate section information by referring to the object location information for testing; (c) instructing a neural network to determine parameters for testing, to be used for applying the neural network operations to either (i) the subsections including each of the objects for testing and each of non-objects for testing, or (ii) each of sub-regions, in each of the subsections, where said each of the non-objects for testing is located; and (d) instructing the neural network to apply the neural network operations to the test image for testing to thereby generate neural network outputs."
558,16255339,2019.01.23,,,10311578,2019.06.04,10311578,2019.06.04,"Learning method and learning device for segmenting an image having one or more lanes by using embedding loss to support collaboration with HD maps required to satisfy level 4 of autonomous vehicles and softmax loss, and testing method and testing device using the same","G06K7/14,G06T7/143","Stradvision, inc.","A learning method for segmenting an image having one or more lanes is provided to be used for supporting collaboration with HD maps required to satisfy level 4 of autonomous vehicles. The learning method includes steps of: a learning device instructing a CNN module (a) to apply convolution operations to the image, thereby generating a feature map, and apply deconvolution operations thereto, thereby generating segmentation scores of each of pixels on the image; (b) to apply Softmax operations to the segmentation scores, thereby generating Softmax scores; and (c) to (I) apply multinomial logistic loss operations and pixel embedding operations to the Softmax scores, thereby generating Softmax losses and embedding losses, where the embedding losses is used to increase inter-lane differences among averages of the segmentation scores and decrease intra-lane variances among the segmentation scores, in learning parameters of the CNN module, and (II) backpropagate the Softmax and the embedding losses."
559,16254525,2019.01.22,,,10311336,2019.06.04,10311336,2019.06.04,Method and device of neural network operations using a grid generator for converting modes according to classes of areas to satisfy level 4 of autonomous vehicles,"G06K9/62,G06N3/08,G06N3/04,G06T7/70,G06K9/00","Stradvision, Inc.",A method of neural network operations by using a grid generator is provided for converting modes according to classes of areas to satisfy level 4 of autonomous vehicles. The method includes steps of: (a) a computing device instructing a pair detector to acquire information on locations and classes of pairs for testing by detecting the pairs for testing; (b) the computing device instructing the grid generator to generate section information by referring to the information on the locations of the pairs for testing; (c) the computing device instructing a neural network to determine parameters for testing by referring to parameters for training which have been learned by using information on pairs for training; and (d) the computing device instructing the neural network to apply the neural network operations to a test image by using each of the parameters for testing to thereby generate one or more neural network outputs.
560,16871346,2020.05.11,,,11443288,2022.09.13,11443288,2022.09.13,Automatic assessment of damage and repair costs in vehicles,"G06Q40/08,G06Q10/00,G06T7/00,G06T7/11,G06T7/143,G06T7/33,G06K9/62,G06V10/44,G06V10/46,G06V20/20,G06F3/04842,G06Q30/02,G06T7/40,G06T19/00,G06T7/194","American International Group, Inc.","A system and method are provided for automatically estimating a repair cost for a vehicle. A method includes: receiving, at a server computing device over an electronic network, one or more images of a damaged vehicle from a client computing device; performing image processing operations on each of the one or more images to detect external damage to a first set of parts of the vehicle; inferring internal damage to a second set of parts of the vehicle based on the detected external damage; and, calculating an estimated repair cost for the vehicle based on the detected external damage and inferred internal damage based on accessing a parts database that includes repair and labor costs for each part in the first and second sets of parts."
561,17069765,2020.10.13,20210142080,2021.05.13,20210142080,2021.05.13,,,DETECTION OF UNSAFE CABIN CONDITIONS IN AUTONOMOUS VEHICLES,"G06K9/00,G06N3/04,G06N3/08,G06K9/62,G08B25/10,H04W4/44,B60Q9/00,B60R22/48","Alpine Electronics of Silicon Valley, Inc.","Devices, systems and processes for the detection of unsafe cabin conditions that provides a safer passenger experience in autonomous vehicles are described. One example method for enhancing passenger safety includes capturing at least a set of images of one or more passengers in the vehicle, determining, based on the set of images, the occurrence of an unsafe activity in an interior of the vehicle, performing, using a neural network, a classification of the unsafe activity, and performing, based on the classification, one or more responsive actions."
562,16657575,2019.10.18,,,10803334,2020.10.13,10803334,2020.10.13,Detection of unsafe cabin conditions in autonomous vehicles,"G06N3/04,G06N3/08,G06K9/62,G08B25/10,B60Q9/00,G06K9/00,H04W4/44,B60R22/48","Alpine Electronics of Silicon Valley, Inc.","Devices, systems and processes for the detection of unsafe cabin conditions that provides a safer passenger experience in autonomous vehicles are described. One example method for enhancing passenger safety includes capturing at least a set of images of one or more passengers in the vehicle, determining, based on the set of images, the occurrence of an unsafe activity in an interior of the vehicle, performing, using a neural network, a classification of the unsafe activity, and performing, based on the classification, one or more responsive actions."
563,16871346,2020.05.11,20200273001,2020.08.27,20200273001,2020.08.27,,,AUTOMATIC ASSESSMENT OF DAMAGE AND REPAIR COSTS IN VEHICLES,"G06Q10/00,G06K9/00,G06T7/00,G06T7/11,G06T7/143,G06T7/33,G06K9/46,G06K9/62,G06F3/0484,G06Q30/02,G06Q40/08,G06T7/40,G06T19/00","American International Group, Inc.","A system and method are provided for automatically estimating a repair cost for a vehicle. A method includes: receiving, at a server computing device over an electronic network, one or more images of a damaged vehicle from a client computing device; performing image processing operations on each of the one or more images to detect external damage to a first set of parts of the vehicle; inferring internal damage to a second set of parts of the vehicle based on the detected external damage; and, calculating an estimated repair cost for the vehicle based on the detected external damage and inferred internal damage based on accessing a parts database that includes repair and labor costs for each part in the first and second sets of parts."
564,17021207,2020.09.15,20220081000,2022.03.17,20220081000,2022.03.17,,,HYBRID PLANNING SYSTEM FOR AUTONOMOUS VEHICLES,"B60W60/00,G01C21/34,B60W30/095,B60W30/18,G01C21/00,G06N3/08",Baidu USA LLC,"In one embodiment, a system/method generates a driving trajectory for an autonomous driving vehicle (ADV). The system perceives an environment of an autonomous driving vehicle (ADV). The system determines one or more bounding conditions based on the perceived environment. The system generates a first trajectory using a neural network model, wherein the neural network model is trained to generate a driving trajectory. The system evaluates/determines if the first trajectory satisfies the one or more bounding conditions. If the first trajectory satisfies the one or more bounding conditions, the system controls the ADV autonomously according to the first trajectory. Otherwise, the system controls the ADV autonomously according to a second trajectory, where the second trajectory is generated based on an objective function, where the objective function is determined based on at least the one or more bounding conditions."
565,17397461,2021.08.09,20220024473,2022.01.27,20220024473,2022.01.27,,,Generating Testing Instances for Autonomous Vehicles,"B60W50/04,G07C5/08,B60W60/00","Aurora Innovation, Inc.","Sensor data collected from an autonomous vehicle can be labeled using sensor data collected from an additional vehicle. Labeled sensor data can generate targeted testing instances for a trained machine learning model, where the trained machine learning model is used in generating control signals for an autonomous vehicle. In many implementations, targeted training instances can generate an accuracy value for the trained neural network model. Additionally or alternatively, the sensor suite on the additional vehicle can include a removable hardware pod which can be mounted on a variety of vehicles."
566,16271401,2019.02.08,,,11086319,2021.08.10,11086319,2021.08.10,Generating testing instances for autonomous vehicles,"G05D1/00,G05D1/02,G05B13/02","Aurora Innovation, Inc.","Sensor data collected from an autonomous vehicle can be labeled using sensor data collected from an additional vehicle. Labeled sensor data can generate targeted testing instances for a trained machine learning model, where the trained machine learning model is used in generating control signals for an autonomous vehicle. In many implementations, targeted training instances can generate an accuracy value for the trained neural network model. Additionally or alternatively, the sensor suite on the additional vehicle can include a removable hardware pod which can be mounted on a variety of vehicles."
567,16740109,2020.01.10,20200326715,2020.10.15,20200326715,2020.10.15,,,SAFETY SYSTEM FOR AUTONOMOUS OPERATION OF OFF-ROAD AND AGRICULTURAL VEHICLES USING MACHINE LEARNING FOR DETECTION AND IDENTIFICATION OF OBSTACLES,"G05D1/02,G05D1/00,B60W10/20,B60W10/18,B60W10/04,B60W10/10,G06K9/00,G06K9/62,G06N20/00","Raven Industries, Inc.","A framework for safely operating autonomous machinery, such as vehicles and other heavy equipment, in an in-field or off-road environment, includes detecting, identifying, classifying and tracking objects and/or terrain characteristics from on-board sensors that capture images in front and around the autonomous machinery as it performs agricultural or other activities. The framework generates commands for navigational control of the autonomous machinery in response to perceived objects and terrain impacting safe operation. The framework processes image data and range data in multiple fields of view around the autonomous equipment to discern objects and terrain, and applies artificial intelligence techniques in one or more neural networks to accurately interpret this data for enabling such safe operation."
568,16271401,2019.02.08,20200142409,2020.05.07,20200142409,2020.05.07,,,Generating Testing Instances for Autonomous Vehicles,"G05D1/00,G05D1/02,G05B13/02","Aurora Innovation, Inc.","Sensor data collected from an autonomous vehicle can be labeled using sensor data collected from an additional vehicle. Labeled sensor data can generate targeted testing instances for a trained machine learning model, where the trained machine learning model is used in generating control signals for an autonomous vehicle. In many implementations, targeted training instances can generate an accuracy value for the trained neural network model. Additionally or alternatively, the sensor suite on the additional vehicle can include a removable hardware pod which can be mounted on a variety of vehicles."
569,16541739,2019.08.15,20200159225,2020.05.21,20200159225,2020.05.21,,,End-To-End Interpretable Motion Planner for Autonomous Vehicles,"G05D1/02,G05D1/00,G01C21/34,G01C21/32","Uber Technologies, Inc.",Systems and methods for generating motion plans including target trajectories for autonomous vehicles are provided. An autonomous vehicle may include or access a machine-learned motion planning model including a backbone network configured to generate a cost volume including data indicative of a cost associated with future locations of the autonomous vehicle. The cost volume can be generated from raw sensor data as part of motion planning for the autonomous vehicle. The backbone network can generate intermediate representations associated with object detections and objection predictions. The motion planning model can include a trajectory generator configured to evaluate one or more potential trajectories for the autonomous vehicle and to select a target trajectory based at least in part on the cost volume generate by the backbone network.
570,16984972,2020.08.04,20220215508,2022.07.07,20220215508,2022.07.07,,,SUPER-RESOLUTION RADAR FOR AUTONOMOUS VEHICLES,"G06T3/40,G06T3/60,G06T5/50,G01S13/89,G01S17/89,G06N3/08,G06N20/00,G06K9/00",Metawave Corporation,Examples disclosed herein relate to an autonomous driving system in an vehicle. The autonomous driving system includes a radar system configured to detect a target in a path and a surrounding environment of the vehicle and produce radar data with a first resolution that is gathered over a continuous field of view on the detected target. The system includes a super-resolution network configured to receive the radar data with the first resolution and produce radar data with a second resolution different from the first resolution using first neural networks. The system also includes a target identification module configured to receive the radar data with the second resolution and to identify the detected target from the radar data with the second resolution using second neural networks. Other examples disclosed herein include a method of operating the radar system in the autonomous driving system of the vehicle.
571,16984972,2020.08.04,20220044359,2022.02.10,20220044359,2022.02.10,,,SUPER-RESOLUTION RADAR FOR AUTONOMOUS VEHICLES,"G06T3/40,G06T3/60,G06T5/50,G01S13/89,G01S17/89,G06N3/08,G06N20/00,G06K9/00",Metawave Corporation,Examples disclosed herein relate to an autonomous driving system in an vehicle. The autonomous driving system includes a radar system configured to detect a target in a path and a surrounding environment of the vehicle and produce radar data with a first resolution that is gathered over a continuous field of view on the detected target. The system includes a super-resolution network configured to receive the radar data with the first resolution and produce radar data with a second resolution different from the first resolution using first neural networks. The system also includes a target identification module configured to receive the radar data with the second resolution and to identify the detected target from the radar data with the second resolution using second neural networks. Other examples disclosed herein include a method of operating the radar system in the autonomous driving system of the vehicle.
572,16530961,2019.08.02,,,11378654,2022.07.05,11378654,2022.07.05,Recurrent super-resolution radar for autonomous vehicles,"G01S7/40,G01S13/931,G01S7/41,G01S13/86",Metawave Corporation,Examples disclosed herein relate to an autonomous driving system in an ego vehicle. The autonomous driving system includes a radar system to detect a target in a path and a surrounding environment of the ego vehicle and produce radar data with a first resolution that is gathered over a continuous field of view on the detected target. The system includes a recurrent super-resolution network having recurrent encoder layers to receive the radar data with the first resolution and produce radar data with a second resolution using first neural networks. The recurrent encoder layers perform recurrence operations prior to a max pooling operation. The radar data with the second resolution may be produced from at least an output of the recurrent encoder layers. Other examples disclosed herein include a method of operating the radar system in the autonomous driving system of the ego vehicle.
573,16927422,2020.07.13,20220012507,2022.01.13,20220012507,2022.01.13,,,SYSTEM AND METHOD FOR RECOGNIZING INTERSECTION BY AUTONOMOUS VEHICLES,"G06K9/00,G06N3/04,B60W30/18","Beijing Jingdong Qianshi Technology Co., Ltd.,JD.com American Technologies Corporation","A system and method for autonomous navigation. The system includes a computing device having a processor and a storage device storing computer executable code. The computer executable code, when executed at the processor, is configured to: provide a planned path having intersections in an environment, where the intersections and roads therebetween are represented by sequential place identifications (IDs); receive images of the environment; perform convolutional neural network on the images to obtain predicted place IDs; when a predicted place ID of a current image is next to a place ID of a previous image, and is the same as predicted place IDs of a predetermined number of following images, define the predicted place ID as place IDs of the current and the following images; and perform autonomous navigation based on the planned path and the image place IDs."
574,17170173,2021.02.08,20210177261,2021.06.17,20210177261,2021.06.17,,,"SYSTEM, METHOD, AND COMPUTER-ACCESSIBLE MEDIUM FOR MAGNETIC RESONANCE VALUE DRIVEN AUTONOMOUS SCANNER","A61B5/00,A61B5/055,A61B6/03,G01R33/561,G16H40/67,G16H30/20,G16H30/40,G16H50/20,G16H50/50,G16H50/70,G16H15/00,G06N3/08,H04L29/06",The Trustees of Columbia University in the City of New York,"Exemplary system, method and computer-accessible medium for remotely initiating a medical imaging scan(s) of a patient(s), can include, for example, receiving, over a network, encrypted first information related to first parameters of the patient(s), determining second information related to image acquisition second parameters based on the first information, generating an imaging sequence(s) based on the second information, and initiating, remotely from the patient(s), the medical imaging scan(s) based on the imaging sequence(s). The medical imaging scan(s) can be a magnetic resonance imaging (“MRI”) sequence(s). The image acquisition second parameters can be MRI acquisition parameters, and the imaging sequence(s) can be a gradient recalled echo (“GRE”) pulse sequence(s)."
575,17081202,2020.10.27,20210133500,2021.05.06,20210133500,2021.05.06,,,Generating Training Datasets for Training Machine Learning Based Models for Predicting Behavior of Traffic Entities for Navigating Autonomous Vehicles,"G06K9/62,G06K9/00,G06N20/00,B60W60/00,B60W30/095",Perceptive Automata Inc.,"A vehicle collects video data of an environment surrounding the vehicle including traffic entities, e.g., pedestrians, bicyclists, or other vehicles. The captured video data is sampled and the sampled video frames are presented to users to provide input on a traffic entity's state of mind. The system determines an attribute value that describes a statistical distribution of user responses for the traffic entity. If the attribute for a sampled video frame is within a threshold of the attribute of another video frame, the system interpolates attribute for a third video frame between the two sampled video frames. Otherwise, the system requests further user input for a video frame captured between the two sampled video frames. The interpolated and/or user based attributes are used to train a machine learning based model that predicts a hidden context of the traffic entity. The trained model is used for navigation of autonomous vehicles."
576,17081211,2020.10.27,20210133497,2021.05.06,20210133497,2021.05.06,,,Adaptive Sampling of Stimuli for Training of Machine Learning Based Models for Predicting Hidden Context of Traffic Entities For Navigating Autonomous Vehicles,"G06K9/62,G08G1/01,G06K9/00,G06N20/00,G05D1/02",Perceptive Automata Inc.,"A vehicle collects video data of an environment surrounding the vehicle including traffic entities, e.g., pedestrians, bicyclists, or other vehicles. The captured video data is sampled and presented to users to provide input on a traffic entity's state of mind. The user responses on the captured video data is used to generate a training dataset. A machine learning based model configured to predict a traffic entity's state of mind is trained with the training dataset. The system determines input video frames and associated dimension attributes for which the model performs poorly. The dimension attributes characterize stimuli and/or an environment shown in the input video frames. The system generates a second training dataset based on video frames that have the dimension attributes for which the model performed poorly. The model is retrained using the second training dataset and provided to an autonomous vehicle to assist with navigation in traffic."
577,16822619,2020.03.18,20210080956,2021.03.18,20210080956,2021.03.18,,,BEHAVIOR CONTROL DEVICE AND BEHAVIOR CONTROL METHOD FOR AUTONOMOUS VEHICLES,"G05D1/00,B62D15/02,G05D1/02,G06N3/08","HYUNDAI MOTOR COMPANY,KIA MOTORS CORPORATION,HYUNDAI MOTOR COMPANY,KIA MOTORS CORPORATION",A behavior control device and a behavior control method for an autonomous vehicle are provided. The behavior control device includes a learning device configured to perform deep learning of a behavior pattern of a vehicle according to a driving environment and a controller configured to control a behavior of the autonomous vehicle based on a result of the learning of the learning device.
578,16447032,2019.06.20,20190391235,2019.12.26,10739438,2020.08.11,10739438,2020.08.11,Super-resolution radar for autonomous vehicles,"G01S7/41,G01S7/03,G01S7/40,H01Q1/32,H01Q1/36,G01S13/86",Metawave Corporation,Examples disclosed herein relate to an autonomous driving system in an ego vehicle. The autonomous driving system includes a radar system configured to detect a target in a path and a surrounding environment of the ego vehicle and produce radar data with a first resolution that is gathered over a continuous field of view on the detected target. The system includes a super-resolution network configured to receive the radar data with the first resolution and produce radar data with a second resolution different from the first resolution using first neural networks. The system also includes a target identification module configured to receive the radar data with the second resolution and to identify the detected target from the radar data with the second resolution using second neural networks. Other examples disclosed herein include a method of operating the radar system in the autonomous driving system of the ego vehicle.
579,16701669,2019.12.03,20200175401,2020.06.04,20200175401,2020.06.04,,,MACHINE LEARNING MODELS OPERATING AT DIFFERENT FREQUENCIES FOR AUTONOMOUS VEHICLES,"G06N5/04,G06N20/00","Tesla, Inc.","Systems and methods include machine learning models operating at different frequencies. An example method includes obtaining images at a threshold frequency from one or more image sensors positioned about a vehicle. Location information associated with objects classified in the images is determined based on the images. The images are analyzed via a first machine learning model at the threshold frequency. For a subset of the images, the first machine learning model uses output information from a second machine learning model, the second machine learning model being performed at less than the threshold frequency."
580,16530961,2019.08.02,20200041612,2020.02.06,20200041612,2020.02.06,,,RECURRENT SUPER-RESOLUTION RADAR FOR AUTONOMOUS VEHICLES,"G01S7/41,G01S13/86,G01S13/93,G01S7/40",Metawave Corporation,Examples disclosed herein relate to an autonomous driving system in an ego vehicle. The autonomous driving system includes a radar system to detect a target in a path and a surrounding environment of the ego vehicle and produce radar data with a first resolution that is gathered over a continuous field of view on the detected target. The system includes a recurrent super-resolution network having recurrent encoder layers to receive the radar data with the first resolution and produce radar data with a second resolution using first neural networks. The recurrent encoder layers perform recurrence operations prior to a max pooling operation. The radar data with the second resolution may be produced from at least an output of the recurrent encoder layers. Other examples disclosed herein include a method of operating the radar system in the autonomous driving system of the ego vehicle.
581,17359421,2021.06.25,,,11346086,2022.05.31,11346086,2022.05.31,Machine learning for optimizing tool path planning in autonomous earth moving vehicles,"E02F9/26,G06N20/00,E02F9/20,G05D1/02,E02F3/84",Built Robotics Inc.,"An autonomous earth moving system can select an action for an earth moving vehicle (EMV) to autonomously perform using a tool (such as an excavator bucket). The system then generates a set of candidate tool paths, each illustrating a potential path for the tool to trace as the earth moving vehicle performs the action. In some cases, the system uses an online learning model iteratively trained to determine which candidate tool path best satisfies one or more metrics measuring the success of the action. The earth moving vehicle the executes the earth moving action using the selected tool path and measures the results of the action. In some implementations, the autonomous earth moving system updates the machine learning model based on the result of the executed action."
582,17359432,2021.06.25,,,11352769,2022.06.07,11352769,2022.06.07,Online machine learning for calibration of autonomous earth moving vehicles,"E02F9/26,G06N3/08,G05D1/00",Built Robotics Inc.,"In some implementations, the EMV uses a calibration to inform autonomous control over the EMV. To calibrate an EMV, the system first selects a calibration action comprising a control signal for actuating a control surface of the EMV. Then, using a calibration model comprising a machine learning model trained based on one or more previous calibration actions taken by the EMV, the system predicts a response of the control surface to the control signal of the calibration action. After the EMV executes the control signal to perform the calibration action, the EMV system monitors the actual response of the control signal and uses that to update the calibration model based on a comparison between the predicted and monitored states of the control surface."
583,17280529,2019.09.26,20220043454,2022.02.10,20220043454,2022.02.10,,,METHODS AND SYSTEMS FOR NAVIGATING AUTONOMOUS AND SEMI-AUTONOMOUS VEHICLES,"G05D1/02,G06K9/00,G06K9/62,G06N3/02","EmergeX, LLC,EmergeX, LLC","A system and method for forecasting perceived transitions to the four annual seasons in geographic areas is disclosed. The perceived transitions are identified by comparing forecasted daily temperatures in each geographic area to thresholds generated based on normal daily temperatures in those geographic areas. The forecasted daily temperatures may be calculated using both forecasted temperatures and forecasted perceived ambient temperatures (calculated using both temperature and humidity, cloud cover, sun intensity, and/or wind speed)."
584,16584566,2019.09.26,,,11300965,2022.04.12,11300965,2022.04.12,Methods and systems for navigating autonomous and semi-autonomous vehicles,"G06N3/04,G06N3/08,G05D1/02,G06K9/62,G05D1/00","EmergeX, LLC","Methods and systems are disclosed for an improved control system in autonomous and semi-autonomous vehicles. More specifically, the methods and systems relate to powering control systems of autonomous and semi-autonomous vehicles through the use of computer vision based on delta images (i.e., delta-vision)."
585,17516159,2021.11.01,20220051035,2022.02.17,20220051035,2022.02.17,,,Object Detection and Property Determination for Autonomous Vehicles,"G06K9/00,G05D1/00,G06K9/62,G06N3/02","UATC, LLC","Systems, methods, tangible non-transitory computer-readable media, and devices for detecting objects are provided. For example, the disclosed technology can obtain a representation of sensor data associated with an environment surrounding a vehicle. Further, the sensor data can include sensor data points. A point classification and point property estimation can be determined for each of the sensor data points and a portion of the sensor data points can be clustered into an object instance based on the point classification and point property estimation for each of the sensor data points. A collection of point classifications and point property estimations can be determined for the portion of the sensor data points clustered into the object instance. Furthermore, object instance property estimations for the object instance can be determined based on the collection of point classifications and point property estimations for the portion of the sensor data points clustered into the object instance."
586,16266713,2019.02.04,,,11189171,2021.11.30,11189171,2021.11.30,Traffic prediction with reparameterized pushforward policy for autonomous vehicles,"G08G1/16,G08G1/01,G06N7/00,G06N3/08,G06N20/00,G06N5/04","NEC Laboratories America, Inc.",Systems and methods for vehicle behavior prediction include an imaging device that captures images of a vehicle in traffic. A processing device including policy stored in a memory of the processing device in communication with the imaging device stochastically models future behavior of the vehicle based on the captured images. A policy simulator in communication with the processing device simulates the policy as a reparameterized pushforward policy of a base distribution. An evaluator receives the simulated policy from the policy simulator and performs cross-entropy optimization on the future behavior of the vehicle by analyzing the simulated policy and updating the policy according to cross-entropy error. An alert system retrieves the future behavior of the vehicle and recognizes hazardous trajectories of the future trajectories and generates an audible alert using a speaker.
587,16828823,2020.03.24,,,11126889,2021.09.21,11126889,2021.09.21,Machine learning based prediction of human interactions with autonomous vehicles,"G06K9/00,G06K9/62,G06N3/08,G06N3/04,G08G1/16,G08G1/04,G05D1/00,B60W30/00,G06N5/00,G06N20/10",Perceptive Automata Inc.,"Systems and methods for predicting user interaction with vehicles. A computing device receives an image and a video segment of a road scene, the first at least one of an image and a video segment being taken from a perspective of a participant in the road scene and then generates stimulus data based on the image and the video segment. Stimulus data is transmitted to a user interface and response data is received, which includes at least one of an action and a likelihood of the action corresponding to another participant in the road scene. The computing device aggregates a subset of the plurality of response data to form statistical data and a model is created based on the statistical data. The model is applied to another image or video segment and a prediction of user behavior in the another image or video segment is generated."
588,16584566,2019.09.26,20200103909,2020.04.02,20200103909,2020.04.02,,,METHODS AND SYSTEMS FOR NAVIGATING AUTONOMOUS AND SEMI-AUTONOMOUS VEHICLES,"G05D1/02,G06K9/62,G05D1/00,G06N3/08,G06N3/04","EmergeX, LLC,EmergeX, LLC","Methods and systems are disclosed for an improved control system in autonomous and semi-autonomous vehicles. More specifically, the methods and systems relate to powering control systems of autonomous and semi-autonomous vehicles through the use of computer vision based on delta images (i.e., delta-vision)."
589,16266713,2019.02.04,20190287404,2019.09.19,20190287404,2019.09.19,,,TRAFFIC PREDICTION WITH REPARAMETERIZED PUSHFORWARD POLICY FOR AUTONOMOUS VEHICLES,"G08G1/16,G08G1/01,G06N5/04,G06N3/08,G06N20/00,G06N7/00","NEC Laboratories America, Inc.",Systems and methods for vehicle behavior prediction include an imaging device that captures images of a vehicle in traffic. A processing device including policy stored in a memory of the processing device in communication with the imaging device stochastically models future behavior of the vehicle based on the captured images. A policy simulator in communication with the processing device simulates the policy as a reparameterized pushforward policy of a base distribution. An evaluator receives the simulated policy from the policy simulator and performs cross-entropy optimization on the future behavior of the vehicle by analyzing the simulated policy and updating the policy according to cross-entropy error. An alert system retrieves the future behavior of the vehicle and recognizes hazardous trajectories of the future trajectories and generates an audible alert using a speaker.
590,17568544,2022.01.04,20220215378,2022.07.07,20220215378,2022.07.07,,,ARTIFICIAL INTELLIGENCE BASED METHODS AND SYSTEMS FOR FACILITATING PAYMENT AUTHORIZATIONS IN AUTONOMOUS VEHICLES,"G06Q20/32,G07C5/08,G06N3/08","MASTERCARD INTERNATIONAL INCORPORATED,,MASTERCARD INTERNATIONAL INCORPORATED,","Embodiments provide electronic methods and systems for facilitating payment authorization for payment transactions initiated from an on-board device of an autonomous vehicle. The method performed by a server system includes receiving payment transaction request initiated from on-board device positioned in autonomous vehicle. The method further includes accessing authentication parameters received from on-board device, wherein authentication parameters include multisensory data captured using sensors positioned in autonomous vehicle, and generating authentication features based on authentication parameters and neural network models. The neural network models are trained based on historical multisensory data of one or more autonomous vehicles. The method includes determining one or more authentication scores associated with the payment transaction request based on the authentication features and transmitting the one or more authentication scores along with the payment transaction request to an issuer associated with the user for authorization."
591,16816942,2020.03.12,,,11403492,2022.08.02,11403492,2022.08.02,Generating labeled training instances for autonomous vehicles,"G06N3/08,B60W60/00,G06K9/62,G05D1/00,G06V20/56,G06K9/00","Aurora Innovation, Inc.","In techniques disclosed herein, machine learning models can be utilized in the control of autonomous vehicle(s), where the machine learning models are trained using automatically generated training instances. In some such implementations, a label corresponding to an object in a labeled instance of training data can be mapped to the corresponding instance of unlabeled training data. For example, an instance of sensor data can be captured using one or more sensors of a first sensor suite of a first vehicle can be labeled. The label(s) can be mapped to an instance of data captured using one or more sensors of a second sensor suite of a second vehicle."
592,16927312,2020.07.13,20220012939,2022.01.13,20220012939,2022.01.13,,,PROVISIONING REAL-TIME THREE-DIMENSIONAL MAPS FOR AUTONOMOUS VEHICLES,"G06T15/20,G06T17/05,G06K9/00,G06T7/70,G05D1/02","Fujitsu Limited,Fujitsu Limited","Systems and methods for provisioning real-time three-dimensional maps, including: at a first processing stage: updating a three-dimensional map of an environment based on received point cloud data; extracting three-dimensional proposals of objects of the environment; projecting the three-dimensional proposals onto a two-dimensional image of the environment; generating two-dimensional proposals of the objects of the environment; at a second processing stage: detecting the objects of the environment from the two-dimensional image of the environment; generating two-dimensional bounding boxes of the objects of the environment; matching the two-dimensional bounding box with a particular two-dimensional proposal of the two-dimensional proposals; and labeling, for each two-dimensional proposal that is matched to a two-dimensional bounding box, the three-dimensional proposal corresponding to the two-dimensional proposal with semantic information associated with the two-dimensional bounding box that is matched to the two-dimensional proposal to update the three-dimensional map."
593,17321297,2021.05.14,20210357662,2021.11.18,20210357662,2021.11.18,,,GROUND TRUTH BASED METRICS FOR EVALUATION OF MACHINE LEARNING BASED MODELS FOR PREDICTING ATTRIBUTES OF TRAFFIC ENTITIES FOR NAVIGATING AUTONOMOUS VEHICLES,"G06K9/00,B60W60/00,G06N3/08","Perceptive Automata, Inc.","A system uses a machine learning based model to determine attributes describing states of mind and behavior of traffic entities in video frames captured by an autonomous vehicle. The system classifies video frames according to traffic scenarios depicted, where each scenario is associated with a filter based on vehicle attributes, traffic attributes, and road attributes. The system identifies a set of video frames associated with ground truth scenarios for validating the accuracy of the machine learning based model and predicts attributes of traffic entities in the video frames. The system analyzes video frames captured after the set of video frames to determine actual attributes of the traffic entities. Based on a comparison of the predicted attributes and actual attributes, the system determines a likelihood of the machine learning based model making accurate predictions and uses the likelihood to generate a navigation action table for controlling the autonomous vehicle."
594,17321253,2021.05.14,20210354730,2021.11.18,20210354730,2021.11.18,,,NAVIGATION OF AUTONOMOUS VEHICLES USING TURN AWARE MACHINE LEARNING BASED MODELS FOR PREDICTION OF BEHAVIOR OF A TRAFFIC ENTITY,"B60W60/00,B60W40/04,G06N3/08,G06K9/00","Perceptive Automata, Inc.","An autonomous vehicle collects sensor data of an environment surrounding the autonomous vehicle including traffic entities such as pedestrians, bicyclists, or other vehicles. The sensor data is provided to a machine learning based model along with an expected turn direction of the autonomous vehicle to determine a hidden context attribute of a traffic entity given the expected turn direction of the autonomous vehicle. The hidden context attribute of the traffic entity represents factors that affect the behavior of the traffic entity, and the hidden context attribute is used to predict future behavior of the traffic entity. Instructions to control the autonomous vehicle are generated based on the hidden context attribute."
595,17155057,2021.01.21,20210226790,2021.07.22,20210226790,2021.07.22,,,Method for Sharing Models among Autonomous Vehicles Based on Blockchain,"H04L9/30,H04W4/44,G06N3/08,H04L9/08",XIDIAN UNIVERSITY,"The present disclosure discloses a method for sharing models among autonomous vehicles based on a blockchain, the method comprising the steps of: 1) creating a mobile edge computing network; 2) generating a key pair for each node in the mobile edge computing network; 3) creating a local model set of a mobile node set in the mobile node computing network; 4) enabling each mobile node to communicate with a corresponding nearest mobile edge computing node; 5) creating supernode sequences by the mobile edge computing node; 6) creating a blockchain based on the supernode sequences; and 7) updating the local model set."
596,16816942,2020.03.12,20200210777,2020.07.02,20200210777,2020.07.02,,,Generating Labeled Training Instances for Autonomous Vehicles,"G06K9/62,G06K9/00,G06N3/08,B60W60/00,G05D1/00","Aurora Innovation, Inc.","In techniques disclosed herein, machine learning models can be utilized in the control of autonomous vehicle(s), where the machine learning models are trained using automatically generated training instances. In some such implementations, a label corresponding to an object in a labeled instance of training data can be mapped to the corresponding instance of unlabeled training data. For example, an instance of sensor data can be captured using one or more sensors of a first sensor suite of a first vehicle can be labeled. The label(s) can be mapped to an instance of data captured using one or more sensors of a second sensor suite of a second vehicle."
597,17199583,2021.03.12,20220292310,2022.09.15,20220292310,2022.09.15,,,METHOD AND SYSTEM FOR A FAST ADAPTATION FOR IMAGE SEGMENTATION FOR AUTONOMOUS EDGE VEHICLES,"G06K9/62,G06F16/55,G06N3/08,G06N3/04",EMC IP Holding Company LLC,"A method includes obtaining, by a local data system manager of a local data system of the local data systems, a portion of unlabeled data from a local data source, performing, using a domain classifier in the local data system manager, a domain classification analysis on the portion of the unlabeled data to identify a domain of the unlabeled data, making a first determination, based on the domain classification, that the domain classification has significantly varied from a previous domain, based on the first determination: performing an adaptive procedure on a local data system image segmentation model to obtain an adapted image segmentation model, and performing a domain reclassification on the domain classifier to obtain an updated domain classifier, and implementing the adapted image segmentation model on the local data system."
598,16777673,2020.01.30,20200239026,2020.07.30,20200239026,2020.07.30,,,NAVIGATING AUTONOMOUS VEHICLES BASED ON MODULATION OF A WORLD MODEL REPRESENTING TRAFFIC ENTITIES,"B60W60/00,G05D1/02","Perceptive Automata, Inc.","An autonomous vehicle uses machine learning based models to predict hidden context attributes associated with traffic entities. The system uses the hidden context to predict behavior of people near a vehicle in a way that more closely resembles how human drivers would judge the behavior. The system determines an activation threshold value for a braking system of the autonomous vehicle based on the hidden context. The system modifies a world model based on the hidden context predicted by the machine learning based model. The autonomous vehicle is safely navigated, such that the vehicle stays at least a threshold distance away from traffic entities."
599,17832189,2022.06.03,20220301069,2022.09.22,20220301069,2022.09.22,,,SYSTEMS AND METHODS FOR ALLOCATING FAULT TO AUTONOMOUS VEHICLES,"G06Q40/08,G07C5/08,G07C5/02,G05D1/00,G01C21/28,G01W1/00",State Farm Mutual Automobile Insurance Company,"In one aspect, a system for allocating fault in a collision involving a vehicle is provided. The system may include (1) a sensor coupled to the vehicle and configured to collect contextual data related to the collision, (2) a non-transitory memory configured to store the contextual data, and (3) a processor coupled to the non-transitory memory and configured to (a) gain access to the contextual data, and (b) compute and assign a fault percentage to a driver of the vehicle based upon the contextual data."
600,17729802,2022.04.26,20220254202,2022.08.11,20220254202,2022.08.11,,,Data Recorders of Autonomous Vehicles,"G07C5/08,B60R21/0134,B60W50/02,B60R21/0136","Micron Technology, Inc.","Systems, methods and apparatus to collect sensor data generated in an autonomous vehicle. Sensors of the vehicle generate a sensor data stream that is buffered, in parallel and in a cyclic way, in a first cyclic buffer and a larger second cyclic buffer respectively. An advanced driver assistance system of the vehicle generates an accident signal when detecting or predicting an accident and provides a training signal when detecting a fault in object detection, recognition, identification or classification. The accident signal causes a sensor data stream segment to be copied from the first cyclic buffer into a slot of a non-volatile memory, selected from a plurality of slots in a round robin way. The training signal causes a sensor data stream segment to be copied from the second cyclic buffer into an area of the non-volatile memory outside of the slots reserved for the first cyclic buffer."
601,17494165,2021.10.05,20220044427,2022.02.10,20220044427,2022.02.10,,,Object Association for Autonomous Vehicles,"G06T7/292,G06K9/00,G06N5/04,G06T7/70,G06N20/00","UATC, LLC","Systems, methods, tangible non-transitory computer-readable media, and devices for associating objects are provided. For example, the disclosed technology can receive sensor data associated with the detection of objects over time. An association dataset can be generated and can include information associated with object detections of the objects at a most recent time interval and object tracks of the objects at time intervals in the past. A subset of the association dataset including the object detections that satisfy some association subset criteria can be determined. Association scores for the object detections in the subset of the association dataset can be determined. Further, the object detections can be associated with the object tracks based on the association scores for each of the object detections in the subset of the association dataset that satisfy some association criteria."
602,17521464,2021.11.08,20220066461,2022.03.03,20220066461,2022.03.03,,,Autonomous Vehicles Featuring Machine-Learned Yield Model,"G05D1/02,G05D1/00,B60W30/095,B60W30/18","UATC, LLC","The present disclosure provides autonomous vehicle systems and methods that include or otherwise leverage a machine-learned yield model. In particular, the machine-learned yield model can be trained or otherwise configured to receive and process feature data descriptive of objects perceived by the autonomous vehicle and/or the surrounding environment and, in response to receipt of the feature data, provide yield decisions for the autonomous vehicle relative to the objects. For example, a yield decision for a first object can describe a yield behavior for the autonomous vehicle relative to the first object (e.g., yield to the first object or do not yield to the first object). Example objects include traffic signals, additional vehicles, or other objects. The motion of the autonomous vehicle can be controlled in accordance with the yield decisions provided by the machine-learned yield model."
603,16257647,2019.01.25,,,11237555,2022.02.01,11237555,2022.02.01,Backup control systems and methods for autonomous vehicles,"G05D1/00,G01S19/21,B60W50/14",State Farm Mutual Automobile Insurance Company,A backup control server for reducing dangers to automation systems of autonomous vehicles includes a memory and a processor. The processor is programmed to detect an anomalous event which may include one of a geomagnetic interference event and a cyber-attack event. The processor may also be programmed to perform a threat assessment for the anomalous event relative to an automation system of a vehicle. The automation system may be configured to control an aspect of autonomous operation of the vehicle. The processor may be further programmed to determine one or more mitigating actions to perform on the automation system based upon the threat assessment. The one or more mitigating actions are configured to reduce a danger to the vehicle presented by the anomalous event. The processor may also be programmed to transmit to the vehicle instructions to perform one or more mitigating actions on the automation system.
604,17719072,2022.04.12,20220237961,2022.07.28,20220237961,2022.07.28,,,SYSTEMS AND METHODS FOR DETECTING SOFTWARE INTERACTIONS FOR AUTONOMOUS VEHICLES WITHIN CHANGING ENVIRONMENTAL CONDITIONS,"G07C5/08,G07C5/00,G06N20/00",State Farm Mutual Automobile Insurance Company,"An interaction detection and analysis (“IDA”) computing device that includes at least one processor in communication with at least one memory device is provided. The at least one processor being configured to store software ecosystem data, environmental condition data, and performance data in a plurality of data records in a database, wherein each data record i) is associated with one autonomous vehicle (AV) of a plurality of AVs and ii) includes the software ecosystem data, the environmental condition data, and the performance data of the corresponding AV; apply at least one machine learning algorithm to a set of the plurality of data records to identify an interaction between at least one software application and at least one environmental condition resulting in a particular outcome; and transmit, to at least one AV associated with the set of data records, at least one alert message advising of the particular outcome."
605,17713782,2022.04.05,20220230026,2022.07.21,20220230026,2022.07.21,,,Generating Labeled Training Instances for Autonomous Vehicles,"G06K9/62,G06N3/08,B60W60/00,G05D1/00,G06V20/56","Aurora Operations, Inc.","In techniques disclosed herein, machine learning models can be utilized in the control of autonomous vehicle(s), where the machine learning models are trained using automatically generated training instances. In some such implementations, a label corresponding to an object in a labeled instance of training data can be mapped to the corresponding instance of unlabeled training data. For example, an instance of sensor data can be captured using one or more sensors of a first sensor suite of a first vehicle can be labeled. The label(s) can be mapped to an instance of data captured using one or more sensors of a second sensor suite of a second vehicle."
606,16263359,2019.01.31,,,11373466,2022.06.28,11373466,2022.06.28,Data recorders of autonomous vehicles,"G07C5/08,B60R21/0134,B60W50/02,B60R21/0136","Micron Technology, Inc.","Systems, methods and apparatus to collect sensor data generated in an autonomous vehicle. Sensors of the vehicle generate a sensor data stream that is buffered, in parallel and in a cyclic way, in a first cyclic buffer and a larger second cyclic buffer respectively. An advanced driver assistance system of the vehicle generates an accident signal when detecting or predicting an accident and provides a training signal when detecting a fault in object detection, recognition, identification or classification. The accident signal causes a sensor data stream segment to be copied from the first cyclic buffer into a slot of a non-volatile memory, selected from a plurality of slots in a round robin way. The training signal causes a sensor data stream segment to be copied from the second cyclic buffer into an area of the non-volatile memory outside of the slots reserved for the first cyclic buffer."
607,16376843,2019.04.05,,,11321972,2022.05.03,11321972,2022.05.03,Systems and methods for detecting software interactions for autonomous vehicles within changing environmental conditions,"G05D1/02,G07C5/08,G06N20/00,G07C5/00,H04L67/12",State Farm Mutual Automobile Insurance Company,"An interaction detection and analysis (“IDA”) computing device for aggregating and analyzing operations data from a plurality of autonomous vehicles (“AVs”) may be provided. The IDA computing device may include at least one processor programmed to (i) receive software ecosystem data, environmental conditions data, and performance data for a plurality of AVs, (ii) store the received data in a plurality of data records, (iii) apply at least one clustering algorithm to the plurality of data records to identify a subset of data records for AVs that have similar software ecosystems, and (iv) apply at least one machine learning algorithm to the identified subset of data records to detect i) an interaction between at least one software application and at least one environmental condition that may result in a particular outcome and ii) a correlation between the detected interaction and the particular outcome."
608,16271628,2019.02.08,,,11256263,2022.02.22,11256263,2022.02.22,Generating targeted training instances for autonomous vehicles,"G06N20/00,G06N3/08,G05D1/02,G06K9/00","Aurora Innovation, Inc.","Sensor data collected via an autonomous vehicle can be labeled using sensor data collected via an additional vehicle, such as a non-autonomous vehicle mounted with a vehicle agnostic removable hardware pod. A training instance can include an instance of data collected by an autonomous vehicle sensor suite and one or more corresponding labels."
609,16257624,2019.01.25,20220035371,2022.02.03,20220035371,2022.02.03,,,BACKUP CONTROL SYSTEMS AND METHODS FOR AUTONOMOUS VEHICLES,"G05D1/00,B60W50/14,G01S19/21",State Farm Mutual Automobile Insurance Company,"Dangers to autonomous vehicles may be reduced. A backup control computing device includes a memory and a processor. The processor is programmed to (1) receive an indication of an anomalous event, the anomalous event including one of a geomagnetic interference event and a cyber-attack event; (2) perform a threat assessment for the anomalous event relative to an automation system of a vehicle, the automation system is configured to control an aspect of autonomous operation of the vehicle; (3) determine one or more mitigating actions to perform on the automation system based upon the threat assessment, the one or more mitigating actions are configured to reduce a danger to the vehicle presented by the anomalous event; and (4) perform the one or more mitigating actions on the automation system, thereby reducing danger to the vehicle presented by the anomalous event."
610,17486298,2021.09.27,20220016989,2022.01.20,20220016989,2022.01.20,,,CHARGE COUPLER AND METHOD FOR AUTONOMOUSLY CHARGING VEHICLE BATTERIES,"B60L53/16,B60L58/10,H01R13/453,H02J7/00","Zoox, Inc.","A system for charging a battery carried by a vehicle may include a charging box for coupling to a vehicle chassis and including interface electrical contacts electrically coupled to the battery. The system may also include a charge coupler including coupler electrical contacts for electrically coupling to the interface electrical contacts from under the vehicle and configured to be coupled to an electrical power supply. The charging box may include an interface activation surface, and the charge coupler may include a housing for enclosing the coupler electrical contacts and including a base for supporting the coupler electrical contacts, a coupler activation surface opposite the base, an opening, and a door configured to open the opening to expose the coupler electrical contacts as the interface activation surface contacts the coupler activation surface and moves the coupler activation surface toward the base."
611,17321309,2021.05.14,20210356968,2021.11.18,20210356968,2021.11.18,,,SCENARIO IDENTIFICATION FOR VALIDATION AND TRAINING OF MACHINE LEARNING BASED MODELS FOR AUTONOMOUS VEHICLES,"G05D1/02,G06K9/00,G06K9/62,G06K9/46,B60W60/00,G06N20/00,G06N5/04","Perceptive Automata, Inc.","A system uses a machine learning based model to determine attributes describing states of mind and behavior of traffic entities in video frames captured by an autonomous vehicle. The system classifies video frames according to traffic scenarios depicted, where each scenario is associated with a filter based on vehicle attributes, traffic attributes, and road attributes. The system identifies a set of video frames associated with ground truth scenarios for validating the accuracy of the machine learning based model and predicts attributes of traffic entities in the video frames. The system analyzes video frames captured after the set of video frames to determine actual attributes of the traffic entities. Based on a comparison of the predicted attributes and actual attributes, the system determines a likelihood of the machine learning based model making accurate predictions and uses the likelihood to generate a navigation action table for controlling the autonomous vehicle."
612,17376681,2021.07.15,20210344423,2021.11.04,20210344423,2021.11.04,,,SYSTEM AND METHOD FOR OPTIMIZING OPTICAL COMMUNICATION FOR AUTONOMOUS VEHICLES,"H04B10/112,G08G1/052","Amir HANDELMAN,David GEVA","A system and method for optimizing optical communication for autonomous vehicles, including: determining a predetermined route of a vehicle equipped with an optical communication device (OCD) including an array of micromirrors; determining a location of at least one infrastructure unit along the predetermined route; determining optimal angles for the array of micromirrors based on the predetermined route and the determined location of the at least one infrastructure unit to optimize optical communication between the OCD and the at least one infrastructure unit; and adjusting the array of micromirrors based on the determined optimal angles."
613,17336856,2021.06.02,20210343150,2021.11.04,20210343150,2021.11.04,,,TRAFFIC LIGHT DETECTION AND LANE STATE RECOGNITION FOR AUTONOMOUS VEHICLES,"G08G1/16,G05D1/00,G06K9/00,G06K9/66,G08G1/01,G08G1/04,G08G1/095",Waymo LLC,"Methods and system are provided for training and using a model to determine states of lanes of interest. For instance, image data including an image and an associated label identifying at least one traffic light, a state of the at least one traffic light, and a lane controlled by the at least one traffic light are received and used to train the model such that the model is configured to, in response to receiving an image and a lane of interest included in the image, output a lane state for the lane of interest. This model is then used by a vehicle in order to determine a state of a lane of interest. This state is then used to control the vehicle in an autonomous driving mode based on the state of the lane of interest."
614,16842146,2020.04.07,20210312406,2021.10.07,20210312406,2021.10.07,,,"ARTIFICIAL INTELLIGENCE MONITORING, NEGOTIATING, AND TRADING AGENTS FOR AUTONOMOUS VEHICLES","G06Q10/00,G06N3/04,G07C5/00","DGNSS SOLUTIONS, LLC","A system for autonomous vehicle Artificial Intelligence (AI) platform consisting of 1) AI “health monitoring AI agent(s)” monitoring the health of parts of the “autonomous vehicles” or “manually driven vehicles” or the health of the entire “autonomous” or “manually-driven” vehicles; 2) e-commerce AI “negotiating” agents, including the back-end and the cloud computing infrastructure required for the AI agents working on behalf of the “autonomous” or manually-driven vehicles to find the best possible price through negotiations, auctions or futures trading for new or used “autonomous vehicles”, “autonomous vehicle” replacement parts, “autonomous vehicle” fuel, and/or “autonomous Vehicle” service providers; and 3) e-commerce AI “negotiating” agents, including the back-end and the cloud computing infrastructure required for the AI agents working on behalf of sellers to offer the best possible price through negotiations, auctions or futures trading for new or used “autonomous vehicles”, “autonomous vehicle” replacement parts, “autonomous vehicle” fuel, and/or “autonomous vehicle” services."
615,17338383,2021.06.03,20210293567,2021.09.23,20210293567,2021.09.23,,,System And Method To Identify Points Of Interest From Within Autonomous Vehicles,"G01C21/36,G06N3/02","Huawei Technologies Co., Ltd.","The disclosure relates to technology within an autonomous vehicle for interacting with passengers to provide information about their surroundings as they travel within the autonomous vehicle. In one example, the system may automatically detect and push information about points of interest in the vicinity of the vehicle to the vehicle passengers. In another example, the system provides information about points of interest around the autonomous vehicle in response to physical and/or verbal cues from a passenger in the autonomous vehicle."
616,17081656,2020.10.27,,,11106926,2021.08.31,11106926,2021.08.31,Methods and systems for automatically predicting the repair costs of a damaged vehicle from images,"G06Q40/08,G06K9/00,G06Q30/02,G06K9/62,G06T7/73,H04N5/232",State Farm Mutual Automobile Insurance Company,"A system and computer-implemented method for automatically predicting the labor, hours, and parts costs for repair of a vehicle includes receiving one or more images of the vehicle from a policyholder. A damage assessment model is accessed. The damage assessment model corresponds to features of vehicle damage based on a plurality of damaged vehicle images contained in an image training database. The damage assessment model is compared to the images of the vehicle and vehicle damage is identified based on the images. In addition, in response to identifying the vehicle damage, total labor costs, total parts costs, and total hours for repair of the vehicle are predicted based on the associated total labor costs, total parts costs, and total hours for repair data contained in the historical claims database."
617,16825049,2020.03.20,20210200212,2021.07.01,20210200212,2021.07.01,,,Jointly Learnable Behavior and Trajectory Planning for Autonomous Vehicles,"G05D1/00,G05D1/02","UATC, LLC",Systems and methods for generating motion plans for autonomous vehicles are provided. An autonomous vehicle can include a machine-learned motion planning system including one or more machine-learned models configured to generate target trajectories for the autonomous vehicle. The model(s) include a behavioral planning stage configured to receive situational data based at least in part on the one or more outputs of the set of sensors and to generate behavioral planning data based at least in part on the situational data and a unified cost function. The model(s) includes a trajectory planning stage configured to receive the behavioral planning data from the behavioral planning stage and to generate target trajectory data for the autonomous vehicle based at least in part on the behavioral planning data and the unified cost function.
618,17018499,2020.09.11,20210146949,2021.05.20,20210146949,2021.05.20,,,Localization with Diverse Dataset for Autonomous Vehicles,"B60W60/00,G06T15/08,G06N20/00","UATC, LLC","A computer-implemented method for localizing a vehicle can include accessing, by a computing system comprising one or more computing devices, a machine-learned retrieval model that has been trained using a ground truth dataset comprising a plurality of pre-localized sensor observations. Each of the plurality of pre-localized sensor observations has a predetermined pose value associated with a previously obtained sensor reading representation. The method also includes obtaining, by the computing system, a current sensor reading representation obtained by one or more sensors located at the vehicle. The method also includes inputting, by the computing system, the current sensor reading representation into the machine-learned retrieval model. The method also includes receiving, by the computing system and from the machine-learned retrieval model, a determined current pose value for the vehicle based at least in part on one or more of the pre-localized sensor observations determined to be a closest match to the current sensor reading representation. The determined current pose value has an accuracy of within about one meter."
619,16577627,2019.09.20,20210089026,2021.03.25,20210089026,2021.03.25,,,RELATIVE POSITION MANAGEMENT OF AUTONOMOUS VEHICLES BASED ON DATA BANDWITH REQUIREMENTS,"G05D1/00,G01C21/36,G01C21/34,G08G1/0968,H04W72/06,H04W72/04,H04W4/46,H04W72/08",International Business Machines Corporation,Aspects of the present invention disclose a method for routing one or more autonomous vehicles to minimize a density of autonomous vehicles and passengers passing through network areas with oversubscribed bandwidth. The method includes one or more processors determining a bandwidth requirement of a first autonomous vehicle. The method further includes determining respective bandwidth requirement for one or more additional autonomous vehicles utilizing a wireless network. The method further includes determining a total bandwidth capacity of one or more nodes of the wireless network. The method further includes determining routing instructions from a current location of the first autonomous vehicle to a destination of the first autonomous vehicle based at least in part on the bandwidth requirement of the first autonomous vehicle and the total bandwidth capacity of the one or more nodes of the wireless network.
620,16825539,2020.03.20,20210046954,2021.02.18,20210046954,2021.02.18,,,Full Uncertainty for Motion Planning in Autonomous Vehicles,"B60W60/00,G06N20/00","UATC, LLC","Systems and methods for motion planning by a vehicle computing system of an autonomous vehicle are provided. The vehicle computing system can input sensor data to a machine-learned system including one or more machine-learned models. The computing system can obtain, as an output of the machine-learned model(s), motion prediction(s) associated with object(s) detected by the system. The system can convert a shape of the object(s) into a probability of occupancy by convolving an occupied area of the object(s) with a continuous uncertainty associated with the object(s). The system can determine a probability of future occupancy of a plurality of locations in the environment at future times based at least in part on the motion prediction(s) and the probability of occupancy of the object(s). The system can provide the motion prediction(s) and the probability of future occupancy of the plurality of locations to a motion planning system of the autonomous vehicle."
621,17081656,2020.10.27,20210042543,2021.02.11,20210042543,2021.02.11,,,METHODS AND SYSTEMS FOR AUTOMATICALLY PREDICTING THE REPAIR COSTS OF A DAMAGED VEHICLE FROM IMAGES,"G06K9/00,G06Q30/02,G06Q40/08,G06K9/62,G06T7/73",State Farm Mutual Automobile Insurance Company,"A system and computer-implemented method for automatically predicting the labor, hours, and parts costs for repair of a vehicle includes receiving one or more images of the vehicle from a policyholder. A damage assessment model is accessed. The damage assessment model corresponds to features of vehicle damage based on a plurality of damaged vehicle images contained in an image training database. The damage assessment model is compared to the images of the vehicle and vehicle damage is identified based on the images. In addition, in response to identifying the vehicle damage, total labor costs, total parts costs, and total hours for repair of the vehicle are predicted based on the associated total labor costs, total parts costs, and total hours for repair data contained in the historical claims database."
622,16389718,2019.04.19,20200320992,2020.10.08,10854202,2020.12.01,10854202,2020.12.01,Dynamic microphone system for autonomous vehicles,"G10L15/00,G10L15/22,B60R16/037","Alpine Electronics of Silicon Valley, Inc.","Devices, systems and processes for a dynamic microphone system that enhances the passenger experience in autonomous vehicles are described. One example method for enhancing a passenger experiences includes generating, using an artificial intelligence algorithm, a plurality of filters based on a plurality of stored waveforms previously recorded by each of one or more passengers and a plurality of recordings of one or more noise sources, capturing voice commands from at least one of the one or more passengers inside the autonomous vehicle, generating voice commands with reduced distortion based on processing the voice commands using the plurality of filters, and instructing, based on the voice commands with reduced distortion, the autonomous vehicle to perform one or more actions."
623,16263359,2019.01.31,20200250901,2020.08.06,20200250901,2020.08.06,,,Data Recorders of Autonomous Vehicles,"G07C5/08,B60R21/0134,B60R21/0136,B60W50/02","Micron Technology, Inc.","Systems, methods and apparatus to collect sensor data generated in an autonomous vehicle. Sensors of the vehicle generate a sensor data stream that is buffered, in parallel and in a cyclic way, in a first cyclic buffer and a larger second cyclic buffer respectively. An advanced driver assistance system of the vehicle generates an accident signal when detecting or predicting an accident and provides a training signal when detecting a fault in object detection, recognition, identification or classification. The accident signal causes a sensor data stream segment to be copied from the first cyclic buffer into a slot of a non-volatile memory, selected from a plurality of slots in a round robin way. The training signal causes a sensor data stream segment to be copied from the second cyclic buffer into an area of the non-volatile memory outside of the slots reserved for the first cycle buffer."
624,16271628,2019.02.08,20200142422,2020.05.07,20200142422,2020.05.07,,,Generating Targeted Training Instances for Autonomous Vehicles,"G05D1/02,G06K9/00,G06N3/08,G06N20/00","Aurora Innovation, Inc.","Sensor data collected via an autonomous vehicle can be labeled using sensor data collected via an additional vehicle, such as a non-autonomous vehicle mounted with a vehicle agnostic removable hardware pod. A training instance can include an instance of data collected by an autonomous vehicle sensor suite and one or more corresponding labels."
625,17619905,2020.07.02,20220308204,2022.09.29,20220308204,2022.09.29,,,BEAM STEERING RADAR WITH SELECTIVE SCANNING MODE FOR AUTONOMOUS VEHICLES,"G01S13/931,G01S13/58,G05B13/02,B60W60/00,H01Q1/32",Metawave Corporation,"Examples disclosed herein relate to a beam steering radar for use in an autonomous vehicle. The beam steering radar has a radar module with at least one beam steering antenna, a transceiver, and a controller that can cause the transceiver to perform, using the at least one beam steering antenna, a first scan of a first field-of-view (FoV) with a first chirp slope in a first radio frequency (RF) signal and a second scan of a second FoV with a second chirp slope in a second RF signal. The radar module also has a perception module having a machine learning-trained classifier that can detect objects in a path and surrounding environment of the autonomous vehicle based on the first chirp slope in the first RF signal and classify the objects based on the second chirp slope in the second RF signal."
626,17292601,2020.09.30,20220189312,2022.06.16,20220189312,2022.06.16,,,INTELLIGENT COLLISION AVOIDANCE METHOD FOR A SWARM OF UNMANNED SURFACE VEHICLES BASED ON DEEP REINFORCEMENT LEARNING,"G08G3/02,G05D1/02,G05D1/00,G06N3/08",Wuhan University of Technology,"Disclosed is an intelligent collision avoidance method for a swarm of unmanned surface vehicles based on deep reinforcement learning; firstly, a theoretical framework of autonomous learning collision avoidance of a swarm of unmanned surface vehicles based on deep reinforcement learning is proposed, and the LSTM neural network memory ability is integrated to realize the continuity of collision avoidance actions; then, according to the USV environment in the framework, the characterization method is obtained, and the USV collision avoidance reward and punishment function is proposed to evaluate the collision avoidance effect; finally, an intelligent collision avoidance training system for a swarm of unmanned surface vehicles is formed. The simulation and verification of this disclosure show that the USV trained in this disclosure can navigate safely in the collision avoidance environment with a swarm of unmanned surface vehicles and realize intelligent collision avoidance."
627,16446804,2019.06.20,,,11287829,2022.03.29,11287829,2022.03.29,Environment mapping for autonomous vehicles using video stream sharing,"G05D1/02,G05D1/00,B64C39/02,G08G1/14","Cisco Technology, Inc.","In one embodiment, a supervisory service of a parking area may send a light fidelity (Li-Fi) based advertisement indicative of an offer to send video streams of the parking area to an autonomous vehicle. The supervisory service may receive an acceptance of the offer by the autonomous vehicle that includes an identifier for the autonomous vehicle. The supervisory service may identify one or more video streams of the parking area as associated with the autonomous vehicle based in part on a location of the autonomous vehicle in the parking area. The supervisory service may annotate the one or more identified video streams with metadata regarding a feature of the parking area. The supervisory service may send the annotated one or more video streams to the autonomous vehicle, wherein the autonomous vehicle uses the metadata of the annotated one or more video streams to avoid the feature of the parking area."
628,16575686,2019.09.19,,,11195258,2021.12.07,11195258,2021.12.07,Device and method for automatic image enhancement in vehicles,"G06T5/00,G06T7/80,G06T5/20,G06T11/00",ROBERT BOSCH GMBH,"A device and method for automatic image enhancement in vehicles, in particular land vehicles, including a camera to record a primary-image, and an image-processing-module to determine a resulting-image from the primary-image. The image-processing-module includes image-processing-filters, each configured to transform the primary-image in each case into an intermediate-image, an evaluation-module that outputs a quality-index for each of the intermediate-images transformed with the image-processing-filter, a selection-module that selects the intermediate-image having the highest quality index and outputs it as the resulting-image, and a learning-neural-network to learn, in a learning phase, for each primary-image the image-processing-filter, from the image-processing-filters, having the highest quality index of the intermediate-image, and after the learning phase, for each primary-image to select the image-processing-filter, from the image-processing-filters, having the highest quality index of the intermediate-image."
629,17343187,2021.06.09,20210294346,2021.09.23,20210294346,2021.09.23,,,Object Action Classification For Autonomous Vehicles,"G05D1/02,G05D1/00,G06K9/00,G06K9/62,B60W30/095,G01S17/931",Waymo LLC,"Aspects of the disclosure relate to training and using a model for identifying actions of objects. For instance, LIDAR sensor data frames including an object bounding box corresponding to an object as well as an action label for the bounding box may be received. Each sensor frame is associated with a timestamp and is sequenced with respect to other sensor frames. Each given sensor data frame may be projected into a camera image of the object based on the timestamp associated with the given sensor data frame in order to provide fused data. The model may be trained using the fused data such that the model is configured to, in response to receiving fused data, the model outputs an action label for each object bounding box of the fused data. This output may then be used to control a vehicle in an autonomous driving mode."
630,16365094,2019.03.26,,,11079767,2021.08.03,11079767,2021.08.03,Lidar based recognition of ride hailing gestures for autonomous vehicles,"G05D1/02,G01S17/89,G05D1/00,G06K9/00,G06K9/62",GM Cruise Holdings LLC,"An AV is described herein. The AV includes a lidar sensor system. The AV additionally includes a computing system that executes a gesture recognition component to determine, based upon lidar sensor data, whether a pedestrian in a driving environment of the AV is performing a hailing gesture. The AV can be configured to initiate a pickup maneuver to approach the pedestrian in response to determining that the pedestrian is performing a hailing gesture."
631,16594893,2019.10.07,20210103772,2021.04.08,20210103772,2021.04.08,,,SYSTEMS AND METHODS FOR AUTOMATICALLY ASSESSING FAULT IN RELATION TO MOTOR VEHICLE COLLISIONS,"G06K9/62,G06F17/27,G06N3/08,G07C5/00,G07C5/08","The Toronto-Dominion Bank,The Toronto-Dominion Bank","A computer-implemented method of providing a recommendation as to a fault determination for a motor vehicle collision is disclosed. The method may include receiving unstructured text describing the circumstances of the collision. The unstructured text is evaluated an associated intent related to the circumstances of the motor vehicle collision is identified. The intent is mapped to an internal node of a decision tree corresponding to a set of fault-determination rules. The computer then successively prompts and receive input responsive to the prompting that corresponds to details of the circumstances of the collision. The computer may identify, based on the received input, a path through the decision tree ending at a leaf node that corresponds to a fault-determination rule governing motor vehicle collisions that matches the circumstances of the motor vehicle collision. The recommendation is then provided based on that rule. Related systems and computer-readable media are also disclosed."
632,16920246,2020.07.02,20210003691,2021.01.07,20210003691,2021.01.07,,,BEAM STEERING RADAR WITH ADJUSTABLE LONG-RANGE RADAR MODE FOR AUTONOMOUS VEHICLES,"G01S13/42,G01S7/41,G01S7/35,G01S13/931",Metawave Corporation,"Examples disclosed herein relate to a beam steering radar for use in an autonomous vehicle. The beam steering radar has a radar module with at least one beam steering antenna, a transceiver, and a controller that can cause the transceiver to perform, using the at least one beam steering antenna, a first scan of a field-of-view (FoV) with a first number of chirps in a first radio frequency (RF) signal and a second scan of the FoV with a second number of chirps in a second RF signal. The radar module also has a perception module having a machine learning-trained classifier that can detect objects in a path and surrounding environment of the autonomous vehicle based on the first number of chirps in the first RF signal and classify the objects based on the second number of chirps in the second RF signal."
633,16446804,2019.06.20,20200401157,2020.12.24,20200401157,2020.12.24,,,ENVIRONMENT MAPPING FOR AUTONOMOUS VEHICLES USING VIDEO STREAM SHARING,"G05D1/02,G05D1/00,G08G1/14,B64C39/02","Cisco Technology, Inc.,Cisco Technology, Inc.","In one embodiment, a supervisory service of a parking area may send a light fidelity (Li-Fi) based advertisement indicative of an offer to send video streams of the parking area to an autonomous vehicle. The supervisory service may receive an acceptance of the offer by the autonomous vehicle that includes an identifier for the autonomous vehicle. The supervisory service may identify one or more video streams of the parking area as associated with the autonomous vehicle based in part on a location of the autonomous vehicle in the parking area. The supervisory service may annotate the one or more identified video streams with metadata regarding a feature of the parking area. The supervisory service may send the annotated one or more video streams to the autonomous vehicle, wherein the autonomous vehicle uses the metadata of the annotated one or more video streams to avoid the feature of the parking area."
634,16365094,2019.03.26,20200310433,2020.10.01,20200310433,2020.10.01,,,LIDAR BASED RECOGNITION OF RIDE HAILING GESTURES FOR AUTONOMOUS VEHICLES,"G05D1/02,G01S17/89,G05D1/00,G06K9/00,G06K9/62",GM Cruise Holdings LLC,"An AV is described herein. The AV includes a lidar sensor system. The AV additionally includes a computing system that executes a gesture recognition component to determine, based upon lidar sensor data, whether a pedestrian in a driving environment of the AV is performing a hailing gesture. The AV can be configured to initiate a pickup maneuver to approach the pedestrian in response to determining that the pedestrian is performing a hailing gesture."
635,16575686,2019.09.19,20200098095,2020.03.26,20200098095,2020.03.26,,,DEVICE AND METHOD FOR AUTOMATIC IMAGE ENHANCEMENT IN VEHICLES,"G06T5/00,G06T5/20,G06T11/00,G06T7/80",ROBERT BOSCH GMBH,"A device and method for automatic image enhancement in vehicles, in particular land vehicles, including a camera to record a primary-image, and an image-processing-module to determine a resulting-image from the primary-image. The image-processing-module includes image-processing-filters, each configured to transform the primary-image in each case into an intermediate-image, an evaluation-module that outputs a quality-index for each of the intermediate-images transformed with the image-processing-filter, a selection-module that selects the intermediate-image having the highest quality index and outputs it as the resulting-image, and a learning-neural-network to learn, in a learning phase, for each primary-image the image-processing-filter, from the image-processing-filters, having the highest quality index of the intermediate-image, and after the learning phase, for each primary-image to select the image-processing-filter, from the image-processing-filters, having the highest quality index of the intermediate-image."
636,16566802,2019.09.10,20200074024,2020.03.05,20200074024,2020.03.05,,,SIMULATION SYSTEM AND METHODS FOR AUTONOMOUS VEHICLES,"G06F17/50,G05D1/02,G05D1/00,G01S17/93","Zoox, Inc.","Various embodiments relate generally to autonomous vehicles and associated mechanical, electrical and electronic hardware, computer software and systems, and wired and wireless network communications to provide an autonomous vehicle fleet as a service. More specifically, systems, devices, and methods are configured to simulate navigation of autonomous vehicles in various simulated environments. In particular, a method may include receiving data representing characteristics of a dynamic object, calculating a classification of a dynamic object to identify a classified dynamic object, identifying data representing dynamic-related characteristics associated with the classified dynamic object, forming a data model of the classified dynamic object, simulating a predicted range of motion of the classified dynamic object in a simulated environment to form a simulated dynamic object, and simulating a predicted response of a data representation of a simulated autonomous vehicle."
637,17149706,2021.01.14,20220220846,2022.07.14,20220220846,2022.07.14,,,Automatic Well Control Based on Detection of Fracture Driven Interference,"E21B49/00,E21B43/26,E21B47/02,E21B47/003","Baker Hughes Oilfield Operations LLC,Baker Hughes Oilfield Operations LLC","A method is provided for controlling the operation of an offset well located near an active well that is undergoing a hydraulic fracturing operation that may produce a fracture driven interference (FDI) event to the offset well. The method includes providing an FDI intervention system that includes a computer-implemented predictive model for determining a risk of the FDI event occurring during the hydraulic fracturing operation, calculating a risk-weighted FDI event cost of the FDI event impacting production from the offset well, and calculating a defensive intervention implementation cost to apply a defensive intervention on the offset well to mitigate harm from an FDI event. The method includes calculating a cost comparison based on a comparison of the defensive intervention implementation cost and the risk-weighted FDI event cost. The method concludes with automatically controlling the operation of the offset well with the FDI intervention system based on the cost comparison."
638,17557591,2021.12.21,20220111843,2022.04.14,20220111843,2022.04.14,,,"SYSETEM FOR SPEED CONTROL OF ELECTRIC BIKES , ELECTRIC SCOOTERS, AND SIGN RECOGNITION FOR ELECTRIC VEHICLES , AUTONOMOUS VEHICLES IN CITIES ,AND HIGHWAYS","B60W30/18,G08G1/0968","SHIV P VERMA,SHAILEN VERMA","A system for speed control of electric bikes, electric scooters and road sign recognition for connected vehicles is presented in this invention. A web server system containing all the information on the road signs and traffic lights under the city's jurisdiction with street map is used. This server controls a controller installed on all the road signs and road traffic lights. This controller uses an ISM band transmitter to transmit content of the posted road sign as multiple data packets. These data packets are used by the controller installed in the vehicle to determine type of road signs and then inform the vehicle main system controller to perform appropriate operation for speed control and operation of the vehicle."
639,17093390,2020.11.09,,,11379925,2022.07.05,11379925,2022.07.05,Systems and methods for allocating fault to autonomous vehicles,"G06Q40/08,G05D1/00,G07C5/08,G07C5/02,G01W1/00,G01C21/28",State Farm Mutual Automobile Insurance Company,"In one aspect, a system for allocating fault in a collision involving a vehicle is provided. The system may include (1) a sensor coupled to the vehicle and configured to collect contextual data related to the collision, (2) a non-transitory memory configured to store the contextual data, and (3) a processor coupled to the non-transitory memory and configured to (a) gain access to the contextual data, and (b) compute and assign a fault percentage to a driver of the vehicle based upon the contextual data."
640,17551851,2021.12.15,20220107637,2022.04.07,20220107637,2022.04.07,,,BACKUP CONTROL SYSTEMS AND METHODS FOR AUTONOMOUS VEHICLES,"G05D1/00,G01S19/21,B60W50/14",State Farm Mutual Automobile Insurance Company,A backup control server for reducing dangers to automation systems of autonomous vehicles includes a memory and a processor. The processor is programmed to detect an anomalous event which may include one of a geomagnetic interference event and a cyber-attack event. The processor may also be programmed to perform a threat assessment for the anomalous event relative to an automation system of a vehicle. The automation system may be configured to control an aspect of autonomous operation of the vehicle. The processor may be further programmed to determine one or more mitigating actions to perform on the automation system based upon the threat assessment. The one or more mitigating actions are configured to reduce a danger to the vehicle presented by the anomalous event. The processor may also be programmed to transmit to the vehicle instructions to perform one or more mitigating actions on the automation system.
641,17515932,2021.11.01,20220055549,2022.02.24,20220055549,2022.02.24,,,Systems and Methods for Streaming Processing for Autonomous Vehicles,"B60R16/023,G01S13/72,G01S13/931,G01S17/66,G01S17/86,G01S17/931,B60N2/00,G01S17/933,G06N20/00,G05D1/00,G05D1/02,G06N5/04,G06K9/00","UATC, LLC","Generally, the present disclosure is directed to systems and methods for streaming processing within one or more systems of an autonomy computing system. When an update for a particular object or region of interest is received by a given system, the system can control transmission of data associated with the update as well as a determination of other aspects by the given system. For example, the system can determine based on a received update for a particular aspect and a priority classification and/or interaction classification determined for that aspect whether data associated with the update should be transmitted to a subsequent system before waiting for other updates to arrive."
642,16918272,2020.07.01,20220003855,2022.01.06,20220003855,2022.01.06,,,POINT CLOUDS BASED LIDAR RECALIBRATION SYSTEM FOR AUTONOMOUS VEHICLES,"G01S7/497,G01S17/87,G01S17/931,G01S7/48,G01S7/4914",Baidu USA LLC,"Embodiments of the present disclosures disclose a method and a system to notify an operator that perception sensors of an autonomous driving vehicle (ADV) need to be recalibrated. In one embodiment, a system perceives a surrounding environment of an autonomous driving vehicle (ADV), including one or more obstacles. The system extracts feature information from previously stored point clouds mapping a three-dimensional surrounding environment of the ADV. The system identifies one or more matching features between the extracted feature information and features of the one or more obstacles. The system determines an average offset distance based on each of the matching features. The system determines an average offset distance distribution based on the average offset distance over a period of time. The system sends an alert to the ADV to alert that the one or more sensors is recommended for recalibration if the average offset distance distribution satisfies a predetermined condition."
643,17408728,2021.08.23,20210382488,2021.12.09,20210382488,2021.12.09,,,Systems and Methods for Prioritizing Object Prediction for Autonomous Vehicles,"G05D1/02,G06N20/00,G05D1/00,B60W30/095,G08G1/01,B60W40/00,G06T7/70","UATC, LLC","Systems and methods for determining object prioritization and predicting future object locations for an autonomous vehicle are provided. A method can include obtaining, by a computing system comprising one or more processors, state data descriptive of at least a current or past state of a plurality of objects that are perceived by an autonomous vehicle. The method can further include determining, by the computing system, a priority classification for each object in the plurality of objects based at least in part on the respective state data for each object. The method can further include determining, by the computing system, an order at which the computing system determines a predicted future state for each object based at least in part on the priority classification for each object and determining, by the computing system, the predicted future state for each object based at least in part on the determined order."
644,16861723,2020.04.29,20200257300,2020.08.13,20200257300,2020.08.13,,,METHOD AND SYSTEM FOR RISK MODELING IN AUTONOMOUS VEHICLES,"G05D1/02,B64D11/06,B60W50/00,B60W30/00,B60W40/09,G08G1/0967,G08G1/01,G05D1/00","Zendrive, Inc.","A method for adaptive risk modeling for an autonomous vehicle, the method comprising: retrieving parameters of an identified driving mission of the autonomous vehicle; in response to the parameters of the identified driving mission, generating values of: a comparative autonomous parameter, a mix model parameter, a surrounding risk parameter, a geographic operation parameter, and a security risk parameter upon evaluating situational inputs associated with the identified driving mission with a comparative autonomous model, a mix model, a sensor-surrounding model, a geography-dependent model, and a security risk model generated using sensor and supplementary data extraction systems associated with the autonomous vehicle; upon generating values, generating a risk analysis with a rule-based algorithm; and contemporaneously with execution of the identified driving mission, implementing a response action associated with control of the autonomous vehicle, based upon the risk analysis."
645,16376818,2019.04.05,,,10703383,2020.07.07,10703383,2020.07.07,Systems and methods for detecting software interactions for individual autonomous vehicles,"B60W50/00,B60W50/14,B60W50/04,G07C5/00",State Farm Mutual Automobile Insurance Company,"An interaction detection and analysis (“IDA”) computing device for analyzing data from a plurality of autonomous vehicles (“AVs”) relative to an individual AV that identifies potential performance outcomes and risks based on interactions associated with software onboard the AVs may be provided. The IDA computing device may include at least one processor programmed to (i) receive AV data from the individual AV including a software ecosystem and hardware installed on the individual AV, (ii) store the received AV data in a data record in a database, (iii) compare the software ecosystem and the hardware for the individual AV to data associated with AVs having relatively similar software ecosystems and hardware, (iv) identify at least one known performance outcome and risk based on the data from the AVs having relatively similar software ecosystems and hardware, and (v) alert a user of the individual AV of the identified performance outcome and risk."
646,16432921,2019.06.05,,,11479262,2022.10.25,11479262,2022.10.25,Geographically disparate sensor fusion for enhanced target detection and identification in autonomous vehicles,"B60W30/08,B60W50/04,G01S13/931,G01S13/86",Metawave Corporation,Examples disclosed herein relate to an autonomous driving system in an ego vehicle. The autonomous driving system includes a radar system configured to detect and identify a target in a path and a surrounding environment of the ego vehicle. The autonomous driving system also includes a sensor fusion module configured to receive radar data on the identified target from the radar system and compare the identified target with one or more targets identified by a plurality of perception sensors that are geographically disparate from the radar system. Other examples disclosed herein include a method of operating the radar system in the autonomous driving system of the ego vehicle.
647,16834497,2020.03.30,,,11458994,2022.10.04,11458994,2022.10.04,Systems and methods for semi-autonomously controlling a vehicle,"B60W60/00,B60W40/08,B60W30/095,B60W30/09,G05B13/02,G06N3/08","Toyota Research Institute, Inc.","Systems and methods for semi-autonomously controlling a vehicle are disclosed. In one embodiment, a method includes determining a trajectory of a semi-autonomous vehicle based on data received from one or more vehicle sensors, determining a state of the vehicle based on data received from the vehicle sensors, determining an optimal trajectory of the vehicle based on the state of the vehicle, determining a level of confidence in the determined state of the vehicle and in the determined optimal trajectory of the vehicle, determining a plurality of possible future states of the vehicle based on the state of the vehicle, the trajectory of the vehicle, and the level of confidence, determining whether a subset of the possible future states of the vehicle are recoverable, and when it is determined that the subset of the possible future states of the vehicle are recoverable, issuing a security certificate."
648,17742314,2022.05.11,20220270181,2022.08.25,20220270181,2022.08.25,,,METHODS FOR AUTOMATICALLY DETERMINING INJURY TREATMENT RELATION TO A MOTOR VEHICLE ACCIDENT AND DEVICES THEREOF,"G06Q40/08,G16H50/30,G06V20/59,G06V10/94,G06V10/74,G06V10/70,G06T7/246","Mitchell International, Inc.,Mitchell International, Inc.","A method for automatically determining injury treatment relation to a motor vehicle accident comprises obtaining a plurality of images of a damaged motor vehicle, vehicle data describing the motor vehicle, occupant data describing an occupant who occupied the motor vehicle during the motor vehicle accident, and injury data from an electronic insurance claim associated with the motor vehicle accident, the injury data specifying an injury to the occupant; determining a delta velocity value for the damaged motor vehicle by applying a first machine learning model to the set of images of the damaged motor vehicle and the vehicle data; determining an injury severity score by applying a second machine learning model to the delta velocity value for the damaged motor vehicle, the vehicle data, and the occupant data; and automatically adjudicating the electronic insurance claim."
649,17829034,2022.05.31,20220290404,2022.09.15,20220290404,2022.09.15,,,Sensor Retrofit to Autonomously Actuate An Excavation Vehicle,"E02F9/20,E02F3/43",Built Robotics Inc.,"An excavation vehicle capable of autonomously actuating an excavation tool or navigating an excavation vehicle to perform an excavation routine within an excavation site is described herein. Sensors mounted to the excavation vehicle and the excavation tool produce signals representative of a position and orientation of the corresponding joint relative on the excavation vehicle relative to the excavation site, a position and orientation of the excavation vehicle relative to the excavation site, and one or more features of the excavation site based on the position of the excavation vehicle within the excavation site. A set of solenoids are configured to couple to corresponding hydraulic valves of the excavation tool to actuate the valve. A controller produces actuating signals to control the joints of the excavation tool to autonomously perform the excavation routine based on the signals produced by the sensors."
650,17186940,2021.02.26,20220276653,2022.09.01,20220276653,2022.09.01,,,Lane-Level Route Planner for Autonomous Vehicles,"G05D1/02,G01C21/36","Nissan North America, Inc.,The University of Massachusetts","Route planning includes receiving a destination, obtaining a lane-level route to the destination using a map, and controlling an autonomous vehicle (AV) to traverse the lane-level route. The lane-level route includes a transition from a first segment of a first lane of a road to a second segment of a second lane of the road."
651,17165396,2021.02.02,20220242451,2022.08.04,20220242451,2022.08.04,,,MALICIOUS EVENT DETECTION FOR AUTONOMOUS VEHICLES,"B60W60/00,H04L29/08,G07C5/08,G05D1/02,B60R25/102,B60R25/104","TuSimple, Inc.","A system comprises an autonomous vehicle (AV) and a control device operably coupled with the AV. The control device detects a series of events within a threshold period of time, where a number of series of events in the series of events is above a threshold number. The series of events taken in the aggregate within the threshold period of time deviates from a normalcy mode. The normalcy mode comprises events that are expected to the encountered by the AV. The control device determines whether the series of events corresponds to a malicious event, where the malicious event indicates tampering with the AV. In response to determining that the series of events corresponds to the malicious event, the series of events are escalated to be addressed."
652,17592407,2022.02.03,20220244351,2022.08.04,20220244351,2022.08.04,,,Localization System for Autonomous Vehicles Using Sparse Radar Data,"G01S7/41,G01C21/30,G01S13/89,G01S13/86","Autonomous Solutions, Inc.","An autonomous vehicle is disclosed that includes a velocity sensor; a radar system; a digital storage medium; and a controller in communication with the digital storage medium, radar system, and the velocity sensor. The controller, for example, may retrieve map data from the digital storage medium; receive current radar data from the radar system; receive autonomous vehicle velocity data from the velocity sensor; identify radar data points in the current radar data that represent objects in motion; remove radar data points from the current radar data that represent objects in motion; and/or match the radar data with the map data to return location data."
653,16993533,2020.08.14,,,11380109,2022.07.05,11380109,2022.07.05,Mobile launchpad for autonomous vehicles,"G06V20/58,G08G1/01","TuSimple, Inc.","An autonomous vehicle (AV) includes at least one vehicle sensor that is configured, when the AV is stopped, to observe at least a first portion of a zone around the stopped AV. A portable device is operated by a user near the stopped AV. A control subsystem receives a communication from the portable device that includes information regarding whether a second portion of the zone around the AV is free of obstructions. The control subsystem receives AV sensor data from the at least one vehicle sensor. The control subsystem determines whether the first portion of the zone free of obstructions and whether the second portion of the zone is free of obstructions. If that both the first and second portions of the zone around the stopped AV are free of obstructions, the stopped AV is allowed to begin moving."
654,16817600,2020.03.12,,,11401689,2022.08.02,11401689,2022.08.02,Sensor retrofit to autonomously actuate an excavation vehicle,"E02F9/20,E02F3/43,E02F9/26",Built Robotics Inc.,"An excavation vehicle capable of autonomously actuating an excavation tool or navigating an excavation vehicle to perform an excavation routine within an excavation site is described herein. Sensors mounted to the excavation vehicle and the excavation tool produce signals representative of a position and orientation of the corresponding joint relative on the excavation vehicle relative to the excavation site, a position and orientation of the excavation vehicle relative to the excavation site, and one or more features of the excavation site based on the position of the excavation vehicle within the excavation site. A set of solenoids are configured to couple to corresponding hydraulic valves of the excavation tool to actuate the valve. A controller produces actuating signals to control the joints of the excavation tool to autonomously perform the excavation routine based on the signals produced by the sensors."
655,16575521,2019.09.19,,,11237562,2022.02.01,11237562,2022.02.01,System and method for avoiding contact between autonomous and manned vehicles caused by loss of traction,"G05D1/02,G05D1/00,B60W30/09,G06N20/00",CATERPILLAR INC.,"A control system for preventing vehicle collisions may include a vehicle location determination module, a terrain determination module, a terrain surface coefficient of friction estimation module, and a sensing system configured to generate signals indicative of vehicle speed, vehicle pose, vehicle size, vehicle weight, vehicle tire type, vehicle load, vehicle gear ratio, weather characteristics, and road conditions for a vehicle operating at a job site. A manned vehicle trajectory determination module may receive location information and plot a first travel path for a manned vehicle based at least in part on a location, heading, and speed of the manned vehicle and a desired destination for the manned vehicle. An autonomous vehicle trajectory determination module may receive location information, terrain information, and terrain surface coefficient of friction information, plot a second travel path for an autonomous vehicle, and determine projected slide trajectories for the autonomous vehicle at successive positions along the second travel path where the autonomous vehicle is predicted to lose traction based at least in part on signals received from the sensing system."
656,16836486,2020.03.31,,,11235779,2022.02.01,11235779,2022.02.01,Dual-measurement data structure for autonomous vehicles,"B60W50/023,G05D1/00","Augmented Radar Imaging, Inc.","During a measurement technique, an electronic device may receive first sensor information associated with a first field of view and a first timestamp, and second sensor information associated with a second field of view and a second timestamp. For example, the electronic device may perform a first measurement using a first sensor and performing a second, different type of measurement using a second sensor. Therefore, the first sensor information and the second sensor information may be associated with different types of sensors. Moreover, the first timestamp and the second timestamp may be concurrent or in close temporal proximity, and the first field of view and the second field of view may at least substantially overlap. Then, the electronic device may store the first sensor information and the second sensor information in memory. In some embodiments, the electronic device stores the first timestamp and the second timestamp in the memory."
657,16803171,2020.02.27,,,11386501,2022.07.12,11386501,2022.07.12,Accident fault determination for autonomous vehicles,"G06Q40/08,G07C5/00,G07C5/08,G06Q40/00,B60W50/02",State Farm Mutual Automobile Insurance Company,"Methods and systems for determining fault for an accident involving a vehicle having one or more autonomous and/or semi-autonomous operation features are provided. According to certain aspects, performance data indicative of the performance of the features may be used to determine fault for a vehicle accident, such as a collision, by allocating fault for the accident between a vehicle operator, the autonomous operation features, or a third party. The allocation of fault may be used to determine an adjustment to an insurance policy and/or adjust coverage levels for an insurance policy. The allocation of fault may further be used to adjust risk levels or profiles associated with the autonomous or semi-autonomous operation features, which may be applied to other vehicles having the same or similar features."
658,17544556,2021.12.07,20220234618,2022.07.28,20220234618,2022.07.28,,,HOMOTOPIC-BASED PLANNER FOR AUTONOMOUS VEHICLES,"B60W60/00,B60W40/06,B60W50/00,B60W30/095,B60W30/09,B60W30/14",Motional AD LLC,"Among other things, techniques are described for planning a route for an autonomous vehicle. As an example, a set of candidate constraints for a road segment to be traversed by a vehicle is obtained. A plurality of homotopies are determined, each including a different respective combination of the candidate constraints. For each homotopy, a first prediction of a motion of the vehicle is generated according to a first degree of precision, and a determination is made that the vehicle can traverse the road segment according to a subset of the homotopies. Further, a plurality of trajectories are determined according to the subset of the homotopies, including generating at least one second prediction of the motion of the vehicle according to a second degree of precision greater than the first degree of precision, and selecting one of the trajectories."
659,17110966,2020.12.03,20220179409,2022.06.09,20220179409,2022.06.09,,,OPTIMIZING MANAGEMENT OF AUTONOMOUS VEHICLES,"G05D1/00,H04W4/44,G08G1/127","MITSUBISHI ELECTRIC AUTOMOTIVE AMERICA, INC.,MITSUBISHI ELECTRIC AUTOMOTIVE AMERICA, INC.","A system, device and method of managing autonomous vehicles are provided. The system may include a server, a feedback device, a control device for controlling a vehicle. A server may include a communication interface configured to communicate with a control device of each of a plurality of vehicles and a feedback device; a memory storing instructions; and at least one processor. The at least one processor is configured to receive control data from the control device of each of the plurality of vehicles; determine an operation status of each of the plurality of vehicles based on the control data; generate a feedback interface based on the operation status of each of the plurality of vehicles; and transmit the feedback interface to the feedback device."
660,17544242,2021.12.07,20220155415,2022.05.19,20220155415,2022.05.19,,,Detecting Spurious Objects For Autonomous Vehicles,"G01S7/48,G05D1/00,G05D1/02,G01S7/487",Waymo LLC,"Aspects of the disclosure relate to detecting spurious objects. For instance, a model may be trained using raining data including a plurality of LIDAR data points generated by a LIDAR sensor of a vehicle. Each given LIDAR data point includes location information and intensity information, and is associated with waveform data for that given LIDAR data point. At least one of the plurality of LIDAR data points is further associated with a label identifying spurious objects through which the vehicle is able to drive. The model and/or a plurality of heuristics may then be provided to a vehicle in order to allow the vehicle to determine LIDAR data points that correspond to spurious objects. These LIDAR data points may then be filtered from sensor data, and the filtered sensor data may be used to control the vehicle in an autonomous driving mode."
661,17569990,2022.01.06,20220126850,2022.04.28,20220126850,2022.04.28,,,SYSTEM AND METHOD FOR DETERMINING DRIVER PREFERENCES FOR AUTONOMOUS VEHICLES,"B60W50/08,G05D1/00","TOYOTA MOTOR ENGINEERING &#x26; MANUFACTURING NORTH AMERICA, INC.,TOYOTA MOTOR ENGINEERING &#x26; MANUFACTURING NORTH AMERICA, INC.","The driver preferences system can determine driver habits and preferences based on output from a plurality of sensors. Utilizing the output from the plurality of sensors, an autonomous vehicle can operate according to the learning habits and preferences of the driver. The operator of the driver preferences system can finely adjust any habits or preferences via a driver preferences interface, as well as select preset modes including an aggressive driving mode or a cautious driving mode. Additionally, one or more driver profiles can be stored and selected via the driver preferences interface so that more than one driver can have an autonomous vehicle operator according to their personal driving habits and/or preferences."
662,17410068,2021.08.24,20220099450,2022.03.31,20220099450,2022.03.31,,,QUALITY SCORING FOR PULLOVERS FOR AUTONOMOUS VEHICLES,"G01C21/34,B60W60/00,B60W30/095","Waymo, LLC","Aspects of the disclosure relate to evaluating quality of a predetermined pullover location for an autonomous vehicle. For instance, a plurality of inputs for the predetermined pullover location may be received. The plurality of inputs may each include a value representative of a characteristic of the predetermined pullover location. The plurality of inputs may be combined to determine a pullover quality value for the predetermined pullover location. The pullover quality value may be provided to a vehicle in order to enable the vehicle to select a pullover location for the vehicle."
663,16993533,2020.08.14,20220051033,2022.02.17,20220051033,2022.02.17,,,MOBILE LAUNCHPAD FOR AUTONOMOUS VEHICLES,"G06K9/00,G08G1/01","TuSimple,Inc.","An autonomous vehicle (AV) includes at least one vehicle sensor that is configured, when the AV is stopped, to observe at least a first portion of a zone around the stopped AV. A portable device is operated by a user near the stopped AV. A control subsystem receives a communication from the portable device that includes information regarding whether a second portion of the zone around the AV is free of obstructions. The control subsystem receives AV sensor data from the at least one vehicle sensor. The control subsystem determines whether the first portion of the zone free of obstructions and whether the second portion of the zone is free of obstructions. If that both the first and second portions of the zone around the stopped AV are free of obstructions, the stopped AV is allowed to begin moving."
664,16434501,2019.06.07,,,11287816,2022.03.29,11287816,2022.03.29,Navigational constraints for autonomous vehicles,"G05D1/00,G08G1/00,G01C21/34","Uber Technologies, Inc.","A computing system can generate a map constraint interface enabling a fleet operator to update map constraints for autonomous vehicles (AVs). The map constraint interface can comprise a unified document model enabling the fleet operator to configure a set of constraint layers of autonomy maps utilized by the AVs. Each constraint layer can include a toggle feature that enables the fleet operator to enable and disable the constraint layer. The system can receive, via the map constraint interface, a set of inputs configuring the set of constraint layers of the one or more autonomy maps, compile a set of updated map constraints, corresponding to the configured set of constraint layers, into a document container, and output the document container to a subset of the AVs to enable the subset of AVs to integrate the set of updated map constraints with the autonomy maps."
665,16993420,2020.08.14,20220048643,2022.02.17,20220048643,2022.02.17,,,LAUNCHPAD FOR AUTONOMOUS VEHICLES,"B64F1/10,B64C39/02","TuSimple, Inc.","A launchpad is sized and shaped to accommodate an autonomous vehicle (AV) that includes at least one vehicle sensor. The launchpad includes one or more launchpad sensors located on or around the launchpad. A control subsystem receives launchpad sensor data from the launchpad sensor(s) and AV sensor data from the vehicle sensor(s).  In response to the request for departure of the AV, the control subsystem determines, based at least in part upon the launchpad sensor data, whether the launchpad is free of obstructions that would prevent departure from the launchpad and determines, based at least in part upon the AV sensor data, whether the region in front of the AV is clear of obstructions that would prevent movement away from the launchpad. If both the launchpad and the region in front of the AV are free of obstructions, the AV is permitted to begin driving autonomously."
666,16993762,2020.08.14,20220048537,2022.02.17,20220048537,2022.02.17,,,LANDING PAD FOR AUTONOMOUS VEHICLES,"B60W60/00,G06K9/00","TuSimple, Inc.","Each of a plurality of landing pads is sized and shaped to accommodate an AV. Landing pad sensor(s) are located in or around each landing pad. A control subsystem receives landing pad sensor data from the one or more landing pad sensors and receives, from a first AV traveling to a location of the plurality of landing pads, a request for an assigned landing pad in which the first AV should park. In response to this request, the control subsystem determines, based on the received landing pad sensor data, whether a first landing pad is free of obstructions that would prevent receipt of the first AV. If the first landing pad is free of obstructions, an indication is provided to the AV that the first landing pad is the assigned landing pad."
667,16935266,2020.07.22,20220028277,2022.01.27,20220028277,2022.01.27,,,REAL TIME FLEET MANAGEMENT FOR AUTONOMOUS VEHICLES USING PUDDLE MAPPING,"G08G1/00,G08G1/0967",Waymo LLC,"The disclosure relates to managing a fleet of autonomous vehicles. For instance, a method may include receiving, from a plurality of the autonomous vehicles of the fleet, reports identifying locations of detected puddles. A miles per puddle rate may be determined based on the received reports. An operating policy for the fleet may be determined based on the miles per puddle rate. An instruction may be sent to one or more of the autonomous vehicles of the fleet in order to implement the operating policy."
668,17476538,2021.09.16,20220009413,2022.01.13,20220009413,2022.01.13,,,COMMUNICATIONS FOR AUTONOMOUS VEHICLES,"B60Q5/00,G05D1/00,G08G1/00,B60Q1/26",WAYMO LLC,"Aspects of the disclosure provide a method of facilitating communications from an autonomous vehicle to a user. For instance, a method may include, while attempting to pick up the user and prior to the user entering an vehicle, inputting a current location of the vehicle and map information into a model in order to identify a type of communication action for communicating a location of the vehicle to the user; enabling a first communication based on the type of the communication action; determining whether the user has responded to the first communication from received sensor data; and enabling a second communication based on the determination of whether the user has responded to the communication."
669,17405715,2021.08.18,20220004197,2022.01.06,20220004197,2022.01.06,,,Verification Of Iterative Closest Point Alignments For Autonomous Vehicles,"G05D1/02,G01S17/89,G01S13/86,G05D1/00",Waymo LLC,"Aspects of the disclosure relate to training and using a model for verifying accuracy of ICP alignments or alignments between data points using an iterative closest point algorithm. For instance, a model may be trained using ICP alignment data, including alignments between an object appearing in LIDAR sensor frames. The training may also include setting a definition for a trusted ICP alignment. In this regard, the model may be trained such that, n response to receiving additional LIDAR sensor frames and corresponding additional ICP alignment data, output a value indicative of whether the additional ICP alignment data is trusted according to the definition. The model may then be used to control a vehicle in an autonomous driving mode by determining whether alignment data for object determined using the ICP algorithm should be trusted."
670,16909950,2020.06.23,20210397857,2021.12.23,20210397857,2021.12.23,,,PERCEPTION SYSTEM FOR AUTONOMOUS VEHICLES,"G06K9/00,G06T7/11,G06K9/32,G06T7/70,G06T11/20,B60W60/00","TUSIMPLE, INC.","Image processing techniques are described to obtain an image from a camera located on a vehicle while the vehicle is being driven, cropping a portion of the obtained image corresponding to a region of interest, detecting an object in the cropped portion, adding a bounding box around the detected object, determining position(s) of reference point(s) on the bounding box, and determining a location of the detected object in a spatial region where the vehicle is being driven based on the determined one or more positions of the second set of one or more reference points on the bounding box."
671,16892999,2020.06.04,20210380141,2021.12.09,20210380141,2021.12.09,,,LOCKED PEDESTRIAN DETECTION AND PREDICTION FOR AUTONOMOUS VEHICLES,"B60W60/00,G06T7/70,G06K9/00",Baidu USA LLC,"Embodiments is disclosed to detect a locked heading direction of a pedestrian and to predict a path for the pedestrian using the locked heading direction. According to one embodiment, a system perceives an environment of an autonomous driving vehicle (ADV) using one or more image capturing devices. The system detects a pedestrian in the perceived environment. The system determines a facing direction of the pedestrian relative to the ADV as one of left/right side, front, or back. If the facing direction of the pedestrian is determined to be front or back facing, the system determines a lane nearest to the pedestrian. The system projects the pedestrian onto the nearest lane to determine a lane direction at the projection. The system determines a heading direction for the pedestrian locking to the lane direction of the nearest lane based on a predetermined condition."
672,16872502,2020.05.12,20210354723,2021.11.18,20210354723,2021.11.18,,,DETERMINING PUDDLE SEVERITY FOR AUTONOMOUS VEHICLES,"B60W60/00,G06K9/00,G06K9/62",Waymo LLC,"Aspects of the disclosure provide methods for controlling a first vehicle having an autonomous driving mode. In one instance, sensor data generated by one or more sensors of the first vehicle may be received. A splash and characteristics of the splash may be detected from the sensor data using a classifier. A severity of a puddle may be determined based on the characteristics of the splash and a speed of a second vehicle that caused the splash. The first vehicle may be controlled based on the severity. In another instance, a location of a puddle relative to a tire of a second vehicle is estimated using sensor data generated by one or more sensors of the first vehicle. A severity of the puddle may be determined based on the estimated location. The first vehicle may be controlled based on the severity."
673,16874928,2020.05.15,,,11155205,2021.10.26,11155205,2021.10.26,Communications for autonomous vehicles,"B60Q5/00,G05D1/00,G08G1/00,B60Q1/26",WAYMO LLC,"Aspects of the disclosure provide a method of facilitating communications from an autonomous vehicle to a user. For instance, a method may include, while attempting to pick up the user and prior to the user entering an vehicle, inputting a current location of the vehicle and map information into a model in order to identify a type of communication action for communicating a location of the vehicle to the user; enabling a first communication based on the type of the communication action; determining whether the user has responded to the first communication from received sensor data; and enabling a second communication based on the determination of whether the user has responded to the communication."
674,16433165,2019.06.06,,,11142212,2021.10.12,11142212,2021.10.12,Safety-aware comparator for redundant subsystems in autonomous vehicles,"B60W50/023,G05D1/00,B60W50/00",NXP B.V.,"A method, system and device are disclosed for determining safety conflicts in redundant subsystems of autonomous vehicles. Each redundant subsystem calculates a world model or path plan, including locations, dimensions, and orientations of moving and stationary objects, as well as projected travel paths for moving objects in the future. The travel paths and projected future world models are subsequently compared using a geometric overlay operation. If at future time moments the projected world models match within predefined margins, the comparison results in a match. In case of a mismatch at a given future moment between projected world models, a determination is made as to whether the autonomous vehicle and all road users in this future moment are safe from collision or driving off the drivable space or road based on a geometric overlay operation."
675,17347692,2021.06.15,20210312238,2021.10.07,20210312238,2021.10.07,,,SYSTEM AND METHOD FOR DETECTING ABNORMAL PASSENGER BEHAVIOR IN AUTONOMOUS VEHICLES,"G06K9/62,G06K9/00",Robert Bosch GmbH,"A method and system are disclosed for monitoring passengers in within a cabin of a vehicle and determining whether the passengers are engaging in abnormal behavior. The method and system uses a novel vector to robustly and numerically represent the activity of the passengers in a respective frame, which is referred to herein as an “activity vector.” Additionally, a Gaussian Mixture Model is utilized by the method and system to distinguish between normal and abnormal passenger behavior. Cluster components of the Gaussian Mixture Model are advantageously learned using an unsupervised approach in which training data is not labeled or annotated to indicate normal and abnormal passenger behavior. In this way, the Gaussian Mixture Model can be trained at a very low cost."
676,16834497,2020.03.30,20210300422,2021.09.30,20210300422,2021.09.30,,,SYSTEMS AND METHODS FOR SEMI-AUTONOMOUSLY CONTROLLING A VEHICLE,"B60W60/00,B60W40/08,B60W30/09,B60W30/095,G05B13/02,G06N3/08","Toyota Research Institute, Inc.,Toyota Research Institute, Inc.","Systems and methods for semi-autonomously controlling a vehicle are disclosed. In one embodiment, a method includes determining a trajectory of a semi-autonomous vehicle based on data received from one or more vehicle sensors, determining a state of the vehicle based on data received from the vehicle sensors, determining an optimal trajectory of the vehicle based on the state of the vehicle, determining a level of confidence in the determined state of the vehicle and in the determined optimal trajectory of the vehicle, determining a plurality of possible future states of the vehicle based on the state of the vehicle, the trajectory of the vehicle, and the level of confidence, determining whether a subset of the possible future states of the vehicle are recoverable, and when it is determined that the subset of the possible future states of the vehicle are recoverable, issuing a security certificate."
677,16716580,2019.12.17,,,11132585,2021.09.28,11132585,2021.09.28,System and method for detecting abnormal passenger behavior in autonomous vehicles,"G06K9/00,G06K9/62",Robert Bosch GmbH,"A method and system are disclosed for monitoring passengers in within a cabin of a vehicle and determining whether the passengers are engaging in abnormal behavior. The method and system uses a novel vector to robustly and numerically represent the activity of the passengers in a respective frame, which is referred to herein as an “activity vector.” Additionally, a Gaussian Mixture Model is utilized by the method and system to distinguish between normal and abnormal passenger behavior. Cluster components of the Gaussian Mixture Model are advantageously learned using an unsupervised approach in which training data is not labeled or annotated to indicate normal and abnormal passenger behavior. In this way, the Gaussian Mixture Model can be trained at a very low cost."
678,16895330,2020.06.08,,,11127086,2021.09.21,11127086,2021.09.21,Accident fault determination for autonomous vehicles,"G06Q40/00,G06Q40/08,G07C5/08,H04L29/08,H04W4/90,H04W4/44,G07C5/00,B60W40/09,G08G1/005,G08G1/16,G08G1/0967,G08G1/14,G08B21/06,B60W30/16,G08G1/00,G06K9/00,G08B25/08,G06F30/20,G06Q40/04,G06Q10/06,B60Q9/00,G06Q20/08,B60R21/00,G05B15/02,H04W4/46,B60W40/08,G01S19/13,G06Q50/30",State Farm Mutual Automobile Insurance Company,"Methods and systems for determining fault for an accident involving a vehicle having one or more autonomous (and/or semi-autonomous) operation features are provided. According to certain aspects, operating data from sensors within or near the vehicle may be used to determine the occurrence of a vehicle accident, such as a collision. The operating data may further be used to determine an allocation of fault for the accident between a vehicle operator, the autonomous operation features, or a third party. The allocation of fault may be used to adjust risk levels or profiles associated with the vehicle operator or with the autonomous operation features."
679,17330511,2021.05.26,20210286985,2021.09.16,20210286985,2021.09.16,,,PEDESTRIAN BEHAVIOR PREDICTIONS FOR AUTONOMOUS VEHICLES,"G06K9/00,B60W30/095,G08G1/16,G05D1/02,G05D1/00",Waymo LLC,"The technology relates to controlling a vehicle in an autonomous driving mode. For instance, sensor data identifying an object in an environment of the vehicle may be received. A grid including a plurality of cells may be projected around the object. For each given one of the plurality of cells, a likelihood that the object will enter the given one within a period of time into the future is predicted. A contour is generated based on the predicted likelihoods. The vehicle is then controlled in the autonomous driving mode in order to avoid an area within the contour."
680,17254731,2019.05.20,20210269037,2021.09.02,20210269037,2021.09.02,,,SYSTEM AND METHOD TO NAVIGATE AUTONOMOUS VEHICLES,"B60W30/18,B60W60/00,B60W40/06,G06K9/00","Optimum Semiconductor Technologies Inc.,Optimum Semiconductor Technologies Inc.","A system and method to operate an autonomous vehicle on the road. The system and method may include determining a lane area on a road, calculating a first position within the lane area, determining a tolerance region within the lane area, calculating a deviation offset based on the tolerance region, calculating a second position based on the first position and the deviation offset, and causing to operate the autonomous vehicle to travel to the second position."
681,16288750,2019.02.28,,,11107358,2021.08.31,11107358,2021.08.31,Autonomous services vehicles,"G05D1/00,G08G1/00,G06Q10/02","UIPCO, LLC",An autonomous vehicle including equipment configured to provide one or more services to a user in the presence of the vehicle. The vehicle may include a device processor; and a non-transitory computer readable medium including instructions executable by the device processor to perform the following steps: receiving and executing dispatch instructions by autonomously driving to a location designated by a user; and providing the one or more services to the user at the designated location.
682,16834691,2020.03.30,20210253130,2021.08.19,20210253130,2021.08.19,,,METHOD AND SYSTEM FOR GENERATING VELOCITY PROFILES FOR AUTONOMOUS VEHICLES,"B60W60/00,G01S17/931,B60W40/06,B60W40/10,B60W50/04,G05B13/02,G06N20/00",Wipro Limited,"Embodiments of the present disclosure relate to generating velocity profiles for an autonomous vehicle (  101  ). An ECU (  107  ) of the autonomous vehicle (  101  ) receives road information from one or more sensors (  106  ) associated with the autonomous vehicle (  101  ). One or more parameters related to smooth movement of the autonomous vehicle on the road is determined from the road information. Further, a first velocity profile is produced using an AI model and a second velocity profile is produced using a hierarchical model, based on the one or more parameters. Furthermore, one of the first and the second velocity profile is selected by comparing the first and the second velocity profiles. The selected velocity profile has a lower value of velocity value compared to the other velocity profile. The selected velocity profile is provided to the autonomous vehicle (  101  ) for navigating on the road (  102  ) smoothly."
683,16422139,2019.05.24,,,11049301,2021.06.29,11049301,2021.06.29,Method and system for automatically generating an appealing visual based on an original visual captured by the vehicle mounted camera,"G06K9/00,G06T11/60,G06K9/72,G06T5/00,H04N5/225",HONDA RESEARCH INSTITUTE EUROPE GMBH,"A system and method for automatically generating an appealing visual based on an original visual captured by a vehicle mounted camera are provided. A semantic image content and its arrangement in the original visual is computed; an optimization process is performed that improves an appeal of the original visual by making it more similar to a set of predetermined traits. The optimization process may include adding information to the original visual to generate an enhanced visual by adapting content from further visuals, and adapting iteratively a geometric parameter set of the enhanced visual to generate a certain perspective or morphing to improve an arrangement of semantics in the enhanced visual. The optimized parameter set may be applied to the enhanced visual. Post-processing may be conducted after applying the optimized parameter set using a set of templates to generate a final visual that may be output for immediate or later use."
684,17123185,2020.12.16,20210192238,2021.06.24,20210192238,2021.06.24,,,PHRASE RECOGNITION MODEL FOR AUTONOMOUS VEHICLES,"G06K9/00,G05D1/00,G06N3/08,G06T11/20,G06K9/34,G06F40/30","WAYMO LLC,WAYMO LLC","Aspects of the disclosure relate to training and using a phrase recognition model to identify phrases in images. As an example, a selected phrase list may include a plurality of phrases is received. Each phrase of the plurality of phrases includes text. An initial plurality of images may be received. A training image set may be selected from the initial plurality of images by identifying the phrase-containing images that include one or more phrases from the selected phrase list. Each given phrase-containing image of the training image set may be labeled with information identifying the one or more phrases from the selected phrase list included in the given phrase-containing images. The model may be trained based on the training image set such that the model is configured to, in response to receiving an input image, output data indicating whether a phrase of the plurality of phrases is included in the input image."
685,16716580,2019.12.17,20210182617,2021.06.17,20210182617,2021.06.17,,,SYSTEM AND METHOD FOR DETECTING ABNORMAL PASSENGER BEHAVIOR IN AUTONOMOUS VEHICLES,"G06K9/62,G06K9/00",Robert Bosch GmbH,"A method and system are disclosed for monitoring passengers in within a cabin of a vehicle and determining whether the passengers are engaging in abnormal behavior. The method and system uses a novel vector to robustly and numerically represent the activity of the passengers in a respective frame, which is referred to herein as an “activity vector.” Additionally, a Gaussian Mixture Model is utilized by the method and system to distinguish between normal and abnormal passenger behavior. Cluster components of the Gaussian Mixture Model are advantageously learned using an unsupervised approach in which training data is not labeled or annotated to indicate normal and abnormal passenger behavior. In this way, the Gaussian Mixture Model can be trained at a very low cost."
686,16692956,2019.11.22,20210158546,2021.05.27,20210158546,2021.05.27,,,UPDATED POINT CLOUD REGISTRATION PIPELINE BASED ON ADMM ALGORITHM FOR AUTONOMOUS VEHICLES,"G06T7/33,G06T7/73,G05D1/00,G01S19/45,G01S17/89",Baidu USA LLC,"In one embodiment, a system and method for point cloud registration of LIDAR poses of an autonomous driving vehicle (ADV) is disclosed. The method selects poses of the point clouds that possess higher confidence level during the data capture phase as fixed anchor poses. The fixed anchor points are used to estimate and optimize the poses of non-anchor poses during point cloud registration. The method may partition the points clouds into blocks to perform the ICP algorithm for each block in parallel by minimizing the cost function of the bundle adjustment equation updated with a regularity term. The regularity term may measure the difference between current estimates of the poses and previous or the initial estimates. The method may also minimize the bundle adjustment equation updated with a regularity term when solving the pose graph problem to merge the optimized poses from the blocks to make connections between the blocks."
687,16692960,2019.11.22,20210158547,2021.05.27,20210158547,2021.05.27,,,COORDINATE GRADIENT METHOD FOR POINT CLOUD REGISTRATION FOR AUTONOMOUS VEHICLES,"G06T7/33,G06T7/73,G01S17/42,G01S17/931,G01S7/48",Baidu USA LLC,"In one embodiment, a system and method for partitioning a region for point cloud registration of LIDAR poses of an autonomous driving vehicle (ADV) using a regional iterative closest point (ICP) algorithm is disclosed. The method determines the frame pair size of one or more pairs of related LIDAR poses of a region of an HD map to be constructed. If the frame pair size is greater than a threshold, the region is further divided into multiple clusters. The method may perform the ICP algorithm for each cluster. Inside a cluster, the ICP algorithm focuses on a partial subset of the decision variables and assumes the rest of the decision variables are fixed. To construct the HD map, the method may determine if the results of the ICP algorithms from the clusters converge. If the solutions converge, a solution to the point cloud registration for the region is found."
688,16598752,2019.10.10,20210106266,2021.04.15,20210106266,2021.04.15,,,PSYCHOMOTOR VIGILANCE TESTING FOR PERSONS TASKED WITH MONITORING AUTONOMOUS VEHICLES,"A61B5/18,A61B5/16,G05D1/00",Waymo LLC,Assessing a likelihood of a person experiencing a fatigue event when the person tasked with monitoring a vehicle operating in an autonomous driving mode may include receiving a set of response times for a psychomotor vigilance test administered to the person. The test may include a plurality of trials which involve a person lifting a finger from a user input device. Whether the person passed or failed each trial of the set of trials may be determined. A model trained using data from prior psychomotor vigilance tests administered to the person may be identified for the person. Results of the determinations of whether the person passed or failed each trial of the set of trials may be input into the model in order to determine a value representative of a likelihood of a fatigue event. An intervention response may be initiated based on the value.
689,16575521,2019.09.19,20210089039,2021.03.25,20210089039,2021.03.25,,,SYSTEM AND METHOD FOR AVOIDING CONTACT BETWEEN AUTONOMOUS AND MANNED VEHICLES CAUSED BY LOSS OF TRACTION,"G05D1/02,G05D1/00,B60W30/09,G06N20/00","CATERPILLAR INC.,CATERPILLAR INC.","A control system for preventing vehicle collisions may include a vehicle location determination module, a terrain determination module, a terrain surface coefficient of friction estimation module, and a sensing system configured to generate signals indicative of vehicle speed, vehicle pose, vehicle size, vehicle weight, vehicle tire type, vehicle load, vehicle gear ratio, weather characteristics, and road conditions for a vehicle operating at a job site. A manned vehicle trajectory determination module may receive location information and plot a first travel path for a manned vehicle based at least in part on a location, heading, and speed of the manned vehicle and a desired destination for the manned vehicle. An autonomous vehicle trajectory determination module may receive location information, terrain information, and terrain surface coefficient of friction information, plot a second travel path for an autonomous vehicle, and determine projected slide trajectories for the autonomous vehicle at successive positions along the second travel path where the autonomous vehicle is predicted to lose traction based at least in part on signals received from the sensing system."
690,17019161,2020.09.11,20210078550,2021.03.18,20210078550,2021.03.18,,,SUPPLEMENTAL BRAKING CONTROL SYSTEM IN AUTONOMOUS VEHICLES,"B60T8/171,B60T8/88,B60T8/17","TUSIMPLE, INC.","Described are devices, systems and methods for managing a supplemental brake control system in autonomous vehicles. In some aspects, a supplemental brake management system includes brake control hardware and software that operates with a sensing mechanism for determining the brake operational status and a control mechanism for activating the supplemental brake control in an autonomous vehicle, which can be implemented in addition to the vehicle's primary brake control system."
691,17109002,2020.12.01,20210082434,2021.03.18,20210082434,2021.03.18,,,DYNAMIC MICROPHONE SYSTEM FOR AUTONOMOUS VEHICLES,"G10L15/22,B60R16/037","Alpine Electronics of Silicon Valley, Inc.","Devices, systems and processes for a dynamic microphone system that enhances the passenger experience in autonomous vehicles are described. One example method for enhancing a passenger experiences includes generating, using an artificial intelligence algorithm, a plurality of filters based on a plurality of stored waveforms previously recorded by each of one or more passengers and a plurality of recordings of one or more noise sources, capturing voice commands from at least one of the one or more passengers inside the autonomous vehicle, generating voice commands with reduced distortion based on processing the voice commands using the plurality of filters, and instructing, based on the voice commands with reduced distortion, the autonomous vehicle to perform one or more actions."
692,17087858,2020.11.03,20210072756,2021.03.11,20210072756,2021.03.11,,,Solution Path Overlay Interfaces for Autonomous Vehicles,"G05D1/02,G01C21/36,G05D1/00","Nissan North America, Inc.,United States of America as Represented by the Administrator of NASA","Methods and systems for generating a solution path overlay interface to transmit a solution path are described. A method comprises receiving data from a vehicle control system of a vehicle, the data including a movement path for each of a plurality of external objects; generating a solution path overlay interface that includes an indicator for the vehicle, an indicator for one or more of the plurality of external objects and an indicator for a solution path; in response to detecting a change associated with a movement path of the one or more of the plurality of external objects, receiving a command from an operator of the solution path overlay interface, the command including an indication of one or more stop points; updating the solution path overlay interface based on the command to provide an updated solution path; and transmitting the updated solution path to the vehicle for execution."
693,16375747,2019.04.04,20190310378,2019.10.10,10921455,2021.02.16,10921455,2021.02.16,Efficient and scalable three-dimensional point cloud segmentation for navigation in autonomous vehicles,"G06K9/00,G01S17/931,G06T7/136,G06T7/187,G05D1/02","Apex.AI, Inc.","Efficient and scalable three-dimensional point cloud segmentation. In an embodiment, a three-dimensional point cloud is segmented by adding points to a spatial hash. For each unseen point, a cluster is generated, the unseen point is added to the cluster and marked as seen, and, for each point that is added to the cluster, the point is set as a reference, a reference threshold metric is computed, all unseen neighbors are identified based on the reference threshold metric, and, for each identified unseen neighbor, the unseen neighbor is marked as seen, a neighbor threshold metric is computed, and the neighbor is added or not added to the cluster based on the neighbor threshold metric. When the cluster reaches a threshold size, it may be added to a cluster list. Objects may be identified based on the cluster list and used to control autonomous system(s)."
694,16938279,2020.07.24,20210024092,2021.01.28,20210024092,2021.01.28,,,BATTERY POWER CONTROL IN AUTONOMOUS VEHICLES HAVING ALTERNATOR-CHARGING SYSTEMS,"B60W60/00,B60W10/20,B60W10/18,B60W10/08,B60W10/26,B60W40/105","TUSIMPLE, INC.","Described are devices, systems and methods for managing power generation, storage and/or distribution in autonomous vehicles. In some aspects, a system for power management in an autonomous vehicle having a main power source and one or more alternators includes a vehicle control unit, a secondary power source, and a power management unit. In some embodiments, the power management unit is configured on an autonomous vehicle having a single alternator-charging system for battery charging and battery power control with different battery packs. In some embodiments, the power management unit is configured on an autonomous vehicle having multiple alternator-charging systems for battery charging and battery power control for different battery packs."
695,16879299,2020.05.20,20200356794,2020.11.12,10902272,2021.01.26,10902272,2021.01.26,Phrase recognition model for autonomous vehicles,"G06K9/00,G05D1/00,G06N3/08,G06T11/20,G06F40/30,G06K9/34",Waymo LLC,"Aspects of the disclosure relate to training and using a phrase recognition model to identify phrases in images. As an example, a selected phrase list may include a plurality of phrases is received. Each phrase of the plurality of phrases includes text. An initial plurality of images may be received. A training image set may be selected from the initial plurality of images by identifying the phrase-containing images that include one or more phrases from the selected phrase list. Each given phrase-containing image of the training image set may be labeled with information identifying the one or more phrases from the selected phrase list included in the given phrase-containing images. The model may be trained based on the training image set such that the model is configured to, in response to receiving an input image, output data indicating whether a phrase of the plurality of phrases is included in the input image."
696,16938705,2020.07.24,20210012592,2021.01.14,20210012592,2021.01.14,,,Fleet Maintenance Management for Autonomous Vehicles,"G07C5/08,G06N5/04,G07C5/00,G05D1/00,G05D1/02,G06N20/00,G06Q50/30,G06Q10/00,G06Q10/06,G06Q10/02","Lyft, Inc.","In particular embodiments, a computing system may determine a predicted amount of ride requests for a plurality of collectively-managed vehicles and determine an availability of the collectively-managed vehicles to satisfy the predicted amount of ride requests. Subsequent to determining that the availability fails to satisfy one or more predetermined criteria for servicing the predicted amount of ride requests, the system may determine status information associated with the collectively-managed vehicles and determine, based on at least the status information, one or more minimum services for servicing one or more vehicles among the plurality of collectively-managed vehicles at one or more service centers such that the availability satisfies the one or more predetermined criteria. The system may instruct the one or more vehicles that are to receive the one or more minimum services to travel to the one or more service centers to be serviced."
697,16433165,2019.06.06,20200385008,2020.12.10,20200385008,2020.12.10,,,Safety-Aware Comparator for Redundant Subsystems in Autonomous Vehicles,"B60W50/023,G05D1/00","NXP B.V.,NXP B.V.","A method, system and device are disclosed for determining safety conflicts in redundant subsystems of autonomous vehicles. Each redundant subsystem calculates a world model or path plan, including locations, dimensions, and orientations of moving and stationary objects, as well as projected travel paths for moving objects in the future. The travel paths and projected future world models are subsequently compared using a geometric overlay operation. If at future time moments the projected world models match within predefined margins, the comparison results in a match. In case of a mismatch at a given future moment between projected world models, a determination is made as to whether the autonomous vehicle and all road users in this future moment are safe from collision or driving off the drivable space or road based on a geometric overlay operation."
698,16874644,2020.05.14,20200363816,2020.11.19,20200363816,2020.11.19,,,SYSTEM AND METHOD FOR CONTROLLING AUTONOMOUS VEHICLES,"G05D1/02,B60W50/00,B60W40/105,B60W40/11,B60W40/107",WeRide Corp.,"A method for controlling a vehicle using a model predictive controller generating consecutive sets of reference states at a calculation frequency. In one embodiment, the method comprises: receiving a trajectory reference for guiding movement of the vehicle; generating, in a calculation cycle repeated at the calculation frequency, a set of reference states based on an initial state of the vehicle at a start time of the calculation cycle and the trajectory reference; sending the set of reference states to a second controller; detecting, by the second controller at a detection frequency equal to or higher than the calculation frequency, an updated state of the vehicle; generating a vehicle control parameter value based on the updated state of the vehicle and a reference state of the set of reference states; and controlling the vehicle using the vehicle control parameter value."
699,16895408,2020.06.08,20200302548,2020.09.24,20200302548,2020.09.24,,,ACCIDENT FAULT DETERMINATION FOR AUTONOMOUS VEHICLES,G06Q40/08,State Farm Mutual Automobile Insurance Company,"Methods and systems for determining fault for an accident involving a vehicle having one or more autonomous (and/or semi-autonomous) operation features are provided. According to certain aspects, operating data from sensors within or near the vehicle may be used to determine fault for a vehicle accident, such as a collision. The operating data may include information regarding use of the features at the time of the accident and may further be used to determine an allocation of fault for the accident between a vehicle operator, the autonomous operation features, or a third party. The allocation of fault may be used to determine and/or adjust coverage levels for an insurance policy associated with the vehicle. The allocation of fault may further be used to adjust risk levels or profiles associated with the vehicle operator or with the autonomous operation features."
700,16895330,2020.06.08,20200302546,2020.09.24,20200302546,2020.09.24,,,ACCIDENT FAULT DETERMINATION FOR AUTONOMOUS VEHICLES,G06Q40/08,State Farm Mutual Automobile Insurance Company,"Methods and systems for determining fault for an accident involving a vehicle having one or more autonomous (and/or semi-autonomous) operation features are provided. According to certain aspects, operating data from sensors within or near the vehicle may be used to determine the occurrence of a vehicle accident, such as a collision. The operating data may further be used to determine an allocation of fault for the accident between a vehicle operator, the autonomous operation features, or a third party. The allocation of fault may be used to adjust risk levels or profiles associated with the vehicle operator or with the autonomous operation features."
701,16817600,2020.03.12,20200291608,2020.09.17,20200291608,2020.09.17,,,Sensor Retrofit to Autonomously Actuate An Excavation Vehicle,"E02F9/20,E02F3/43",Built Robotics Inc.,"An excavation vehicle capable of autonomously actuating an excavation tool or navigating an excavation vehicle to perform an excavation routine within an excavation site is described herein. Sensors mounted to the excavation vehicle and the excavation tool produce signals representative of a position and orientation of the corresponding joint relative on the excavation vehicle relative to the excavation site, a position and orientation of the excavation vehicle relative to the excavation site, and one or more features of the excavation site based on the position of the excavation vehicle within the excavation site. A set of solenoids are configured to couple to corresponding hydraulic valves of the excavation tool to actuate the valve. A controller produces actuating signals to control the joints of the excavation tool to autonomously perform the excavation routine based on the signals produced by the sensors."
702,16874928,2020.05.15,20200290509,2020.09.17,20200290509,2020.09.17,,,COMMUNICATIONS FOR AUTONOMOUS VEHICLES,"B60Q5/00,B60Q1/26,G08G1/00,G05D1/00",WAYMO LLC,"Aspects of the disclosure provide a method of facilitating communications from an autonomous vehicle to a user. For instance, a method may include, while attempting to pick up the user and prior to the user entering an vehicle, inputting a current location of the vehicle and map information into a model in order to identify a type of communication action for communicating a location of the vehicle to the user; enabling a first communication based on the type of the communication action; determining whether the user has responded to the first communication from received sensor data; and enabling a second communication based on the determination of whether the user has responded to the communication."
703,16407238,2019.05.09,,,10719886,2020.07.21,10719886,2020.07.21,Accident fault determination for autonomous vehicles,"G06Q40/08,G06Q40/00,G07C5/00,G07C5/08,B60W50/02",State Farm Mutual Automobile Insurance Company,"Methods and systems for determining fault for an accident involving a vehicle having one or more autonomous and/or semi-autonomous operation features are provided. According to certain aspects, performance data indicative of the performance of the features may be used to determine fault for a vehicle accident, such as a collision, by allocating fault for the accident between a vehicle operator, the autonomous operation features, or a third party. The allocation of fault may be used to determine an adjustment to an insurance policy and/or adjust coverage levels for an insurance policy. The allocation of fault may further be used to adjust risk levels or profiles associated with the autonomous or semi-autonomous operation features, which may be applied to other vehicles having the same or similar features."
704,16836486,2020.03.31,20200223447,2020.07.16,20200223447,2020.07.16,,,Dual-Measurement Data Structure for Autonomous Vehicles,"B60W50/023,G05D1/00","Augmented Radar Imaging, Inc.,Augmented Radar Imaging, Inc.","During a measurement technique, an electronic device may receive first sensor information associated with a first field of view and a first timestamp, and second sensor information associated with a second field of view and a second timestamp. For example, the electronic device may perform a first measurement using a first sensor and performing a second, different type of measurement using a second sensor. Therefore, the first sensor information and the second sensor information may be associated with different types of sensors. Moreover, the first timestamp and the second timestamp may be concurrent or in close temporal proximity, and the first field of view and the second field of view may at least substantially overlap. Then, the electronic device may store the first sensor information and the second sensor information in memory. In some embodiments, the electronic device stores the first timestamp and the second timestamp in the memory."
705,16734437,2020.01.06,20200219070,2020.07.09,20200219070,2020.07.09,,,Servicing of autonomous vehicles,"G06Q10/00,G06N20/00,G06N5/04,G07C5/00,G07C5/08",Ottopia Technologies Ltd.,"A method includes generating a plurality of training vectors relating to different respective historical service requests generated by respective autonomous vehicles, each of the training vectors including respective features associated with the historical request to which the training vector relates. The method further includes, using the training vectors, training a model configured to generate a prediction relating to one or more future service requests, generating the prediction using the model, and outputting the generated prediction. Other embodiments are also described."
706,16351124,2019.03.12,,,10696222,2020.06.30,10696222,2020.06.30,Communications for autonomous vehicles,"B60Q5/00,G05D1/00,G08G1/00,B60Q1/26",WAYMO LLC,"Aspects of the disclosure provide a method of facilitating communications from an autonomous vehicle to a user. For instance, a method may include, while attempting to pick up the user and prior to the user entering an vehicle, inputting a current location of the vehicle and map information into a model in order to identify a type of communication action for communicating a location of the vehicle to the user; enabling a first communication based on the type of the communication action; determining whether the user has responded to the first communication from received sensor data; and enabling a second communication based on the determination of whether the user has responded to the communication."
707,16703333,2019.12.04,20200184808,2020.06.11,20200184808,2020.06.11,,,METHOD AND SYSTEM FOR ASCERTAINING PARTICULAR PIECES OF STATUS INFORMATION FOR AT LEAST ONE GEOGRAPHICAL POSITION WITH THE AID OF AUTONOMOUS OR SEMI-AUTONOMOUS VEHICLES,"G08G1/01,G08G1/0967,G08G1/16,G06K9/00,G05D1/00,H04W4/40",Robert Bosch GmbH,"A method is described for ascertaining particular pieces of status information for at least one geographical position with the aid of autonomous or semi-autonomous vehicles,  at least one autonomous or semi-autonomous vehicle detecting pieces of information from its surroundings during a drive with using at least one surroundings sensor and carrying out a planning of its instantaneous travel trajectory based on the obtained pieces of information, and the vehicle detecting additional pieces of information from its surroundings with using its surroundings sensor during a stop, which are not used for planning its instantaneous travel trajectory. The vehicle conveys the ascertained additional pieces of information, with a geographical position at which the additional pieces of information have been detected, to an external server. The external server uses the data received from the vehicle to ascertain at least one piece of status information for the respective geographical position."
708,16667784,2019.10.29,20200136240,2020.04.30,20200136240,2020.04.30,,,RANGE ADAPTABLE ANTENNA SYSTEM FOR AUTONOMOUS VEHICLES,"H01Q1/32,G05D1/02,G05D1/00,H01Q3/26,H04W4/40",Metawave Corporation,"Examples disclosed herein relate to a range adaptable antenna system for use in autonomous vehicles. The antenna system has a connector and a transition layer to receive an RF transmission signal from a transmission signal controller, a range adaptable power divider layer coupled to the connector and transition layer to divide the RF transmission signal into a plurality of transmission signals to propagate through an array of transmission lines, with a set of transmission lines from the array of transmission lines having a set of switches, an RFIC layer having a plurality of phase shifters to apply different phase shifts to the plurality of transmission signals and generate a plurality of phase shifted transmission signals, and an antenna layer having an array of superelements for radiating the plurality of phase shifted transmission signals, wherein a set of superelements is connected to the set of switches in the range adaptable power divider layer for deactivation."
709,16437881,2019.06.11,20190295421,2019.09.26,10586458,2020.03.10,10586458,2020.03.10,Hybrid trip planning for autonomous vehicles,"G08G1/00,G01C21/34,B60W50/08,G06Q10/04,G01S19/13","Uber Technologies, Inc.","A hybrid trip planning system can receive transport requests from requesting users, and determine a pick-up location from each transport request. The pick-up location can be within or external to an autonomy grid on which a plurality of autonomous vehicles (AVs) can operate in an autonomous mode. The system can further determine a drop-off location from the transport request, the drop-off location also being within or external to the autonomy grid. The system can select and route an AV to a most optimal entry and/or exit point of the autonomy grid based on the transport request, where the selected AV is to switch between a manual and an autonomous mode."
710,16542151,2019.08.15,20200058987,2020.02.20,20200058987,2020.02.20,,,"MULTI-LAYER, MULTI-STEERING ANTENNA SYSTEM FOR AUTONOMOUS VEHICLES","H01Q1/32,H01Q21/06,H01Q3/36,G01S7/03,G01S13/93",Metawave Corporation,"Examples disclosed herein relate to a multi-layer, multi-steering (MLMS) antenna array for autonomous vehicles. The MLMS antenna array includes a superelement antenna array layer comprising superelement subarrays, in which each superelement subarray includes radiating slots for radiating a transmission signal. The MLMS antenna array also includes a power divider layer coupled to the superelement antenna array layer and configured to serve as a feed to the superelement antenna array layer, in which the power divider layer is coupled to phase shifters that apply different phase shifts to transmission signals propagating to the superelement antenna array layer. The MLMS antenna array also includes a transition layer configured to couple the power divider layer and the superelement antenna array layer to the phase shifters through transition structures such as through-hole vias. Other examples disclosed herein include a radar system for use in an autonomous driving vehicle."
711,16432921,2019.06.05,20190375425,2019.12.12,20190375425,2019.12.12,,,GEOGRAPHICALLY DISPARATE SENSOR FUSION FOR ENHANCED TARGET DETECTION AND IDENTIFICATION IN AUTONOMOUS VEHICLES,"B60W50/04,B60W30/08,G01S13/86,G01S13/93",Metawave Corporation,Examples disclosed herein relate to an autonomous driving system in an ego vehicle. The autonomous driving system includes a radar system configured to detect and identify a target in a path and a surrounding environment of the ego vehicle. The autonomous driving system also includes a sensor fusion module configured to receive radar data on the identified target from the radar system and compare the identified target with one or more targets identified by a plurality of perception sensors that are geographically disparate from the radar system. Other examples disclosed herein include a method of operating the radar system in the autonomous driving system of the ego vehicle.
712,16434501,2019.06.07,20190377342,2019.12.12,20190377342,2019.12.12,,,NAVIGATIONAL CONSTRAINTS FOR AUTONOMOUS VEHICLES,"G05D1/00,G01C21/34,G08G1/00","Uber Technologies, Inc.","A computing system can generate a map constraint interface enabling a fleet operator to update map constraints for autonomous vehicles (AVs). The map constraint interface can comprise a unified document model enabling the fleet operator to configure a set of constraint layers of autonomy maps utilized by the AVs. Each constraint layer can include a toggle feature that enables the fleet operator to enable and disable the constraint layer. The system can receive, via the map constraint interface, a set of inputs configuring the set of constraint layers of the one or more autonomy maps, compile a set of updated map constraints, corresponding to the configured set of constraint layers, into a document container, and output the document container to a subset of the AVs to enable the subset of AVs to integrate the set of updated map constraints with the autonomy maps."
713,16422139,2019.05.24,20190362527,2019.11.28,20190362527,2019.11.28,,,METHOD AND SYSTEM FOR AUTOMATICALLY GENERATING AN APPEALING VISUAL BASED ON AN ORIGINAL VISUAL CAPTURED BY THE VEHICLE MOUNTED CAMERA,"G06T11/60,G06T5/00,G06K9/72",HONDA RESEARCH INSTITUTE EUROPE GMBH,"A system and method for automatically generating an appealing visual based on an original visual captured by a vehicle mounted camera are provided. A semantic image content and its arrangement in the original visual is computed; an optimization process is performed that improves an appeal of the original visual by making it more similar to a set of predetermined traits. The optimization process may include adding information to the original visual to generate an enhanced visual by adapting content from further visuals, and adapting iteratively a geometric parameter set of the enhanced visual to generate a certain perspective or morphing to improve an arrangement of semantics in the enhanced visual. The optimized parameter set may be applied to the enhanced visual. Post-processing may be conducted after applying the optimized parameter set using a set of templates to generate a final visual that may be output for immediate or later use."
714,17678398,2022.02.23,20220306161,2022.09.29,20220306161,2022.09.29,,,Method for detecting inconsistencies in the outputs of perception systems of autonomous vehicles,B60W60/00,IVEX,"A system and method for the detection of inconsistencies in perception systems of autonomous vehicles is described. The system receives the observations of objects in the surrounding environment from one or more sensors or perception systems of an automated vehicle. At actual time, the system estimates the consistency of the currently observed elements of the perception system according to the previous inputs received. This consistency is decided by calculating the boundaries of possible states of the previously observed elements, based on the received information and on assumptions."
715,17652008,2022.02.22,20220308594,2022.09.29,20220308594,2022.09.29,,,"METHOD AND SYSTEM FOR CONTROLLING A PLURALITY OF VEHICLES, IN PARTICULAR AUTONOMOUS VEHICLES","G05D1/02,G05D1/00,G01C21/34","VOLVO AUTONOMOUS SOLUTIONS AB,VOLVO AUTONOMOUS SOLUTIONS AB",There is provided a method for controlling a plurality of vehicles sharing a set of common resources Each vehicle's motion is controllable by a finite set of predefined commands. The method includes forming subsets of the common resources on the basis of predefined motion constraints of individual ones of the vehicles; partitioning the vehicles into disjoint clusters on the basis of the subsets; executing a tree-based planning algorithm. Each execution including an evaluation of sequences of the predefined commands to be fed to the vehicles in a single cluster and a selection of a preferred sequence of the commands; and feeding the preferred sequence of commands to the vehicles in each cluster.
716,16514083,2019.07.17,,,11345341,2022.05.31,11345341,2022.05.31,"Information processing apparatus, information processing method and computer readable recording medium for recording information processing program for providing autonomous movement of stationary vehicles","B60W30/095,B60W30/09,G08G1/16,G06V20/58,G06V40/16",Panasonic Intellectual Property Management Co. Ltd.,An information processing apparatus of a moving body includes: a sensing information acquisition part which acquires sensing information indicative of a situation of the outside of the moving body by a sensor mounted on the moving body for detecting an object; a traveling obstruction determination part which determines a mode of other moving body which travels near the moving body using the sensing information; and a movement request generation part which controls a movement request transmitted to the moving body using a determination result of the mode of the other moving body.
717,17551091,2021.12.14,20220198921,2022.06.23,20220198921,2022.06.23,,,DATA COLLECTION AND MODELING SYSTEMS AND METHODS FOR AUTONOMOUS VEHICLES,"G08G1/01,G08G1/0967,G08G1/04,G08G1/052,G08G1/048,G06N20/00","Sensible 4 Oy,Sensible 4 Oy","Embodiments of the disclosed systems and methods provide for systems and methods for collecting and managing vehicle and infrastructure sensor measurement data and building predictive models based on such data. In certain embodiments, operation and/or control of a vehicle may be based on the predictive model. In certain embodiments, the predictive model may be generated and/or otherwise trained based on actual vehicle measurement data and actual infrastructure measurement data that has been correlated by associated time and/or location. In further embodiments, model validation techniques may be used to determine a predictive quality of the model."
718,16857553,2020.04.24,20200339131,2020.10.29,20200339131,2020.10.29,,,SAFETY MECHANISM FOR ASSURING DRIVER ENGAGEMENT DURING AUTONOMOUS DRIVE,"B60W40/08,B60W60/00",Zenuity AB,"A method for controlling a driving assistance feature of a vehicle is disclosed. The method comprises determining a state of a driver of the vehicle by means of a driver monitoring system (DMS) the state of the driver comprising at least one attention parameter, and comparing the determined state of the driver with a predefined attention model. The predefined attention model comprises an independent threshold range for each attention parameter. The method further comprises controlling the driving assistance feature based on the comparison between the determined state of the driver and the predefined attention model."
719,17554630,2021.12.17,20220198279,2022.06.23,20220198279,2022.06.23,,,Data-Driven Methodology for Automatic Detection of Data Drift,G06N3/08,"The Boeing Company,The Boeing Company","A system and method for drift detection is disclosed. The method may comprise training and testing an autoencoder, and using the trained and tested autoencoder to automatically detect data drift. The training may include initializing the autoencoder and training the autoencoder based on a first set of sensor data. The testing of the autoencoder with a second set of sensor data may comprise: for an empirical distribution of the reconstruction errors of the second set of sensor data, determining a value of a reconstruction error at the percentile threshold; determining that data drift is not present when the reconstruction error of the second set of sensor data is less than a threshold; and calculating a deviation output for at least one of the one or more sensors. Using the trained and tested autoencoder to automatically detect data drift in sensor data."
720,16783975,2020.02.06,20200256999,2020.08.13,20200256999,2020.08.13,,,LIDAR TECHNIQUES FOR AUTONOMOUS VEHICLES,"G01S17/894,G01S17/931,G01S7/48,G01S17/58","Atulya Yellepeddi,Ravi Kiran Raman,Jennifer Tang,Sefa Demirtas,Miles R. Bennett,Christopher Barber","A Laser Imaging Detection and Ranging (LIDAR) system comprises a memory configured to store LIDAR measurement data obtained by the LIDAR system representative of a three-dimensional (3D) space in a field of view of the LIDAR system and signal processing circuitry. The signal processing circuitry is and configured to convert the LIDAR measurement data to a voxel characteristic of voxels of the 3D space, process and adjust a voxel characteristic of a first voxel of the 3D space using a voxel characteristic of other voxels within a specified distance of the first voxel in the 3D space, continue to process and adjust the voxel characteristics of all voxels in the 3D space, and generate an indication of presence of an object in the field of view according to the adjusted voxel characteristics."
721,17644741,2021.12.16,20220192450,2022.06.23,20220192450,2022.06.23,,,"Method for Automatically Ascertaining Cleaning, Maintenance and/or Repair Information for a Motor-Driven Treatment Tool and System for Automatically Ascertaining Cleaning, Maintenance and/or Repair Information for a Motor-Driven Treatment Tool","A47L9/28,A47L7/00",Andreas Stihl AG &#x26; Co. KG,"A method and system automatically determine cleaning, maintenance and/or repair information for a motor-driven treatment tool, wherein the treatment tool comprises a residue, able to be detected externally optically, caused during the operation of the treatment tool. The method involves the steps of: optically detecting the residue; classing the detected residue in accordance with a type of the residue; determining the cleaning, maintenance and/or repair information based on the classing; and outputting the determined cleaning, maintenance and/or repair information."
722,16381948,2019.04.11,,,11036939,2021.06.15,11036939,2021.06.15,Data driven approach for automatically generating a natural language processing cartridge,"G06F40/295,G06F40/30,G06N20/00,G06N5/02,G06F40/242",INTERNATIONAL BUSINESS MACHINES CORPORATION,"An artifact identification engine identifies artifacts from structured and unstructured data in one or more documents based on pre-defined artifacts, by using cognitive annotations. The identified artifacts are analyzed based at least on received inputs. A cartridge that includes artifacts that are relevant to the structured and unstructured data is generated, based on the analyzing."
723,16381948,2019.04.11,20200327195,2020.10.15,20200327195,2020.10.15,,,DATA DRIVEN APPROACH FOR AUTOMATICALLY GENERATING A NATURAL LANGUAGE PROCESSING CARTRIDGE,"G06F17/27,G06N5/02,G06N20/00",INTERNATIONAL BUSINESS MACHINES CORPORATION,"An artifact identification engine identifies artifacts from structured and unstructured data in one or more documents based on pre-defined artifacts, by using cognitive annotations. The identified artifacts are analyzed based at least on received inputs. A cartridge that includes artifacts that are relevant to the structured and unstructured data is generated, based on the analyzing."
